---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    citation_package: biblatex
  bookdown::html_document2: default
  bookdown::word_document2: default
documentclass: book
bibliography: references.bib
---

```{r}
resource_version <- "temp"
```

# Models for spatial structure {#beyond-borders}
\adjustmtc
\markboth{Models for spatial structure}{}
<!-- For PDF output, include these two LaTeX commands after unnumbered chapter headings, otherwise the mini table of contents and the running header will show the previous chapter -->

In this chapter, I present an investigation of spatial random effects specifications.
My investigation was motivated by a fundamental question encountered during model construction.
Namely, should the model be augmented to capture a conjectured feature of the data?
The results are presented in @howes2023beyond.
Code for the analysis in this chapter is available from [`https://github.com/athowes/beyond-borders`](https://github.com/athowes/beyond-borders).

## Background

## Models based on adjacency

### The Besag model

Spatial structure can be encoded using a symmetric relation between areas.
Let $i \sim j$ if the areas $A_i$ and $A_j$ are adjacent or neighbouring.
Adjacency is often defined by a shared border, though other choices are possible [@paciorek2013spatial].
The Besag model [@besag1991bayesian] is an improper conditional auto-regressive (ICAR) model where the full conditional distribution of the $i$th spatial random effect is given by
\begin{equation}
    u_i \, | \, \mathbf{u}_{-i} \sim \mathcal{N} \left(\frac{1}{n_{\delta i}} \sum_{j: j \sim i} u_j, \frac{1}{n_{\delta i}\tau_u}\right), (\#eq:besag)
\end{equation}
where $\delta i$ is the set of neighbours of $A_i$ with cardinality $n_{\delta i} = |\delta i|$ and $\mathbf{u}_{-i}$ is the vector of spatial random effects with the $i$th entry removed.
The conditional mean of the random effect $u_i$ is the average of its neighbours $\{u_j\}_{j \sim i}$ and the precision $n_{\delta i}\tau_u$ is proportional to the number of neighbours $n_{\delta i}$.
By Brook's lemma [@rue2005gaussian] the set of full conditionals of the Besag model are equivalent to the Gaussian Markov random field (GMRF) given by
\begin{equation}
    \mathbf{u} \sim \mathcal{N}(\mathbf{0}, \tau_u^{-1} \mathbf{R}^{-}), (\#eq:gmrf)
\end{equation}
where $\mathbf{R}^{-}$ is the generalised inverse of the rank-deficient structure matrix $\mathbf{R}$, so-called because it defines the structure of the precision matrix, with entries
\begin{equation}
    R_{ij} =
    \begin{cases}
        n_{\delta i}, & i = j \\
        -1, & i \sim j \\
        0, & \text{otherwise.}
    \end{cases}
\end{equation}
The Markov property arises due to the conditional independence structure $p(u_i \, | \, \mathbf{u}_{-i}) = p(u_i \, | \, \mathbf{u}_{\delta i})$ whereby each area only depends on its neighbours.
This is reflected in the sparsity of $\mathbf{R}$ such that $u_i \perp u_j \, | \, \mathbf{u}_{-ij}$ if and only if $R_{ij} = 0$.
The structure matrix $\mathbf{R}$ may also be expressed as the Laplacian of the adjacency graph $\mathcal{G} = (\mathcal{V}, \mathcal{E})$ with vertices $v \in \mathcal{V}$ corresponding to each area and edges $e \in \mathcal{E}$ between vertices $i$ and $j$ when $i \sim j$.

Rewriting Equation \@ref(eq:gmrf), the probability density function of $\mathbf{u}$ is
\begin{equation}
    p(\mathbf{u})
    \propto \exp \left( -\frac{\tau_u}{2} \mathbf{u}^\top \mathbf{R} \mathbf{u} \right)
    \propto \exp \left( -\frac{\tau_u}{2} \sum_{i \sim j} (u_i - u_j)^2 \right). (\#eq:pdfu)
\end{equation}
This density is a function of the pairwise differences $u_i - u_j$ and so is invariant to the addition of a constant $c$ to each entry $p(\mathbf{u}) = p(\mathbf{u} + c\mathbf{1})$, leading to an improper uniform distribution on the average of the $u_i$.
If $\mathcal{G}$ is connected, in that by traversing the edges, any vertex can be reached from any other vertex, then there is only one impropriety in the model and $\text{rank}(\mathbf{R}) = n - 1$, while if $\mathcal{G}$ is disconnected, and composed of $n_c \geq 2$ connected components with index sets $I_1, \ldots, I_{n_c}$, then the corresponding structure matrix $\mathbf{R}$ has rank $n - n_c$ and the density is invariant to the addition of a constant to each of the connected components $p(\mathbf{u}_{I}) = p(\mathbf{u}_{I} + c\mathbf{1})$ where $I = I_1, \ldots, I_{n_c}$.

### Best practises for the Besag model

@freni2018note recommended three best practices:

1. The structure matrix $\mathbf{R}$ should be rescaled to have generalised variance, defined by the geometric mean of the diagonal elements of its generalised inverse
\begin{equation}
    \sigma^2_{\text{GV}}(\mathbf{R}) = \prod_{i = 1}^n (\mathbf{R}^-_{ii})^{1/n} = \exp \left( \frac{1}{n} \sum_{i = 1}^n \log (\mathbf{R}^-_{ii}) \right),
\end{equation}
equal to one, by replacing $\mathbf{R}$ with $\mathbf{R}^\star = \mathbf{R} / \sigma^2_{\text{GV}}(\mathbf{R})$.
As the diagonal elements $R^-_{ii}$ correspond to marginal variances, the generalised variance gives a measure of the average marginal variance.
However, this measure, introduced by @sorbye2014scaling, ignores off-diagonal entries and more broadly any measure of typical variance could be used.
Scaling mitigates the influence of the adjacency graph on the variance of $\mathbf{u}$.
Allowing the variance to be controlled by $\tau_u$ alone is important as it allows for consistent, interpretable prior selection.

When the adjacency graph is disconnected it is not appropriate to scale the structure matrix $\mathbf{R}$ uniformly since for a given precision $\tau_u$, local smoothing operates on each connected component independently.
As such, each connected component should be scaled independently to have generalised variance one giving $\mathbf{R}^\star_I = \mathbf{R}_I / \sigma^2_{\text{GV}}(\mathbf{R}_I)$ where $\mathbf{R}_I$ is the sub-matrix of the structure matrix corresponding to index set $I$.

2. When one of the connected components is a single area, known either as a singleton or an island, the probability density $\exp \left( -\frac{\tau_u}{2} \sum_{i \sim j} (u_i - u_j)^2 \right)$ has no dependence on $u_i$.
This is equivalent to using an improper prior $p(u_i) \propto 1$ and can be avoided by setting each singleton to have independent Gaussian noise $p(u_i) \sim \mathcal{N}(0, 1)$.
3. To avoid confounding of the spatial random effects with the intercept, it is recommended to place a sum-to-zero constraint on each non-singleton connected component.
In other words, for each $|I| > 1$ that $\sum_{i \in I} u_i = 0$.

### The reparameterised Besag-York-Mollié model

Often, as well as spatial structure, there exists IID over-dispersion in the residuals and it is inappropriate to use purely spatially structured random effects in the model.
The Besag-York-Mollié (BYM) model of @besag1991bayesian accounts for this in a natural way by decomposing the spatial random effect $\mathbf{u} = \mathbf{v} + \mathbf{w}$ into a sum of an unstructured IID component $\mathbf{v}$ and a spatially structured Besag component $\mathbf{w}$, each of which with their own respective precision parameters $\tau_v$ and $\tau_w$.
The resulting distribution is
\begin{equation}
    \mathbf{u} \sim \mathcal{N}(0, \tau_v^{-1} \mathbf{I} + \tau_w^{-1} \mathbf{R}^{-}) (\#eq:bym).
\end{equation}
Including both $\mathbf{v}$ and $\mathbf{w}$ is intended to enable the model to learn the relative extent of the unstructured and structured components via $\tau_v$ and $\tau_w$.
However, in this specification scaling of the Besag precision matrix $\mathbf{Q}$ is not taken into account despite this issue being particularly pertinent when dealing with multiple sources of noise.
In particular, placing a joint prior $(\tau_v, \tau_w) \sim p(\tau_v, \tau_w)$ which doesn't privilege either component is more easily accomplished if $\mathbf{Q}$ and $\mathbf{I}$ have the same scale.
Additionally, supposing we have a prior belief that the over-dispersion is primarily IID and $\mathbf{v}$ accounts for the majority of the dispersion, then it is not immediately obvious how to represent this belief using $p(\tau_v, \tau_w)$, without inadvertently altering the prior about the overall variation.
This highlights identifiability issues of the parameters $(\tau_v, \tau_w)$ resulting from them not being orthogonal.
Building on the models of @leroux2000estimation and @dean2001detecting which tackle this identifiability problem, but do not scale the spatially structured noise, @simpson2017penalising propose a reparameterisation $(\tau_v, \tau_w) \mapsto (\tau_u, \phi)$ of the BYM model known as the BYM2 model and given by
\begin{align}
\mathbf{u} = \frac{1}{\tau_u} \left( \sqrt{1- \phi} \, \mathbf{v} + \sqrt{\phi} \, \mathbf{w}^\star \right), (\#eq:bym2)
\end{align}
where $\tau_u$ is the marginal precision of $\mathbf{u}$, $\phi \in [0, 1]$ gives the proportion of the marginal variance explained by each component, and $\mathbf{w}^\star$ is a scaled version of $\mathbf{w}$ with precision matrix given by the scaled structure matrix $\mathbf{R}^\star$.
When $\phi = 0$ the random effects are IID, and when $\phi = 1$ the random effects follow the Besag model.
To borrow an analogy [@rue2020comment] the parameterisation $(\tau_v, \tau_w)$ is like having one hot water and one cold water tap, whereas the parameterisation $(\tau_u, \phi)$ is like a mixer tap where the amount of water and its temperature can be adjusted separately.

### Concerns about the Besag model's representation of space

The Besag model was originally proposed for use in image analysis, where areas correspond to pixels arranged in a regular lattice structure.
Since then, it has seen wider use, including in situations, like small-area estimation of HIV, where the spatial structure is less regular.
As such, I have a number of concerns about the model's applicability to this broader setting.
This discussion is closely linked to the modifiable areal unit problem [@openshow1979million], whereby statistical conclusions change as a result of seemingly arbitrary changes in data aggregation, as well as the challenge of ecological inference and the ecological fallacy [@wakefield2010aggregation].

(ref:maup1) Figure caption.

```{r maup1, fig.cap="(ref:maup1)"}
knitr::include_graphics(paste0("resources/beyond-borders/", resource_version, "/depends/maup1.pdf"))
```

(ref:maup2) Figure caption.

```{r maup2, fig.cap="(ref:maup2)"}
knitr::include_graphics(paste0("resources/beyond-borders/", resource_version, "/depends/maup2.pdf"))
```

(ref:maup3) Figure caption.

```{r maup3, fig.cap="(ref:maup3)"}
knitr::include_graphics(paste0("resources/beyond-borders/", resource_version, "/depends/maup3.pdf"))
```

#### Adjacency compression

Summarising a geometry by an adjacency graph represents a loss of information.
Many geometries share the same adjacency graph, and are as such isomorphic identical under the Besag model (Figure).
This is not in itself a problem, but does prompt consideration as to whether the class of geometries with the same adjacency graph is sufficiently similar to merit identical models.^[The regularity of realistic geometries may help to constrain each class to be more similar than it strictly has to be. In other words, although pathological geometries can be constructed, they are implausible in statistical practise and so not of great concern to us here.]
Intuitively, the more regular the spatial structure, the less information is lost in compression to an adjacency graph.
In image analysis, very little spatial information is lost in compression of a lattice structure to an adjacency graph.
On the other hand, the regions of a country, determined by political and geographic forces, tend to display greater irregularity.
The appropriateness of adjacency compression therefore varies by the type of geometry common to the application setting.

#### Mean structure

In the Besag model is all adjacent areas count equally.
This assumption is unsatisfying: for most geometries, we expect different amounts of correlation between neighbours.
Figure illustrates a number of heuristic features for neighbour importance, including length of shared border, and the proximity of centers of mass.

#### Variance structure

In Equation \@ref(eq:besag) the precision of $u_i$ is proportional to its number of neighbours $n_{\delta i}$.
It follow that as $n_{\delta i} \to \infty$ then $\text{Var}(u_i) \to 0$.
This is illustrated by Figure where the area on the right is repeatedly divided such that its number of neighbours increases.
This property is a consequence of averaging the conditional mean over a greater number of areas, which, in certain situations, can correspond to a greater amount of information.
However, if the amount of information in the shaded area remains fixed, it is inappropriate that $\text{Var}(u_1)$ should tend to zero as a result of drawing additional, arbitrary, boundaries.
In the image analysis setting this modelling assumption is reasonable: each pixel represents a fixed amount of information and a higher pixel density represents a greater amount of information.
On the other hand, in public health and epidemiology, drawing boundaries to create additional areas is not expected to correspond to a greater amount of information.

Suppose we fit a Besag model upon identical data using each of the two geometries in Figure.
If the spatial variation is relatively smooth, dividing the shaded areas into two will result in a lower estimated variance $\sigma^2_u$ in geometry (ii) as compared with geometry (i) because there will appear to be less variation between neighbouring areas.
This problem does not only apply locally: since the effect of $\sigma^2_u$ applies everywhere, the smoothing will change even in unaltered parts of the study region.

## Models using kernels

## Simulation study

## HIV prevalence study

## Discussion
