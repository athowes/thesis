---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    citation_package: biblatex
  bookdown::html_document2: default
  bookdown::word_document2: default
documentclass: book
bibliography: references.bib
---

```{r}
resource_version <- "temp"
```

# Models for spatial structure {#beyond-borders}
\adjustmtc
\markboth{Models for spatial structure}{}
<!-- For PDF output, include these two LaTeX commands after unnumbered chapter headings, otherwise the mini table of contents and the running header will show the previous chapter -->

This chapter presents an investigation of spatial random effects specifications for areal data.
The investigation was motivated by a question that often occurs during model construction.
Namely, should the model be expanded to capture a sensible, albeit hypothetical, feature of the data?

The hypothesised feature in this case pertains to the spatial correlation structure between areas.
Modelling of spatial variation is particularly important for the small-area estimation of HIV.
This is because the covariates which are most strongly associated with HIV are difficult to measure.
Examples include sexual risk behaviour.
As a result, in previous small-area models of HIV have found including including covariates to only result in a modest improvement in predictive performance [Supplementary Figure 20, @dwyer2019mapping].
The lack of predictive covariates foregrounds the role of modelling spatial variation.
For mapping of other infectious diseases, such as Malaria where transmission is driven by more predictive and easily-measurable environmental factors, explanatory covariates are more easily available and modelling spatial variation is less pertinent [@weiss2015re].

Spatial variation in areal data are often modelled using spatial random effects [@haining2003spatial; @cramb2018investigation].
The most common class of models used to specify spatial random effects are Gaussian Markov random fields [GMRFs; @rue2005gaussian].
These models combine a Gaussian distribution with Markov conditional independence assumptions between areas.
Observations made in areas close together are assumed to be correlated, and more distant relationships are ignored.
Perhaps the simplest GMRF model is that of @besag1991bayesian in which information is borrowed equally from each adjacent area, based on a binary relationship.
The Besag model is attractive as it requires minimal additional modelling choices and is accessibly implemented.
It has been widely used, including:

* to model bird population dynamics from capute-recapture data [@saracco2010modeling];
* for the analysis of magnetic resonance images [@gossl2001bayesian; @schmid2006bayesian];
* to model alcohol use patterns [@dwyer2015drinking].

The Besag model was designed for use in image analysis, on a regular grid.
However, for more irregular geometries, the assumptions made are unrealistic and appear to be violated.
The administrative divisions of a country used in small-area estimation are one example of a more irregular geometry.
This chapter tests the hypothesis that using more realistic assumptions about spatial structure would improve the performance of small-area estimation models.
In doing so, it offers practical recommendations for modelling areal spatial structure.
The results are presented in @howes2023beyond.
Code for the analysis in this chapter is available from [`https://github.com/athowes/beyond-borders`](https://github.com/athowes/beyond-borders).

## Models based on adjacency {#adjacency}

This section discusses spatial random effect models based on an symmetric adjacency relation $i \sim j$ between areas $A_i$ and $A_j$.
Adjacency is typically defined by a shared border, though other choices are possible [@paciorek2013spatial].

### The Besag model

(ref:geometry-graph) Panel A shows the districts of Zimbabwe. Panel B shows the corresponding adjacency graph structure $\mathcal{G}$, with nodes positioned in alignment with the district that they correspond to.

```{r geometry-graph, fig.cap="(ref:geometry-graph)"}
knitr::include_graphics("figures/beyond-borders/geometry-graph.png")
```

The Besag model [@besag1991bayesian] is an improper conditional auto-regressive (ICAR) model where the full conditional distribution of the $i$th spatial random effect is given by
\begin{equation}
    u_i \, | \, \mathbf{u}_{-i} \sim \mathcal{N} \left(\frac{1}{n_{\delta i}} \sum_{j: j \sim i} u_j, \frac{1}{n_{\delta i}\tau_u}\right), (\#eq:besag)
\end{equation}
where $\delta i$ is the set of neighbours of $A_i$ with cardinality $n_{\delta i} = |\delta i|$ and $\mathbf{u}_{-i}$ is the vector of spatial random effects with the $i$th entry removed.
The conditional mean of the random effect $u_i$ is the average of its neighbours $\{u_j\}_{j \sim i}$ and the precision $n_{\delta i}\tau_u$ is proportional to the number of neighbours $n_{\delta i}$.
By Brook's lemma [@rue2005gaussian] the set of full conditionals of the Besag model are equivalent to the Gaussian Markov random field (GMRF) given by
\begin{equation}
    \mathbf{u} \sim \mathcal{N}(\mathbf{0}, \tau_u^{-1} \mathbf{R}^{-}). (\#eq:gmrf)
\end{equation}
The matrix $\mathbf{R}^{-}$ is the generalised inverse of the rank-deficient structure matrix $\mathbf{R}$ with entries
\begin{equation}
    R_{ij} =
    \begin{cases}
        n_{\delta i}, & i = j \\
        -1, & i \sim j \\
        0, & \text{otherwise.}
    \end{cases}
\end{equation}
The Markov property arises due to the conditional independence structure $p(u_i \, | \, \mathbf{u}_{-i}) = p(u_i \, | \, \mathbf{u}_{\delta i})$ whereby each area only depends on its neighbours.
This is reflected in the sparsity of $\mathbf{R}$ such that $u_i \perp u_j \, | \, \mathbf{u}_{-ij}$ if and only if $R_{ij} = 0$.
The structure matrix $\mathbf{R}$ may also be expressed as the Laplacian matrix of the adjacency graph $\mathcal{G} = (\mathcal{V}, \mathcal{E})$ with vertices $v \in \mathcal{V}$ corresponding to each area and edges $e \in \mathcal{E}$ between vertices $i$ and $j$ when $i \sim j$.
Figure \@ref(fig:geometry-graph) shows the adjacency graph for the districts of Zimbabwe.

Rewriting Equation \@ref(eq:gmrf), the probability density function of $\mathbf{u}$ is
\begin{equation}
    p(\mathbf{u})
    \propto \exp \left( -\frac{\tau_u}{2} \mathbf{u}^\top \mathbf{R} \mathbf{u} \right)
    \propto \exp \left( -\frac{\tau_u}{2} \sum_{i \sim j} (u_i - u_j)^2 \right). (\#eq:pdfu)
\end{equation}
This density is a function of the pairwise differences $u_i - u_j$ and so is invariant to the addition of a constant $c$ to each entry $p(\mathbf{u}) = p(\mathbf{u} + c\mathbf{1})$.
As a result, there is an improper uniform distribution on the average of the $u_i$.
If $\mathcal{G}$ is connected, in that by traversing the edges, any vertex can be reached from any other vertex, then there is only one impropriety in the model and $\text{rank}(\mathbf{R}) = n - 1$, while if $\mathcal{G}$ is disconnected, and composed of $n_c \geq 2$ connected components with index sets $I_1, \ldots, I_{n_c}$, then the corresponding structure matrix $\mathbf{R}$ has rank $n - n_c$ and the density is invariant to the addition of a constant to each of the connected components $p(\mathbf{u}_{I}) = p(\mathbf{u}_{I} + c\mathbf{1})$ where $I = I_1, \ldots, I_{n_c}$.

### Best practises for the Besag model

@freni2018note recommended three best practices:

1. The structure matrix $\mathbf{R}$ should be rescaled to have generalised variance equal to one. 
The generalised variance is defined by the geometric mean of the diagonal elements of its generalised inverse
\begin{equation}
    \sigma^2_{\text{GV}}(\mathbf{R}) = \prod_{i = 1}^n (\mathbf{R}^-_{ii})^{1/n} = \exp \left( \frac{1}{n} \sum_{i = 1}^n \log (R^-_{ii}) \right).
\end{equation}
The structure matrix $\mathbf{R}$ may be replaced by
\begin{equation}
\mathbf{R}^\star = \mathbf{R} / \sigma^2_{\text{GV}}(\mathbf{R}).
\end{equation}
As the diagonal elements $R^-_{ii}$ correspond to marginal variances, the generalised variance gives a measure of the average marginal variance.
This measure, introduced by @sorbye2014scaling, ignores off-diagonal entries and more broadly any measure of typical variance could be used.
Scaling mitigates the influence of the adjacency graph on the variance of $\mathbf{u}$.
Allowing the variance to be controlled by $\tau_u$ alone is important as it allows for consistent, interpretable prior selection.

    When the adjacency graph is disconnected it is not appropriate to scale the structure matrix $\mathbf{R}$ uniformly for the reason that given the precision $\tau_u$, local smoothing operates on each connected component independently.
    As such, each connected component should be scaled independently to have generalised variance one giving
    \begin{equation}
      \mathbf{R}^\star_I = \mathbf{R}_I / \sigma^2_{\text{GV}}(\mathbf{R}_I)
    \end{equation}
    where $\mathbf{R}_I$ is the sub-matrix of the structure matrix corresponding to index set $I$.

2. When one of the connected components is a single area (known either as a singleton or an island) the probability density
\begin{equation}
  p(u_i) \propto  \exp \left( -\frac{\tau_u}{2} \sum_{i \sim j} (u_i - u_j)^2 \right)
\end{equation}
has no dependence on $u_i$.
This is equivalent to using an improper prior $p(u_i) \propto 1$.
To avoid this, each singleton can be set to have independent Gaussian noise $p(u_i) \sim \mathcal{N}(0, 1)$.

3. To avoid confounding of the spatial random effects with the intercept, it is recommended to place a sum-to-zero constraint on each non-singleton connected component.
In other words,
\begin{equation}
  \sum_{i \in I} u_i = 0, \quad |I| > 1.
\end{equation}

### The reparameterised Besag-York-Molli√© model

Often, as well as spatial structure, there exists IID over-dispersion in the residuals and it is inappropriate to use purely spatially structured random effects in the model.
The Besag-York-Molli√© (BYM) model of @besag1991bayesian accounts for this in a natural way by decomposing the spatial random effect $\mathbf{u} = \mathbf{v} + \mathbf{w}$ into a sum of an unstructured IID component $\mathbf{v}$ and a spatially structured Besag component $\mathbf{w}$, each of which with their own respective precision parameters $\tau_v$ and $\tau_w$.
The resulting distribution is
\begin{equation}
    \mathbf{u} \sim \mathcal{N}(0, \tau_v^{-1} \mathbf{I} + \tau_w^{-1} \mathbf{R}^{-}) (\#eq:bym).
\end{equation}
Including both $\mathbf{v}$ and $\mathbf{w}$ is intended to enable the model to learn the relative extent of the unstructured and structured components via $\tau_v$ and $\tau_w$.
However, in this specification scaling of the Besag precision matrix $\mathbf{Q}$ is not taken into account despite this issue being particularly pertinent when dealing with multiple sources of noise.
In particular, placing a joint prior $(\tau_v, \tau_w) \sim p(\tau_v, \tau_w)$ which doesn't privilege either component is more easily accomplished if $\mathbf{Q}$ and $\mathbf{I}$ have the same scale.
Additionally, supposing we have a prior belief that the over-dispersion is primarily IID and $\mathbf{v}$ accounts for the majority of the dispersion, then it is not immediately obvious how to represent this belief using $p(\tau_v, \tau_w)$, without inadvertently altering the prior about the overall variation.
This highlights identifiability issues of the parameters $(\tau_v, \tau_w)$ resulting from them not being orthogonal.
Building on the models of @leroux2000estimation and @dean2001detecting which tackle this identifiability problem, but do not scale the spatially structured noise, @simpson2017penalising propose a reparameterisation $(\tau_v, \tau_w) \mapsto (\tau_u, \phi)$ of the BYM model known as the BYM2 model and given by
\begin{align}
\mathbf{u} = \frac{1}{\tau_u} \left( \sqrt{1- \phi} \, \mathbf{v} + \sqrt{\phi} \, \mathbf{w}^\star \right), (\#eq:bym2)
\end{align}
where $\tau_u$ is the marginal precision of $\mathbf{u}$, $\phi \in [0, 1]$ gives the proportion of the marginal variance explained by each component, and $\mathbf{w}^\star$ is a scaled version of $\mathbf{w}$ with precision matrix given by the scaled structure matrix $\mathbf{R}^\star$.
When $\phi = 0$ the random effects are IID, and when $\phi = 1$ the random effects follow the Besag model.
To borrow an analogy [@rue2020comment] the parameterisation $(\tau_v, \tau_w)$ is like having one hot water and one cold water tap, whereas the parameterisation $(\tau_u, \phi)$ is like a mixer tap where the amount of water and its temperature can be adjusted separately.

### Concerns about the Besag model's spatial representation

The Besag model was originally proposed for use in image analysis, where areas correspond to pixels arranged in a regular lattice structure.
Since then, it has seen wider use, including in situations, like small-area estimation of HIV, where the spatial structure is less regular.
As such, I have a number of concerns about the model's applicability to this broader setting.
This discussion is closely linked to the modifiable areal unit problem [@openshow1979million], whereby statistical conclusions change as a result of seemingly arbitrary changes in data aggregation, as well as the challenge of ecological inference and the ecological fallacy [@wakefield2010aggregation].

(ref:maup1) Though they are quite different, the geometries shown in panels A, B, C, and D each have the same adjacency graph.

```{r maup1, fig.cap="(ref:maup1)"}
knitr::include_graphics("figures/beyond-borders/maup1.png")
```

(ref:maup2) A sequence of geometries where the number of neighbours of area one grows by one at each iteration.

```{r maup2, fig.cap="(ref:maup2)"}
knitr::include_graphics("figures/beyond-borders/maup2.png")
```

(ref:maup3) Each of the shaded areas are split into two moving from Panel A to Panel B.

```{r maup3, fig.cap="(ref:maup3)"}
knitr::include_graphics("figures/beyond-borders/maup3.png")
```

#### Adjacency compression

Summarising a geometry by an adjacency graph represents a loss of information.
Many geometries share the same adjacency graph, and are as such isomorphic identical under the Besag model (Figure).
This is not in itself a problem, but does prompt consideration as to whether the class of geometries with the same adjacency graph is sufficiently similar to merit identical models.^[The regularity of realistic geometries may help to constrain each class to be more similar than it strictly has to be. In other words, although pathological geometries can be constructed, they are implausible in statistical practise and so not of great concern to us here.]
Intuitively, the more regular the spatial structure, the less information is lost in compression to an adjacency graph.
In image analysis, very little spatial information is lost in compression of a lattice structure to an adjacency graph.
On the other hand, the regions of a country, determined by political and geographic forces, tend to display greater irregularity.
The appropriateness of adjacency compression therefore varies by the type of geometry common to the application setting.

#### Mean structure

In the Besag model is all adjacent areas count equally.
This assumption is unsatisfying: for most geometries, we expect different amounts of correlation between neighbours.
Figure illustrates a number of heuristic features for neighbour importance, including length of shared border, and the proximity of centers of mass.

#### Variance structure

In Equation \@ref(eq:besag) the precision of $u_i$ is proportional to its number of neighbours $n_{\delta i}$.
It follow that as $n_{\delta i} \to \infty$ then $\text{Var}(u_i) \to 0$.
This is illustrated by Figure where the area on the right is repeatedly divided such that its number of neighbours increases.
This property is a consequence of averaging the conditional mean over a greater number of areas, which, in certain situations, can correspond to a greater amount of information.
However, if the amount of information in the shaded area remains fixed, it is inappropriate that $\text{Var}(u_1)$ should tend to zero as a result of drawing additional, arbitrary, boundaries.
In the image analysis setting this modelling assumption is reasonable: each pixel represents a fixed amount of information and a higher pixel density represents a greater amount of information.
On the other hand, in public health and epidemiology, drawing boundaries to create additional areas is not expected to correspond to a greater amount of information.

Suppose we fit a Besag model upon identical data using each of the two geometries in Figure.
If the spatial variation is relatively smooth, dividing the shaded areas into two will result in a lower estimated variance $\sigma^2_u$ in geometry (ii) as compared with geometry (i) because there will appear to be less variation between neighbouring areas.
This problem does not only apply locally: since the effect of $\sigma^2_u$ applies everywhere, the smoothing will change even in unaltered parts of the study region.

## Models using kernels

Section \@ref(adjacency) reviewed ways to construct spatial random effect precision matrices using an adjacency relation.
An alternate approach is to define the covariance matrix using an areal kernel function which gives a measure of similarity between two areas $K: \mathcal{P}(\Sc) \times \mathcal{P}(\Sc) \to \mathbb{R}$, where $\mathcal{P}$ denotes the power set such that $\mathcal{P}(\Sc)$ is the space of subsets of the study region.
If $K$ is positive semi-definite, then define areal kernel spatial random effects by
\begin{equation}
    \phi \sim \mathcal{N} \left( 0, \frac{1}{\tau_\phi} \mathbf{K} \right), \label{eq:arealkernel}
\end{equation}
where the $n \times n$ Gram matrix $\mathbf{K}$ with entries $K_{ij} = K(A_i, A_j)$ is a valid covariance matrix.
Here, the precision parameter $\tau_\phi$ is placed outside of the Gram matrix, analogous to the relation of the precision and structure matrices.
Most well-known spatial process models define the correlation structure between a pair of points using a kernel $k: \mathcal{S} \times \mathcal{S} \to \mathbb{R}$.
A simple method to construct $K$ from $k$ is to average the kernel $k$ computed on some collection of points from within each area.

### Centroid kernel

The simplest approach is to use a single point such that $K(A_i, A_j) = k(p_i, p_j)$.
A natural choice is the centroid $p_i = c_i$, given by the arithmetic mean of the latitude and longitude, which may be representative of the area.^[Note it is not guaranteed for the centroid to (even) lie within the area i.e. we may have $c_i \notin A_i$.]
This results in the centroid kernel
\begin{equation}
    K(A_i, A_j) = k(c_i, c_j).
\end{equation}
The centroid kernel has been used in environmental epidemiology [@wakefield1999spatial] and to model the reproduction number of COVID-19 [@teh2021efficient].
A model comparison study [Section 3; @best2005comparison] simulated data representing heterogeneous exposure to air pollution, including elevated rates of exposure near two hypothetical point source locations, and found that the centroid kernel tended to over-smooth the high-risk areas.
That said, it is unsuprising that a stationary covariance would struggle to recover non-stationary structure.

### Integrated kernel

Rather than choosing a single representative point, an alternative is to represent the whole area by integrating the kernel over the areas of interest.
This results in the integrated kernel
\begin{equation}
K(A_i, A_j) = \frac{1}{|A_i||A_j|} \int_{A_i} \int_{A_j} k(s, s') \text{d} s \text{d} s'. \label{eq:ik1}
\end{equation}
This covariance structure is equivalent to that obtained by aggregating a spatially continuous Gaussian process with kernel $k$ over the areal partition, and has been studied in the machine learning literature under the name aggregated Gaussian processes [@law2018variational; @tanaka2019spatially; @yousefi2019multi; @hamelijnck2019multi].
Unlike for the centroid kernel where $K_{ii} = 1$ for all $i$, the marginal variance of the $i$th spatial random effect $K_{ii} = K(A_i, A_i)$ varies depending on the area: becoming smaller for more compact areas and larger for areas which are of greater extent or more spread out.

#### Accounting for heterogeneity

Additional information accounting for heterogeneity over $A_i$ may be incorporated into the integrated kernel^[Analogously, weighted centroids could also be used in the centroid kernel.]
This can be accomplished using weighting distributions $\{W_i\}$ which represent an unequal contribution of each point to the similarity measure, to give a weighted integrated kernel
\begin{equation}
K(A_i, A_j) = \frac{1}{|A_i||A_j|}\int_{A_i} \int_{A_j} w_i(s) w_j(s') k(s, s') \text{d} s \text{d} s', \label{eq:ik2}
\end{equation}
This may be useful in disease mapping, where we expect regions with populations who live close to their shared border to be more strongly correlated than regions whose populations live far apart, which could be accounted for by weighting according to a high resolution measure of population density.

#### Computation

Most of the time we do not expect to be able to calculate Equation \ref{eq:ik2} analytically.
Instead, given $n$ collections of $L_i$ samples $\{s^{(i)}_l \}_{l = 1}^{L_i} \sim \mathcal{U}(A_i)$ drawn uniformly from each area then the integral may be approximated using Monte Carlo by the double sum
\begin{equation}
K(A_i, A_j) \approx \frac{1}{L_i L_j} \sum_{l = 1}^{L_i} \sum_{m = 1}^{L_j}
w_i \left( s^{(i)}_l \right) w_j \left( s^{(j)}_m \right)
k \left( s^{(i)}_l, s^{(j)}_m \right). \label{eq:mcintegratedkernel}
\end{equation}
Equivalently, samples drawn from $W_i$ may be used without weighting by $w_i(s)$.
Nodes may also be selected deterministically to give a numerical quadrature estimate of the kernel.
These approaches require $\mathcal{O}(\sum_{i = 1}^n \sum_{j = 1}^n L_i L_j)$ evaluations of the kernel $k$ to compute the $n \times n$ Gram matrix $K$.
This imposes a significant computational cost if the Gram matrix is often recomputed during inference, as is the case in MCMC when any of the kernel hyperparameters are learnt, placing a limit on the number of samples or nodes it is feasible to use.
@kelsall2002modeling make inference more feasible by using a discrete hyperparameter prior to reduce the number of Gram matrix constructions and inversions required.

#### Mismatch to data generating process

Aggregation via the integrated kernel occurs at the level of the latent field rather than at the level of the data.
<!-- This corresponds to a generative model of the form $y_i \sim p(y_i \, | \,  g^{-1}(x_i))$, with $x_i = |A_i|^{-1}\int_{A_i} x(s) \text{d} s$. -->
If the link function $g$ is the identity or linear then aggregation at the level of the latent field is equivalent to aggregation at the level of the data.
On the other hand, for non-linear link functions $g$ such as the commonly used exponential or logistic, the generative model does not match the proposed data generating process.
<!-- Add equations for mean $\mathbb{E}(y_i)$ and variance $\mathbb{V}(y_i)$ of under this model, as a function of $g$. -->
<!-- Explain under what circumstances we believe this approximation to be acceptable. -->

#### Log-Gaussian Cox processes

The log-Gaussian Cox Process framework [@diggle2013spatial] arrives naturally at the integrated kernel formulation.
A Cox process is an inhomogeneous Poisson process with a continuous stochastic intensity function $\{ x(s), s \in \Sc \}$ such that conditional on the realisation of $x(s)$ the number of points in any area $A_i$ follows a Poisson distribution.
The rate parameter of this Poisson distribution is explicitly aggregated as follows
\begin{equation}
y_i \, | \, x(s) \sim \text{Poisson} \left(\int_{s \in A_i} x(s) \text{d}s \right).
\end{equation}
In a LGCP the log intensity $\log x(s) = \eta(s)$ is modelled using a Gaussian process prior $\eta(s) \sim \mathcal{GP}(\mu(s), k(s, s'))$.
@johnson2019spatially obtain Equation \ref{eq:ik2} by considering a discrete Poisson log-linear mixed model approximation to a continuous LGCP, whereby $\eta(s)$ is approximated by a piecewise constant $\eta_i = \mu_i + \phi_i$ in each area $A_i$.
The $i$th discrete spatial random effect is then $\phi_i = \int_{A_i} w_i(s) \phi(s) \text{d}s$,
with covariance structure
\begin{equation}
\text{Cov} \left( \int_{A_i} w_i(s) \phi(s) \text{d}s, \int_{A_j} w_j(s') \phi(s') \text{d}s' \right)
= \int_{A_i} \int_{A_j} w_i(s) w_j(s') k(s, s') \text{d}s\text{d}s',
\end{equation}
corresponding to an areal integrated kernel with a logarithmic link function and Poisson likelihood.

<!-- Discuss Gary's paper here? [@konstantinoudis2020discrete] -->

#### Disaggregation regression

Disaggregation regression, also known as downscaling or interpolation, is another closely related approach.
Rather than focusing on the aggregate nature of areal observations as primarily a route towards better area-level estimates, disaggregation regression aims to produce high-resolution or point-level estimates from areal observations [@utazi2019spatial; @nandi2023disaggregation].
<!-- Accurate point-level estimates are close to being a necessary intermediate goal towards obtaining accurate area-level estimates. -->
<!-- Disaggregation is challenging without auxiliary information. -->
<!-- A unified view on Bayesian varying coefficient models by Franco-Villoria et al. -->

### The stochastic partial differential equation approximation

This is a more computationally efficient way to implement integrated kernels.

## Simulation study

We tested the ability of inferential models with varying spatial random effect specifications to accurately recover small-area quantities.
The data and modelling choices were designed with a spatial epidemiology setting in mind.

### Synthetic data-sets

## HIV prevalence study

## Discussion

@follestad2003modelling