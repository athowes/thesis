<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Fast approximate Bayesian inference | Bayesian spatio-temporal methods for small-area estimation of HIV indicators</title>
  <meta name="description" content="6 Fast approximate Bayesian inference | Bayesian spatio-temporal methods for small-area estimation of HIV indicators" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Fast approximate Bayesian inference | Bayesian spatio-temporal methods for small-area estimation of HIV indicators" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Fast approximate Bayesian inference | Bayesian spatio-temporal methods for small-area estimation of HIV indicators" />
  
  
  

<meta name="author" content="Adam Howes" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multi-agyw.html"/>
<link rel="next" href="conclusions.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="templates/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#chapter-overview"><i class="fa fa-check"></i><b>1.1</b> Chapter overview</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hiv-aids.html"><a href="hiv-aids.html"><i class="fa fa-check"></i><b>2</b> The HIV/AIDS epidemic</a>
<ul>
<li class="chapter" data-level="2.1" data-path="hiv-aids.html"><a href="hiv-aids.html#background"><i class="fa fa-check"></i><b>2.1</b> Background</a></li>
<li class="chapter" data-level="2.2" data-path="hiv-aids.html"><a href="hiv-aids.html#surveillance"><i class="fa fa-check"></i><b>2.2</b> HIV surveillance</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="hiv-aids.html"><a href="hiv-aids.html#data"><i class="fa fa-check"></i><b>2.2.1</b> Data</a></li>
<li class="chapter" data-level="2.2.2" data-path="hiv-aids.html"><a href="hiv-aids.html#challenges"><i class="fa fa-check"></i><b>2.2.2</b> Challenges</a></li>
<li class="chapter" data-level="2.2.3" data-path="hiv-aids.html"><a href="hiv-aids.html#statistical-approaches"><i class="fa fa-check"></i><b>2.2.3</b> Statistical approaches</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayes-st.html"><a href="bayes-st.html"><i class="fa fa-check"></i><b>3</b> Bayesian spatio-temporal statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayes-st.html"><a href="bayes-st.html#bayesian-statistics"><i class="fa fa-check"></i><b>3.1</b> Bayesian statistics</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="bayes-st.html"><a href="bayes-st.html#bayesian-modelling"><i class="fa fa-check"></i><b>3.1.1</b> Bayesian modelling</a></li>
<li class="chapter" data-level="3.1.2" data-path="bayes-st.html"><a href="bayes-st.html#bayesian-computation"><i class="fa fa-check"></i><b>3.1.2</b> Bayesian computation</a></li>
<li class="chapter" data-level="3.1.3" data-path="bayes-st.html"><a href="bayes-st.html#interplay-between-modelling-and-computation"><i class="fa fa-check"></i><b>3.1.3</b> Interplay between modelling and computation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="bayes-st.html"><a href="bayes-st.html#spatio-temporal-statistics"><i class="fa fa-check"></i><b>3.2</b> Spatio-temporal statistics</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="bayes-st.html"><a href="bayes-st.html#properties-of-spatio-temporal-data"><i class="fa fa-check"></i><b>3.2.1</b> Properties of spatio-temporal data</a></li>
<li class="chapter" data-level="3.2.2" data-path="bayes-st.html"><a href="bayes-st.html#small-area-estimation"><i class="fa fa-check"></i><b>3.2.2</b> Small-area estimation</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="bayes-st.html"><a href="bayes-st.html#hierarchical-lgm-elgm"><i class="fa fa-check"></i><b>3.3</b> Model structure</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="bayes-st.html"><a href="bayes-st.html#linear-model"><i class="fa fa-check"></i><b>3.3.1</b> Linear model</a></li>
<li class="chapter" data-level="3.3.2" data-path="bayes-st.html"><a href="bayes-st.html#generalised-linear-model"><i class="fa fa-check"></i><b>3.3.2</b> Generalised linear model</a></li>
<li class="chapter" data-level="3.3.3" data-path="bayes-st.html"><a href="bayes-st.html#hierarchical"><i class="fa fa-check"></i><b>3.3.3</b> Hierarchical models</a></li>
<li class="chapter" data-level="3.3.4" data-path="bayes-st.html"><a href="bayes-st.html#generalised-linear-mixed-effects-model"><i class="fa fa-check"></i><b>3.3.4</b> Generalised linear mixed effects model</a></li>
<li class="chapter" data-level="3.3.5" data-path="bayes-st.html"><a href="bayes-st.html#lgm"><i class="fa fa-check"></i><b>3.3.5</b> Latent Gaussian model</a></li>
<li class="chapter" data-level="3.3.6" data-path="bayes-st.html"><a href="bayes-st.html#elgm"><i class="fa fa-check"></i><b>3.3.6</b> Extended latent Gaussian model</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="bayes-st.html"><a href="bayes-st.html#model-comparison"><i class="fa fa-check"></i><b>3.4</b> Model comparison</a></li>
<li class="chapter" data-level="3.5" data-path="bayes-st.html"><a href="bayes-st.html#survey"><i class="fa fa-check"></i><b>3.5</b> Survey methods</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="bayes-st.html"><a href="bayes-st.html#survey-notation-and-key-terms"><i class="fa fa-check"></i><b>3.5.1</b> Survey notation and key terms</a></li>
<li class="chapter" data-level="3.5.2" data-path="bayes-st.html"><a href="bayes-st.html#survey-design"><i class="fa fa-check"></i><b>3.5.2</b> Survey design</a></li>
<li class="chapter" data-level="3.5.3" data-path="bayes-st.html"><a href="bayes-st.html#survey-analysis"><i class="fa fa-check"></i><b>3.5.3</b> Survey analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="beyond-borders.html"><a href="beyond-borders.html"><i class="fa fa-check"></i><b>4</b> Models for spatial structure</a>
<ul>
<li class="chapter" data-level="4.1" data-path="beyond-borders.html"><a href="beyond-borders.html#background-1"><i class="fa fa-check"></i><b>4.1</b> Background</a></li>
<li class="chapter" data-level="4.2" data-path="beyond-borders.html"><a href="beyond-borders.html#adjacency"><i class="fa fa-check"></i><b>4.2</b> Models based on adjacency</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="beyond-borders.html"><a href="beyond-borders.html#the-besag-model"><i class="fa fa-check"></i><b>4.2.1</b> The Besag model</a></li>
<li class="chapter" data-level="4.2.2" data-path="beyond-borders.html"><a href="beyond-borders.html#best-practises-for-the-besag-model"><i class="fa fa-check"></i><b>4.2.2</b> Best practises for the Besag model</a></li>
<li class="chapter" data-level="4.2.3" data-path="beyond-borders.html"><a href="beyond-borders.html#the-reparameterised-besag-york-mollié-model"><i class="fa fa-check"></i><b>4.2.3</b> The reparameterised Besag-York-Mollié model</a></li>
<li class="chapter" data-level="4.2.4" data-path="beyond-borders.html"><a href="beyond-borders.html#concerns-about-the-besag-models-spatial-representation"><i class="fa fa-check"></i><b>4.2.4</b> Concerns about the Besag model’s spatial representation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="beyond-borders.html"><a href="beyond-borders.html#models-using-kernels"><i class="fa fa-check"></i><b>4.3</b> Models using kernels</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="beyond-borders.html"><a href="beyond-borders.html#centroid-kernel"><i class="fa fa-check"></i><b>4.3.1</b> Centroid kernel</a></li>
<li class="chapter" data-level="4.3.2" data-path="beyond-borders.html"><a href="beyond-borders.html#integrated-kernel"><i class="fa fa-check"></i><b>4.3.2</b> Integrated kernel</a></li>
<li class="chapter" data-level="4.3.3" data-path="beyond-borders.html"><a href="beyond-borders.html#the-stochastic-partial-differential-equation-approximation"><i class="fa fa-check"></i><b>4.3.3</b> The stochastic partial differential equation approximation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="beyond-borders.html"><a href="beyond-borders.html#simulation-study"><i class="fa fa-check"></i><b>4.4</b> Simulation study</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="beyond-borders.html"><a href="beyond-borders.html#synthetic-data-sets"><i class="fa fa-check"></i><b>4.4.1</b> Synthetic data-sets</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="beyond-borders.html"><a href="beyond-borders.html#hiv-prevalence-study"><i class="fa fa-check"></i><b>4.5</b> HIV prevalence study</a></li>
<li class="chapter" data-level="4.6" data-path="beyond-borders.html"><a href="beyond-borders.html#discussion"><i class="fa fa-check"></i><b>4.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multi-agyw.html"><a href="multi-agyw.html"><i class="fa fa-check"></i><b>5</b> A model for risk group proportions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="multi-agyw.html"><a href="multi-agyw.html#background-2"><i class="fa fa-check"></i><b>5.1</b> Background</a></li>
<li class="chapter" data-level="5.2" data-path="multi-agyw.html"><a href="multi-agyw.html#data-1"><i class="fa fa-check"></i><b>5.2</b> Data</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="multi-agyw.html"><a href="multi-agyw.html#behavioural-data-from-household-surveys"><i class="fa fa-check"></i><b>5.2.1</b> Behavioural data from household surveys</a></li>
<li class="chapter" data-level="5.2.2" data-path="multi-agyw.html"><a href="multi-agyw.html#other-data"><i class="fa fa-check"></i><b>5.2.2</b> Other data</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="multi-agyw.html"><a href="multi-agyw.html#model-for-risk-group-proportions"><i class="fa fa-check"></i><b>5.3</b> Model for risk group proportions</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="multi-agyw.html"><a href="multi-agyw.html#st-multinomial"><i class="fa fa-check"></i><b>5.3.1</b> Spatio-temporal multinomial logistic regression</a></li>
<li class="chapter" data-level="5.3.2" data-path="multi-agyw.html"><a href="multi-agyw.html#s-logistic"><i class="fa fa-check"></i><b>5.3.2</b> Spatial logistic regression</a></li>
<li class="chapter" data-level="5.3.3" data-path="multi-agyw.html"><a href="multi-agyw.html#model-combination"><i class="fa fa-check"></i><b>5.3.3</b> Model combination</a></li>
<li class="chapter" data-level="5.3.4" data-path="multi-agyw.html"><a href="multi-agyw.html#female-sex-worker-population-size-adjustment"><i class="fa fa-check"></i><b>5.3.4</b> Female sex worker population size adjustment</a></li>
<li class="chapter" data-level="5.3.5" data-path="multi-agyw.html"><a href="multi-agyw.html#results"><i class="fa fa-check"></i><b>5.3.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multi-agyw.html"><a href="multi-agyw.html#prevalence-and-incidence-by-risk-group"><i class="fa fa-check"></i><b>5.4</b> Prevalence and incidence by risk group</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="multi-agyw.html"><a href="multi-agyw.html#disaggregation-of-naomi-prevalence-estimates"><i class="fa fa-check"></i><b>5.4.1</b> Disaggregation of Naomi prevalence estimates</a></li>
<li class="chapter" data-level="5.4.2" data-path="multi-agyw.html"><a href="multi-agyw.html#disaggregation-of-naomi-incidence-estimates"><i class="fa fa-check"></i><b>5.4.2</b> Disaggregation of Naomi incidence estimates</a></li>
<li class="chapter" data-level="5.4.3" data-path="multi-agyw.html"><a href="multi-agyw.html#expected-new-infections-reached"><i class="fa fa-check"></i><b>5.4.3</b> Expected new infections reached</a></li>
<li class="chapter" data-level="5.4.4" data-path="multi-agyw.html"><a href="multi-agyw.html#results-1"><i class="fa fa-check"></i><b>5.4.4</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multi-agyw.html"><a href="multi-agyw.html#discussion-1"><i class="fa fa-check"></i><b>5.5</b> Discussion</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="multi-agyw.html"><a href="multi-agyw.html#limitations"><i class="fa fa-check"></i><b>5.5.1</b> Limitations</a></li>
<li class="chapter" data-level="5.5.2" data-path="multi-agyw.html"><a href="multi-agyw.html#conclusion"><i class="fa fa-check"></i><b>5.5.2</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="naomi-aghq.html"><a href="naomi-aghq.html"><i class="fa fa-check"></i><b>6</b> Fast approximate Bayesian inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="naomi-aghq.html"><a href="naomi-aghq.html#inference-methods-and-software"><i class="fa fa-check"></i><b>6.1</b> Inference methods and software</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="naomi-aghq.html"><a href="naomi-aghq.html#la"><i class="fa fa-check"></i><b>6.1.1</b> The Laplace approximation</a></li>
<li class="chapter" data-level="6.1.2" data-path="naomi-aghq.html"><a href="naomi-aghq.html#quadrature"><i class="fa fa-check"></i><b>6.1.2</b> Quadrature</a></li>
<li class="chapter" data-level="6.1.3" data-path="naomi-aghq.html"><a href="naomi-aghq.html#inla"><i class="fa fa-check"></i><b>6.1.3</b> Integrated nested Laplace approximation</a></li>
<li class="chapter" data-level="6.1.4" data-path="naomi-aghq.html"><a href="naomi-aghq.html#software"><i class="fa fa-check"></i><b>6.1.4</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="naomi-aghq.html"><a href="naomi-aghq.html#universal"><i class="fa fa-check"></i><b>6.2</b> A universal INLA implementation</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="naomi-aghq.html"><a href="naomi-aghq.html#epil"><i class="fa fa-check"></i><b>6.2.1</b> Epilepsy GLMM</a></li>
<li class="chapter" data-level="6.2.2" data-path="naomi-aghq.html"><a href="naomi-aghq.html#unknown"><i class="fa fa-check"></i><b>6.2.2</b> An example that <code>R-INLA</code> doesn’t work for</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="naomi-aghq.html"><a href="naomi-aghq.html#naomi"><i class="fa fa-check"></i><b>6.3</b> The Naomi model</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="naomi-aghq.html"><a href="naomi-aghq.html#naomi-model"><i class="fa fa-check"></i><b>6.3.1</b> Model structure</a></li>
<li class="chapter" data-level="6.3.2" data-path="naomi-aghq.html"><a href="naomi-aghq.html#naomi-elgm"><i class="fa fa-check"></i><b>6.3.2</b> Naomi as an ELGM</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="naomi-aghq.html"><a href="naomi-aghq.html#pca-aghq"><i class="fa fa-check"></i><b>6.4</b> AGHQ in moderate dimensions</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="naomi-aghq.html"><a href="naomi-aghq.html#aghq-with-variable-levels"><i class="fa fa-check"></i><b>6.4.1</b> AGHQ with variable levels</a></li>
<li class="chapter" data-level="6.4.2" data-path="naomi-aghq.html"><a href="naomi-aghq.html#principal-components-analysis"><i class="fa fa-check"></i><b>6.4.2</b> Principal components analysis</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="naomi-aghq.html"><a href="naomi-aghq.html#malawi"><i class="fa fa-check"></i><b>6.5</b> Malawi case-study</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="naomi-aghq.html"><a href="naomi-aghq.html#nuts-convergence"><i class="fa fa-check"></i><b>6.5.1</b> NUTS convergence</a></li>
<li class="chapter" data-level="6.5.2" data-path="naomi-aghq.html"><a href="naomi-aghq.html#use-of-pca-aghq"><i class="fa fa-check"></i><b>6.5.2</b> Use of PCA-AGHQ</a></li>
<li class="chapter" data-level="6.5.3" data-path="naomi-aghq.html"><a href="naomi-aghq.html#model-assessment"><i class="fa fa-check"></i><b>6.5.3</b> Model assessment</a></li>
<li class="chapter" data-level="6.5.4" data-path="naomi-aghq.html"><a href="naomi-aghq.html#inference-comparison"><i class="fa fa-check"></i><b>6.5.4</b> Inference comparison</a></li>
<li class="chapter" data-level="6.5.5" data-path="naomi-aghq.html"><a href="naomi-aghq.html#exceedance-probabilities"><i class="fa fa-check"></i><b>6.5.5</b> Exceedance probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="naomi-aghq.html"><a href="naomi-aghq.html#discussion-2"><i class="fa fa-check"></i><b>6.6</b> Discussion</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="naomi-aghq.html"><a href="naomi-aghq.html#a-universal-inla-implementation"><i class="fa fa-check"></i><b>6.6.1</b> A universal INLA implementation</a></li>
<li class="chapter" data-level="6.6.2" data-path="naomi-aghq.html"><a href="naomi-aghq.html#pca-aghq-with-application-to-inla-for-naomi"><i class="fa fa-check"></i><b>6.6.2</b> PCA-AGHQ with application to INLA for Naomi</a></li>
<li class="chapter" data-level="6.6.3" data-path="naomi-aghq.html"><a href="naomi-aghq.html#suggestions-for-future-work"><i class="fa fa-check"></i><b>6.6.3</b> Suggestions for future work</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i><b>7</b> Conclusions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="conclusions.html"><a href="conclusions.html#strengths"><i class="fa fa-check"></i><b>7.1</b> Strengths</a></li>
<li class="chapter" data-level="7.2" data-path="conclusions.html"><a href="conclusions.html#weaknesses"><i class="fa fa-check"></i><b>7.2</b> Weaknesses</a></li>
<li class="chapter" data-level="7.3" data-path="conclusions.html"><a href="conclusions.html#future-work"><i class="fa fa-check"></i><b>7.3</b> Future work</a></li>
<li class="chapter" data-level="7.4" data-path="conclusions.html"><a href="conclusions.html#conclusions-1"><i class="fa fa-check"></i><b>7.4</b> Conclusions</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="models-for-spatial-structure.html"><a href="models-for-spatial-structure.html"><i class="fa fa-check"></i><b>A</b> Models for spatial structure</a>
<ul>
<li class="chapter" data-level="A.1" data-path="models-for-spatial-structure.html"><a href="models-for-spatial-structure.html#comparison-of-aghq-to-nuts"><i class="fa fa-check"></i><b>A.1</b> Comparison of AGHQ to NUTS</a></li>
<li class="chapter" data-level="A.2" data-path="models-for-spatial-structure.html"><a href="models-for-spatial-structure.html#simulation-study-1"><i class="fa fa-check"></i><b>A.2</b> Simulation study</a></li>
<li class="chapter" data-level="A.3" data-path="models-for-spatial-structure.html"><a href="models-for-spatial-structure.html#hiv-study"><i class="fa fa-check"></i><b>A.3</b> HIV study</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="a-model-for-risk-group-proportions.html"><a href="a-model-for-risk-group-proportions.html"><i class="fa fa-check"></i><b>B</b> A model for risk group proportions</a>
<ul>
<li class="chapter" data-level="B.1" data-path="a-model-for-risk-group-proportions.html"><a href="a-model-for-risk-group-proportions.html#the-global-aids-strategy"><i class="fa fa-check"></i><b>B.1</b> The Global AIDS Strategy</a></li>
<li class="chapter" data-level="B.2" data-path="a-model-for-risk-group-proportions.html"><a href="a-model-for-risk-group-proportions.html#household-survey-data"><i class="fa fa-check"></i><b>B.2</b> Household survey data</a></li>
<li class="chapter" data-level="B.3" data-path="a-model-for-risk-group-proportions.html"><a href="a-model-for-risk-group-proportions.html#spatial-analysis-levels"><i class="fa fa-check"></i><b>B.3</b> Spatial analysis levels</a></li>
<li class="chapter" data-level="B.4" data-path="a-model-for-risk-group-proportions.html"><a href="a-model-for-risk-group-proportions.html#survey-questions"><i class="fa fa-check"></i><b>B.4</b> Survey questions and risk group allocation</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html"><i class="fa fa-check"></i><b>C</b> Fast approximate Bayesian inference</a>
<ul>
<li class="chapter" data-level="C.1" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#epilepsy-example"><i class="fa fa-check"></i><b>C.1</b> Epilepsy example</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#tmb-epil"><i class="fa fa-check"></i><b>C.1.1</b> <code>TMB</code> C++ template</a></li>
<li class="chapter" data-level="C.1.2" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#tmb-modified-epil"><i class="fa fa-check"></i><b>C.1.2</b> Modified <code>TMB</code> C++ template</a></li>
<li class="chapter" data-level="C.1.3" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#stan-epil"><i class="fa fa-check"></i><b>C.1.3</b> <code>Stan</code> C++ template</a></li>
<li class="chapter" data-level="C.1.4" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#nuts-convergence-diagnostics"><i class="fa fa-check"></i><b>C.1.4</b> NUTS convergence diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#naomi-math"><i class="fa fa-check"></i><b>C.2</b> Simplified Naomi model description</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#naomi-process"><i class="fa fa-check"></i><b>C.2.1</b> Process specification</a></li>
<li class="chapter" data-level="C.2.2" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#naomi-likelihood"><i class="fa fa-check"></i><b>C.2.2</b> Additional likelihood specification</a></li>
<li class="chapter" data-level="C.2.3" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#naomi-identifiability"><i class="fa fa-check"></i><b>C.2.3</b> Identifiability constraints</a></li>
<li class="chapter" data-level="C.2.4" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#naomi-implementation"><i class="fa fa-check"></i><b>C.2.4</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#model-assessment-1"><i class="fa fa-check"></i><b>C.3</b> Model assessment</a></li>
<li class="chapter" data-level="C.4" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#aghq-and-pca-aghq-details"><i class="fa fa-check"></i><b>C.4</b> AGHQ and PCA-AGHQ details</a></li>
<li class="chapter" data-level="C.5" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#normalising-constant-estimation"><i class="fa fa-check"></i><b>C.5</b> Normalising constant estimation</a></li>
<li class="chapter" data-level="C.6" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#inference-comparison-1"><i class="fa fa-check"></i><b>C.6</b> Inference comparison</a></li>
<li class="chapter" data-level="C.7" data-path="fast-approximate-bayesian-inference.html"><a href="fast-approximate-bayesian-inference.html#mcmc-convergence-and-suitability"><i class="fa fa-check"></i><b>C.7</b> MCMC convergence and suitability</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><p>Bayesian spatio-temporal methods for small-area estimation of HIV indicators</p></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="naomi-aghq" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> Fast approximate Bayesian inference<a href="naomi-aghq.html#naomi-aghq" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!-- For PDF output, include these two LaTeX commands after unnumbered chapter headings, otherwise the mini table of contents and the running header will show the previous chapter -->
<p>This chapter describes the development of a novel Bayesian inference method, motivated by the Naomi small-area estimation model <span class="citation">(<a href="#ref-eaton2021naomi">Eaton et al. 2021</a>)</span>, tackling both implementation and methological challenges.
Over 35 countries <span class="citation">(<a href="#ref-unaids2023global">UNAIDS 2023b</a>)</span> have used the Naomi model web interface (<a href="https://naomi.unaids.org"><code>https://naomi.unaids.org</code></a> to produce subnational estimates of HIV indicators.
Evidence is synthesised from household surveys and routinely collected health data to generate estimates of HIV indicators by district, age, and sex.
The complexity and size of the model makes obtaining fast and accurate Bayesian inferences challenging.</p>
<p>The methods developed in this chapter combine Laplace approximations with adaptive quadrature, and are descended from the integrated nested Laplace approximation (INLA) method pioneered by <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span>.
The INLA method has enabled fast and accurate Bayesian inferences for a vast array of models, across a large number of scientific fields <span class="citation">(<a href="#ref-rue2017bayesian">Håvard Rue et al. 2017</a>)</span>.
The success of INLA is in large part due to its accessible implementation in the <code>R-INLA</code> software.
Use of the INLA method and the <code>R-INLA</code> software are close to ubiquitous in applied settings.
However, the Naomi model is not compatible with <code>R-INLA</code>, foremost because it is too complex to be expressed using a formula interface.
As a result, inferences for the Naomi model have previously been obtained using an empirical Bayes [EB; <span class="citation">Casella (<a href="#ref-casella1985introduction">1985</a>)</span>] approximation to full Bayesian inference, using a Laplace approximation implemented by the more flexible Template Model Builder [<code>TMB</code>; <span class="citation">Kristensen et al. (<a href="#ref-kristensen2016tmb">2016</a>)</span>] R package.
In the EB approximation hyperparameters are fixed by optimisation of the marginal posterior.
This is undesirable as it results in underestimation of uncertainty, which may ultimately lead to worse policy decisions which stem from overconfidence.</p>
<p>Most methodological work relating to INLA has taken place using the <code>R-INLA</code> software package.
There are two notable exceptions.
First, the simplified INLA approach of <span class="citation">Wood (<a href="#ref-wood2020simplified">2020</a>)</span>, implemented in the <code>mgcv</code> R package, proposed an fast Laplace approximation approach which does not rely on Markov structure of the latent field.
Second, <span class="citation">Stringer, Brown, and Stafford (<a href="#ref-stringer2022fast">2022</a>)</span> extended the scope and scalability of INLA by avoiding augmenting the latent field with the noisy structured additive predictors.
This enables the application of INLA to a wider class of extended latent Gaussian models, which includes Naomi.
<span class="citation">Van Niekerk et al. (<a href="#ref-van2023new">2023</a>)</span> refer to this as the “modern” formulation of the INLA method, as opposed to the “classic” formulation of <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span>, and it is now included in <code>R-INLA</code> using <code>inla.mode = "experimental"</code>.
<span class="citation">Stringer, Brown, and Stafford (<a href="#ref-stringer2022fast">2022</a>)</span> also propose use of the adaptive Gauss-Hermite quadrature [AGHQ; <span class="citation">Naylor and Smith (<a href="#ref-naylor1982applications">1982</a>)</span>] rule to perform integration with respect to the hyperparameters.</p>
<p>The methodological contributions of this chapter extend <span class="citation">Stringer, Brown, and Stafford (<a href="#ref-stringer2022fast">2022</a>)</span> in two directions:</p>
<ol style="list-style-type: decimal">
<li>First, a universally applicable implementation of INLA with Laplace marginals, where automatic differentiation via <code>TMB</code> is used to obtain the derivatives required for the Laplace approximation.
Section <a href="naomi-aghq.html#universal">6.2</a> demonstrates the implementation using two examples, one compatible with <code>R-INLA</code> and one incompatible.</li>
<li>Second, a quadrature rule which combines AGHQ with principal components analysis to enable integration over moderate-dimensional spaces, described in Section <a href="naomi-aghq.html#pca-aghq">6.4</a>.
This quadrature rule is used to perform inference for the Naomi model by integrating the marginal Laplace approximation with respect to the moderate-dimensional hyperparameters within an INLA algorithm implemented in <code>TMB</code> in Section <a href="naomi-aghq.html#malawi">6.5</a>.</li>
</ol>
<p>This work was conducted in collaboration with Prof. Alex Stringer, whom I visited at the University of Waterloo during the fall term of 2022.
The results are presented in <span class="citation">Howes et al. (<a href="#ref-howes2023fast">2023+</a>)</span>.
Code for the analysis in this chapter is available from <a href="https://github.com/athowes/naomi-aghq"><code>https://github.com/athowes/naomi-aghq</code></a>.</p>
<div id="inference-methods-and-software" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Inference methods and software<a href="naomi-aghq.html#inference-methods-and-software" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section reviews existing deterministic Bayesian inference methods (Sections <a href="naomi-aghq.html#la">6.1.1</a>, <a href="naomi-aghq.html#quadrature">6.1.2</a>, <a href="naomi-aghq.html#inla">6.1.3</a>) and the software implementing them (Section <a href="naomi-aghq.html#software">6.1.4</a>).
Inference comprises obtaining the posterior distribution
<span class="math display" id="eq:bayes">\[\begin{equation}
p(\boldsymbol{\mathbf{\phi}} \, | \, \mathbf{y}) = \frac{p(\boldsymbol{\mathbf{\phi}}, \mathbf{y})}{p(\mathbf{y})}, \tag{6.1}
\end{equation}\]</span>
or some way to compute relevant functions of it.
The posterior distribution encapsulates beliefs about the parameters <span class="math inline">\(\boldsymbol{\mathbf{\phi}} = (\phi_1, \ldots, \phi_d)\)</span> having observed data <span class="math inline">\(\mathbf{y} = (y_1, \ldots, y_n)\)</span>.
Here I assume these quantities are expressible as vectors.</p>
<p>Inference is a sensible goal because (under Bayesian decision theory) the posterior distribution is sufficient for use in decision making.
More specifically, given a loss function <span class="math inline">\(l(a, \boldsymbol{\mathbf{\phi}})\)</span>, the expected posterior loss of a decision <span class="math inline">\(a\)</span> depends on the data only via the posterior distribution
<span class="math display">\[\begin{equation}
\mathbb{E}(l(a, \boldsymbol{\mathbf{\phi}}) \, | \, \mathbf{y}) = \int_{\mathbb{R}^d} l(a, \boldsymbol{\mathbf{\phi}}) p(\boldsymbol{\mathbf{\phi}} \, | \, \mathbf{y}) \text{d}\boldsymbol{\mathbf{\phi}}.
\end{equation}\]</span>
For example, historic data about treatment demand are only required for planning of HIV treatment service provision in so far as they alter the posterior distribution of current demand.
The information provided for strategic response to the HIV epidemic may therefore be thought of as functions of some posterior distribution.</p>
<p>It is usually intractable to obtain the posterior distribution.
This is because the denominator in Equation <a href="naomi-aghq.html#eq:bayes">(6.1)</a> contains a potentially high-dimensional integral over the <span class="math inline">\(d \in \mathbb{Z}^+\)</span> -dimensional parameters
<span class="math display" id="eq:evidence">\[\begin{equation}
p(\mathbf{y}) = \int_{\mathbb{R}^d} p(\mathbf{y}, \boldsymbol{\mathbf{\phi}}) \text{d}\boldsymbol{\mathbf{\phi}}. \tag{6.2}
\end{equation}\]</span>
This quantity is sometimes called the evidence or posterior normalising constant.
As a result, approximations to the posterior distribution <span class="math inline">\(\tilde p(\boldsymbol{\mathbf{\phi}} \, | \, \mathbf{y})\)</span> are typically used in place of the exact posterior distribution.</p>
<p>Some approximate Bayesian inference methods, like Markov chain Monte Carlo (MCMC), avoid directly calculating the posterior normalising constant.
Instead they find ways to work with the unnormalised posterior distribution
<span class="math display">\[\begin{equation}
p(\boldsymbol{\mathbf{\phi}} \, | \, \mathbf{y}) \propto p(\boldsymbol{\mathbf{\phi}}, \mathbf{y}),
\end{equation}\]</span>
where <span class="math inline">\(p(\mathbf{y})\)</span> is not a function of <span class="math inline">\(\boldsymbol{\mathbf{\phi}}\)</span> and so can be removed as a constant.
Other approximate Bayesian inference methods can more directly be thought of as ways to estimate the posterior normalising constant (Equation <a href="naomi-aghq.html#eq:evidence">(6.2)</a>).
The methods in this chapter fall into this latter category, and are sometimes described as deterministic Bayesian inference methods because they do not make fundamental use of randomness.</p>
<div id="la" class="section level3 hasAnchor" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> The Laplace approximation<a href="naomi-aghq.html#la" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Laplace’s method <span class="citation">(<a href="#ref-laplace1774memoire">Laplace 1774</a>)</span> is a technique used to approximate integrals of the form
<span class="math display">\[\begin{equation}
\int \exp(C h(\mathbf{z})) \text{d}\mathbf{z},
\end{equation}\]</span>
where <span class="math inline">\(C &gt; 0\)</span> is a constant, <span class="math inline">\(h\)</span> is a function which is twice-differentiable, and <span class="math inline">\(\mathbf{z}\)</span> are generic variables.
The Laplace approximation <span class="citation">(<a href="#ref-tierney1986accurate">Tierney and Kadane 1986</a>)</span> is obtained by application of Laplace’s method to calculate the posterior normalising constant (Equation <a href="naomi-aghq.html#eq:evidence">(6.2)</a>).
Let <span class="math inline">\(h(\boldsymbol{\mathbf{\phi}}) = \log p(\boldsymbol{\mathbf{\phi}}, \mathbf{y})\)</span> such that
<span class="math display">\[\begin{equation}
p(\mathbf{y}) = \int_{\mathbb{R}^d} p(\mathbf{y}, \boldsymbol{\mathbf{\phi}}) \text{d}\boldsymbol{\mathbf{\phi}} = \int_{\mathbb{R}^d} \exp(h(\boldsymbol{\mathbf{\phi}})) \text{d}\boldsymbol{\mathbf{\phi}}.
\end{equation}\]</span>
Laplace’s method involves approximating the function <span class="math inline">\(h\)</span> by its second order Taylor expansion.
This expansion is then evaluated at a maxima of <span class="math inline">\(h\)</span> to eliminate the first order term.
Let
<span class="math display" id="eq:posterior-mode">\[\begin{equation}
\hat{\boldsymbol{\mathbf{\phi}}} = \arg\max_{\boldsymbol{\mathbf{\phi}}} h(\boldsymbol{\mathbf{\phi}}) \tag{6.3}
\end{equation}\]</span>
be the posterior mode, and
<span class="math display" id="eq:hessian">\[\begin{equation}
\hat {\mathbf{H}} = - \frac{\partial^2}{\partial \boldsymbol{\mathbf{\phi}} \partial \boldsymbol{\mathbf{\phi}}^\top} h(\boldsymbol{\mathbf{\phi}}) \rvert_{\boldsymbol{\mathbf{\phi}} = \hat{\boldsymbol{\mathbf{\phi}}}} \tag{6.4}
\end{equation}\]</span>
be the Hessian matrix evaluated at the posterior mode.
The Laplace approximation to the posterior normalising constant (Equation <a href="naomi-aghq.html#eq:evidence">(6.2)</a>) is then
<span class="math display" id="eq:la2" id="eq:la">\[\begin{align}
\tilde p_{\texttt{LA}}(\mathbf{y}) &amp;= \int_{\mathbb{R}^d} \exp \left( h(\hat{\boldsymbol{\mathbf{\phi}}}) - \frac{1}{2} (\boldsymbol{\mathbf{\phi}} - \hat{\boldsymbol{\mathbf{\phi}}})^\top \hat {\mathbf{H}} (\boldsymbol{\mathbf{\phi}} - \hat{\boldsymbol{\mathbf{\phi}}}) \right) \text{d}\boldsymbol{\mathbf{\phi}} \tag{6.5} \\
&amp;= p(\hat{\boldsymbol{\mathbf{\phi}}}, \mathbf{y}) \cdot \frac{(2 \pi)^{d/2}}{| \hat {\mathbf{H}} |^{1/2}}. \tag{6.6}
\end{align}\]</span>
The result above is calculated using the known normalising constant of the Gaussian distribution
<span class="math display">\[\begin{equation}
p_\texttt{G}(\boldsymbol{\mathbf{\phi}} \, | \, \mathbf{y}) = \mathcal{N}(\boldsymbol{\mathbf{\phi}} \, | \, \hat{\boldsymbol{\mathbf{\phi}}}, \hat {\mathbf{H}}^{-1}) = \frac{| \hat {\mathbf{H}} |^{1/2}}{(2 \pi)^{d/2}} \exp \left( - \frac{1}{2} (\boldsymbol{\mathbf{\phi}} - \hat{\boldsymbol{\mathbf{\phi}}})^\top \hat {\mathbf{H}} (\boldsymbol{\mathbf{\phi}} - \hat{\boldsymbol{\mathbf{\phi}}}) \right).
\end{equation}\]</span>
The Laplace approximation may be thought of as approximating the posterior distribution by a Gaussian distribution <span class="math inline">\(p(\boldsymbol{\mathbf{\phi}} \, | \, \mathbf{y}) \approx p_\texttt{G}(\boldsymbol{\mathbf{\phi}} \, | \, \mathbf{y})\)</span> such that
<span class="math display">\[\begin{equation}
\tilde p_{\texttt{LA}}(\mathbf{y}) = \frac{p(\boldsymbol{\mathbf{\phi}}, \mathbf{y})}{p_\texttt{G}(\boldsymbol{\mathbf{\phi}} \, | \, \mathbf{y})} \Big\rvert_{\boldsymbol{\mathbf{\phi}} = \hat{\boldsymbol{\mathbf{\phi}}}}.
\end{equation}\]</span></p>
<p>Calculation of the Laplace approximation requires obtaining the second derivative of <span class="math inline">\(h\)</span> with respect to <span class="math inline">\(\boldsymbol{\mathbf{\phi}}\)</span> (Equation <a href="naomi-aghq.html#eq:hessian">(6.4)</a>).
Derivatives may also be used to improve the performance of the optimisation algorithm used to obtain the maxima of <span class="math inline">\(h\)</span> (Equation <a href="naomi-aghq.html#eq:posterior-mode">(6.3)</a>) by providing access to the gradient of <span class="math inline">\(h\)</span> with respect to <span class="math inline">\(\boldsymbol{\mathbf{\phi}}\)</span>.</p>

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:laplace"></span>
<img src="figures/naomi-aghq/laplace.png" alt="Demonstration of the Laplace approximation for the simple Bayesian inference example of Figure 3.1. The unnormalised posterior is \(p(\phi, \mathbf{y}) = \phi^8 \exp(-4 \phi)\), and can be recognised as the unnormalised gamma distribution \(\text{Gamma}(9, 4)\). The true log normalising constant is \(\log p(\mathbf{y}) = \log\Gamma(9) - 9 \log(4) = -1.872046\), whereas the Laplace approximate log normalising constant is \(\log \tilde p_{\texttt{LA}}(\mathbf{y}) = -1.882458\), resulting from the Gaussian approximation \(p_\texttt{G}(\phi \, | \, \mathbf{y}) = \mathcal{N}(\phi \, | \,\mu = 2, \tau = 2)\)." width="95%" />
<p class="caption">
Figure 6.1: Demonstration of the Laplace approximation for the simple Bayesian inference example of Figure <a href="bayes-st.html#fig:conjugate">3.1</a>. The unnormalised posterior is <span class="math inline">\(p(\phi, \mathbf{y}) = \phi^8 \exp(-4 \phi)\)</span>, and can be recognised as the unnormalised gamma distribution <span class="math inline">\(\text{Gamma}(9, 4)\)</span>. The true log normalising constant is <span class="math inline">\(\log p(\mathbf{y}) = \log\Gamma(9) - 9 \log(4) = -1.872046\)</span>, whereas the Laplace approximate log normalising constant is <span class="math inline">\(\log \tilde p_{\texttt{LA}}(\mathbf{y}) = -1.882458\)</span>, resulting from the Gaussian approximation <span class="math inline">\(p_\texttt{G}(\phi \, | \, \mathbf{y}) = \mathcal{N}(\phi \, | \,\mu = 2, \tau = 2)\)</span>.
</p>
</div>
<div id="marginal-la" class="section level4 hasAnchor" number="6.1.1.1">
<h4><span class="header-section-number">6.1.1.1</span> The marginal Laplace approximation<a href="naomi-aghq.html#marginal-la" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Approximating the full joint posterior distribution using a Gaussian distribution may be inaccurate.
An alternative is to approximate the marginal posterior distribution of some subset of the parameters, referred to as the marginal Laplace approximation.
It remains to integrate out the remaining parameters, using another more suitable method.
This approach is the basis of the INLA method.</p>
<p>Let <span class="math inline">\(\boldsymbol{\mathbf{\phi}} = (\mathbf{x}, \boldsymbol{\mathbf{\theta}})\)</span> and consider a three-stage hierarchical model
<span class="math display">\[\begin{equation}
p(\mathbf{y}, \mathbf{x}, \boldsymbol{\mathbf{\theta}}) = p(\mathbf{y} \, | \, \mathbf{x}, \boldsymbol{\mathbf{\theta}}) p(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}) p(\boldsymbol{\mathbf{\theta}}),
\end{equation}\]</span>
where <span class="math inline">\(\mathbf{x} = (x_1, \ldots, x_N)\)</span> is the latent field, and <span class="math inline">\(\boldsymbol{\mathbf{\theta}} = (\theta_1, \ldots, \theta_m)\)</span> are the hyperparameters.
Applying a Gaussian approximation to the latent field, we have <span class="math inline">\(h(\mathbf{x}, \boldsymbol{\mathbf{\theta}}) = \log p(\mathbf{y}, \mathbf{x}, \boldsymbol{\mathbf{\theta}})\)</span> with <span class="math inline">\(N\)</span>-dimensional posterior mode
<span class="math display" id="eq:marginal-posterior-mode">\[\begin{equation}
\hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}}) = \arg\max_{\mathbf{x}} h(\mathbf{x}, \boldsymbol{\mathbf{\theta}}) \tag{6.7}
\end{equation}\]</span>
and <span class="math inline">\(N \times N\)</span>-dimensional Hessian matrix evaluated at the posterior mode
<span class="math display" id="eq:marginal-hessian">\[\begin{equation}
\hat {\mathbf{H}}(\boldsymbol{\mathbf{\theta}}) = - \frac{\partial^2}{\partial \mathbf{x} \partial \mathbf{x}^\top} h(\mathbf{x}, \boldsymbol{\mathbf{\theta}}) \rvert_{\mathbf{x} = \hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}})}. \tag{6.8}
\end{equation}\]</span>
Dependence on the hyperparameters <span class="math inline">\(\boldsymbol{\mathbf{\theta}}\)</span> is made explicit in both Equation <a href="naomi-aghq.html#eq:marginal-posterior-mode">(6.7)</a> and <a href="naomi-aghq.html#eq:marginal-hessian">(6.8)</a> such that there is a Gaussian approximation to the marginal posterior of the latent field <span class="math inline">\(\tilde p_\texttt{G}(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}, \mathbf{y}) = \mathcal{N}(\mathbf{x} \, | \, \hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}}), \hat{\mathbf{H}}(\boldsymbol{\mathbf{\theta}})^{-1})\)</span> at each value <span class="math inline">\(\boldsymbol{\mathbf{\theta}}\)</span> in the space <span class="math inline">\(\mathbb{R}^m\)</span>.
The resulting marginal Laplace approximation, for a particular value of the hyperparameters, is then
<span class="math display" id="eq:marginalla">\[\begin{align}
\tilde p_{\texttt{LA}}(\boldsymbol{\mathbf{\theta}}, \mathbf{y}) &amp;= \int_{\mathbb{R}^N} \exp \left( h(\hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}}), \boldsymbol{\mathbf{\theta}}) - \frac{1}{2} (\mathbf{x} - \hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}}))^\top \hat {\mathbf{H}}(\boldsymbol{\mathbf{\theta}}) (\mathbf{x} - \hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}})) \right) \text{d}\mathbf{x} \tag{6.9} \\
&amp;= \exp(h(\hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}}), \mathbf{y})) \cdot \frac{(2 \pi)^{d/2}}{| \hat {\mathbf{H}}(\boldsymbol{\mathbf{\theta}}) |^{1/2}} \\
&amp;= \frac{p(\mathbf{y}, \mathbf{x}, \boldsymbol{\mathbf{\theta}})}{\tilde p_\texttt{G}(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}, \mathbf{y})} \Big\rvert_{\mathbf{x} = \hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}})}.
\end{align}\]</span></p>
<p>The marginal Laplace approximation is most accurate when the marginal posterior <span class="math inline">\(p(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}, \mathbf{y})\)</span> is accurately approximated by a Gaussian
distribution.
For the class of latent Gaussian models <span class="citation">(<a href="#ref-rue2009approximate">Håvard Rue, Martino, and Chopin 2009</a>)</span> the prior distribution on the latent field is Gaussian
<span class="math display">\[\begin{equation}
\mathbf{x} \sim \mathcal{N}(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}) = \mathcal{N}(\mathbf{x} \, | \, \mathbf{0}, \mathbf{Q}(\boldsymbol{\mathbf{\theta}})),
\end{equation}\]</span>
with assumed zero mean <span class="math inline">\(\mathbf{0}\)</span>, and precision matrix <span class="math inline">\(\mathbf{Q}(\boldsymbol{\mathbf{\theta}})\)</span>.
The resulting marginal posterior distribution
<span class="math display">\[\begin{align}
p(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}, \mathbf{y}) &amp;\propto \mathcal{N}(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}) p(\mathbf{y}  \, | \, \mathbf{x}, \boldsymbol{\mathbf{\theta}}) \\
&amp;\propto \exp \left( - \frac{1}{2} \mathbf{x}^\top \mathbf{Q}(\boldsymbol{\mathbf{\theta}}) \mathbf{x} + \log p(\mathbf{y} \, | \, \mathbf{x}, \boldsymbol{\mathbf{\theta}}) \right)
\end{align}\]</span>
is not exactly Gaussian.
However, its deviation can be expected to be small if <span class="math inline">\(\log p(\mathbf{y} \, | \, \mathbf{x}, \boldsymbol{\mathbf{\theta}})\)</span> is small.</p>
</div>
</div>
<div id="quadrature" class="section level3 hasAnchor" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Quadrature<a href="naomi-aghq.html#quadrature" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Quadrature is a method used to approximate integrals using a weighted sum of function evaluations.
As with the Laplace approximation, it is deterministic in that the computational procedure is not intrinsically random.
Let <span class="math inline">\(\mathcal{Q}\)</span> be a set of quadrature nodes <span class="math inline">\(\mathbf{z} \in \mathcal{Q}\)</span> and <span class="math inline">\(\omega: \mathbb{R}^d \to \mathbb{R}\)</span> be a weighting function.
Then, quadrature can be used to estimate the posterior normalising constant (Equation <a href="naomi-aghq.html#eq:evidence">(6.2)</a>) by
<span class="math display">\[\begin{equation}
\tilde p_{\mathcal{Q}}(\mathbf{y}) = \sum_{\mathbf{z} \in \mathcal{Q}} p(\mathbf{y}, \mathbf{z}) \omega(\mathbf{z}).
\end{equation}\]</span></p>
<p>To illustrate quadrature for a simple example, consider integrating the univariate function <span class="math inline">\(f(z) = z \sin(z)\)</span> between <span class="math inline">\(z = 0\)</span> and <span class="math inline">\(z = \pi\)</span>.
This integral can be calculated analytically using integration by parts and evaluates to <span class="math inline">\(\pi\)</span>.
A quadrature approximation of this integral is
<span class="math display" id="eq:zsinz">\[\begin{equation}
\pi = \sin(z) - z \cos(z) \bigg|_0^\pi = \int_{0}^\pi z \sin(z) \text{d} z \approx \sum_{z \in \mathcal{Q}} z \sin(z) \omega(z), \tag{6.10}
\end{equation}\]</span>
where <span class="math inline">\(\mathcal{Q} = \{z_1, \ldots z_k\}\)</span> are a set of <span class="math inline">\(k\)</span> quadrature nodes and <span class="math inline">\(\omega: \mathbb{R} \to \mathbb{R}\)</span> is a weighting function.</p>
<p>The trapezoid rule is an example of a quadrature rule, in which quadrature nodes are spaced throughout the domain with <span class="math inline">\(\epsilon_i = z_i - z_{i - 1} &gt; 0\)</span> for <span class="math inline">\(1 &lt; i &lt; k\)</span>.
The weighting function is
<span class="math display">\[\begin{equation}
\omega(z_i) =
\begin{cases}
  \epsilon_i &amp; 1 &lt; i &lt; k, \\
  \epsilon_i / 2 &amp; i \in \{1, k\}.
\end{cases}
\end{equation}\]</span>
Figure <a href="naomi-aghq.html#fig:trapezoid">6.2</a> shows application of the trapezoid rule to integration of <span class="math inline">\(z \sin(z)\)</span> as described in Equation <a href="naomi-aghq.html#eq:zsinz">(6.10)</a>.
The more quadrature nodes are used, the more accurate the estimate of the integrand is.
Under some regularity conditions on <span class="math inline">\(f\)</span>, as the spacing between quadrature nodes <span class="math inline">\(\epsilon \to 0\)</span> the estimate obtained using the trapezoid rule converges to the true value of the integral.
Indeed, this approach was used by Riemann to provide the first rigorous definition of the integral.</p>

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:trapezoid"></span>
<img src="figures/naomi-aghq/trapezoid.png" alt="The trapezoid rule with \(k = 5, 10, 20\) equally-spaced (\(\epsilon_i = \epsilon &gt; 0\)) quadrature nodes can be used to integrate the function \(f(z) = z \sin(z)\), shown in green, in the domain \([0, \pi]\). Here, the exact solution is \(\pi \approx 3.1416\). As \(k\) increases and more nodes are used in the computation, the quadrature estimate becomes closer to the exact solution. The trapezoid rule estimate is given by the sum of the areas of the grey trapezoids." width="95%" />
<p class="caption">
Figure 6.2: The trapezoid rule with <span class="math inline">\(k = 5, 10, 20\)</span> equally-spaced (<span class="math inline">\(\epsilon_i = \epsilon &gt; 0\)</span>) quadrature nodes can be used to integrate the function <span class="math inline">\(f(z) = z \sin(z)\)</span>, shown in green, in the domain <span class="math inline">\([0, \pi]\)</span>. Here, the exact solution is <span class="math inline">\(\pi \approx 3.1416\)</span>. As <span class="math inline">\(k\)</span> increases and more nodes are used in the computation, the quadrature estimate becomes closer to the exact solution. The trapezoid rule estimate is given by the sum of the areas of the grey trapezoids.
</p>
</div>
<p>Quadrature methods are most effective when integrating over small dimensions, say three or less.
This is because the number of quadrature nodes at which the function is required to be evaluated in the computation grows exponentially with the dimension.
For even moderate dimension, this quickly makes computation intractable.
For example, using 5, 10, or 20 quadrature nodes per dimension, as in Figure <a href="naomi-aghq.html#fig:trapezoid">6.2</a>, in five-dimensions (rather than one, as shown) would require 3125, 100000 or 3200000 quadrature nodes respectively.
Though quadrature is embarrassingly parallel, in that function evaluation at each node is entirely independent, solutions requiring the evaluation of millions quadrature nodes are unlikely to be tractable.</p>
<div id="gauss-hermite-quadrature" class="section level4 hasAnchor" number="6.1.2.1">
<h4><span class="header-section-number">6.1.2.1</span> Gauss-Hermite quadrature<a href="naomi-aghq.html#gauss-hermite-quadrature" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It is possible to construct quadrature rules which use relatively few nodes and are highly accurate when the integrand adheres to certain assumptions [Chapter 4; <span class="citation">Press et al. (<a href="#ref-press2007numerical">2007</a>)</span>].
Gauss-Hermite quadrature [GHQ; <span class="citation">Davis and Rabinowitz (<a href="#ref-davis1975methods">1975</a>)</span>] is a quadrature rule designed to integrate functions of the form <span class="math inline">\(f(\mathbf{z}) = \varphi(\mathbf{z}) P_\alpha(\mathbf{z})\)</span> exactly, that is with no error, such that
<span class="math display" id="eq:ghqexact">\[\begin{equation}
\int \varphi(\mathbf{z}) P_\alpha(\mathbf{z}) \text{d} \mathbf{z} = \sum_{\mathbf{z} \in \mathcal{Q}}  \varphi(\mathbf{z}) P_\alpha(\mathbf{z}) \omega(\mathbf{z}). \tag{6.11}
\end{equation}\]</span>
In this equation, the term <span class="math inline">\(\varphi(\cdot)\)</span> is a standard multivariate normal density <span class="math inline">\(\mathcal{N}(\cdot \, | \, \mathbf{0}, \mathbf{I})\)</span>, where <span class="math inline">\(\mathbf{0}\)</span> and <span class="math inline">\(\mathbf{I}\)</span> are the zero-vector and identify matrix of relevant dimension, and the term <span class="math inline">\(P_\alpha(\cdot)\)</span> is a polynomial with highest degree monomial <span class="math inline">\(\alpha \leq 2k - 1\)</span>, where <span class="math inline">\(k\)</span> is the number of quadrature nodes per dimension.
GHQ is attractive for Bayesian inference problems because posterior distributions are typically well approximated by functions of this form.
Support for this statement is provided by the Bernstein–von Mises theorem, which states that, under some regularity conditions, as the number of data points increases the posterior distribution convergences to a Gaussian.</p>
<p>I follow the notation for GHQ established by <span class="citation">Bilodeau, Stringer, and Tang (<a href="#ref-bilodeau2022stochastic">2022</a>)</span>.
First, to construct the univariate GHQ rule for <span class="math inline">\(z \in \mathbb{R}\)</span>, let <span class="math inline">\(H_k(z)\)</span> be the <span class="math inline">\(k\)</span>th (probabilist’s) Hermite polynomial
<span class="math display">\[\begin{equation}
H_k(z) = (-1)^k \exp(z^2 / 2) \frac{\text{d}}{\text{d}z^k} \exp(-z^2 / 2)
\end{equation}\]</span>
The Hermite polynomials are defined to be orthogonal with respect to the standard Gaussian probability density function
<span class="math display">\[\begin{equation}
\int H_k(z) H_l(z) \varphi(z) \text{d} z = \delta_{kl},
\end{equation}\]</span>
where <span class="math inline">\(\delta_{kl} = 1\)</span> if <span class="math inline">\(k = l\)</span> and <span class="math inline">\(\delta_{kl} = 0\)</span> otherwise.
<!-- The relevance of the above equation is that... -->
The GHQ nodes <span class="math inline">\(z \in \mathcal{Q}(1, k)\)</span> are given by the <span class="math inline">\(k\)</span> zeroes of the <span class="math inline">\(k\)</span>th Hermite polynomial.
For <span class="math inline">\(k = 1, 2, 3\)</span> these zeros, up to three decimal places, are
<span class="math display">\[\begin{align}
H_1(z) = z = 0 \implies \mathcal{Q}(1, 1) &amp;= \{0\}, \\
H_2(z) = z^2 - 1 = 0 \implies \mathcal{Q}(1, 2) &amp;= \{-0.707, 0.707\}, \\
H_3(z) = z^3 - 3z = 0 \implies \mathcal{Q}(1, 3) &amp;= \{-1.225, 0, 1.225\}.
\end{align}\]</span>
The quadrature nodes are symmetric about zero, and include zero when <span class="math inline">\(k\)</span> is odd.
The corresponding weighting function <span class="math inline">\(\omega: \mathcal{Q}(1, k) \to \mathbb{R}\)</span> chosen to satisfy Equation <a href="naomi-aghq.html#eq:ghqexact">(6.11)</a> is given by
<span class="math display">\[\begin{equation}
\omega(z) = \frac{k!}{\varphi(z) [H_{k + 1}(z)]^2}.
\end{equation}\]</span></p>
<p>Multivariate GHQ rules are usually constructed using the product rule with identical univariate GHQ rules in each dimension.
As such, in <span class="math inline">\(d\)</span> dimensions, the multivariate GHQ nodes <span class="math inline">\(\mathbf{z} \in \mathcal{Q}(d, k)\)</span> are defined by
<span class="math display">\[\begin{equation}
\mathcal{Q}(d, k) = \mathcal{Q}(1, k)^d = \mathcal{Q}(1, k) \times \cdots \times \mathcal{Q}(1, k).
\end{equation}\]</span>
The corresponding weighting function <span class="math inline">\(\omega: \mathcal{Q}(d, k) \to \mathbb{R}\)</span> is given by a product of the univariate weighting functions <span class="math inline">\(\omega(\mathbf{z}) = \prod_{j = 1}^d \omega(z_j)\)</span>.</p>
</div>
<div id="adaptive-quadrature" class="section level4 hasAnchor" number="6.1.2.2">
<h4><span class="header-section-number">6.1.2.2</span> Adaptive quadrature<a href="naomi-aghq.html#adaptive-quadrature" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In adaptive quadrature, the quadrature nodes and weights selected depend on the specific integrand being considered.
For example, adaptive use of the trapezoid rule requires specifying a rule for the start point, end point, and spacing between quadrature nodes.
It is particularly important to use an adaptive quadrature rule for Bayesian inference problems because the posterior normalising constant <span class="math inline">\(p(\mathbf{y})\)</span> is a function of the data.
No fixed quadrature rule can be expected to effectively integrate all possible posterior distributions.</p>
<p>In adaptive GHQ [AGHQ; <span class="citation">Naylor and Smith (<a href="#ref-naylor1982applications">1982</a>)</span>] the quadrature nodes are shifted by the mode of the integrand, and rotated based on a matrix decomposition of the inverse curvature at the mode.
To demonstrate AGHQ, consider its application to calculation of the posterior normalising constant.
The relevant transformation of the GHQ nodes <span class="math inline">\(\mathcal{Q}(d, k)\)</span> is
<span class="math display">\[\begin{equation}
\boldsymbol{\mathbf{\phi}}(\mathbf{z}) = \hat{\mathbf{P}} \mathbf{z} + \hat{\boldsymbol{\mathbf{\phi}}},
\end{equation}\]</span>
where <span class="math inline">\(\hat{\mathbf{P}}\)</span> is a matrix decomposition of <span class="math inline">\(\hat{\boldsymbol{\mathbf{H}}}^{-1} = \hat{\mathbf{P}} \hat{\mathbf{P}}^\top\)</span>.
To account for the transformation, the weighting function may be redefined to include a matrix determinant, analogous to the Jacobian determinant, or more simply the matrix determinant may be written outside the integral.
Taking the later approach, the resulting adaptive quadrature estimate of the posterior normalising constant is
<span class="math display">\[\begin{align}
\tilde p_{\texttt{AQ}}(\mathbf{y})
&amp;= | \hat{\mathbf{P}} | \sum_{\mathbf{z} \in \mathcal{Q}(d, k)} p(\mathbf{y}, \boldsymbol{\mathbf{\phi}}(\mathbf{z})) \omega(\mathbf{z}) \\
&amp;=  | \hat{\mathbf{P}} | \sum_{\mathbf{z} \in \mathcal{Q}(d, k)} p(\mathbf{y}, \hat{\mathbf{P}} \mathbf{z} + \hat{\boldsymbol{\mathbf{\phi}}}) \omega(\mathbf{z}).
\end{align}\]</span></p>
<p>The quantities <span class="math inline">\(\hat{\boldsymbol{\mathbf{\phi}}}\)</span> and <span class="math inline">\(\hat{\boldsymbol{\mathbf{H}}}\)</span> are exactly those given in Equations <a href="naomi-aghq.html#eq:posterior-mode">(6.3)</a> and <a href="naomi-aghq.html#eq:hessian">(6.4)</a> and used in the Laplace approximation.
Indeed, when <span class="math inline">\(k = 1\)</span> then AGHQ corresponds to the Laplace approximation.
To see this, we have <span class="math inline">\(H_1(z)\)</span> with univariate zero <span class="math inline">\(z = 0\)</span> such that the adapted node is given by the mode <span class="math inline">\(\boldsymbol{\mathbf{\phi}}(\mathbf{z} = \mathbf{0} = 0 \times \cdots \times 0) = \hat{\boldsymbol{\mathbf{\phi}}}\)</span>.
The weighting function is given by
<span class="math display">\[\begin{equation}
\omega(0)^d = \left( \frac{1!}{\varphi(0) H_{2}(0)^2} \right)^d = \left( \frac{1}{\varphi(0)} \right)^d = \left(2 \pi\right)^{d / 2}.
\end{equation}\]</span>
The AGHQ estimate of the normalising constant for <span class="math inline">\(k = 1\)</span> is then given by
<span class="math display">\[\begin{equation}
\tilde p_{\texttt{AQ}}(\mathbf{y}) = p(\mathbf{y}, \hat{\boldsymbol{\mathbf{\phi}}}) \cdot | \hat{\mathbf{P}} | \cdot (2 \pi)^{d / 2} = p(\mathbf{y}, \hat{\boldsymbol{\mathbf{\phi}}}) \cdot \frac{(2 \pi)^{d / 2}}{| \hat{\mathbf{H}} | ^{1/2}},
\end{equation}\]</span>
which corresponds to the Laplace approximation <span class="math inline">\(\tilde p_{\texttt{LA}}(\mathbf{y})\)</span> given in Equation <a href="naomi-aghq.html#eq:la2">(6.6)</a>.
This connection supports AGHQ being a natural extension of the Laplace approximation when greater accuracy than <span class="math inline">\(k = 1\)</span> is required.</p>
<!-- For each quadrature rule, the estimate of the integral is given by... -->

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:aghq-demo"></span>
<img src="figures/naomi-aghq/aghq-demo.png" alt="The Gauss-Hermite quadrature nodes \(\mathbf{z} \in \mathcal{Q}(2, 3)\) for a two-dimensional integral with three nodes per dimension (Panel A). Adaption occurs based on the mode (Panel B) and covariance of the integrand via either the Cholesky (Panel C) or spectral (Panel D) decomposition of the inverse curvature at the mode. Here, the integrand is \(f(z_1, z_2) = \text{sn}(0.5 z_1, \alpha = 2) \cdot \text{sn}(0.8 z_1 - 0.5 z_2, \alpha = -2)\), where \(\text{sn}(\cdot)\) is the standard skewnormal probability density function with shape parameter \(\alpha \in \mathbb{R}\)." width="95%" />
<p class="caption">
Figure 6.3: The Gauss-Hermite quadrature nodes <span class="math inline">\(\mathbf{z} \in \mathcal{Q}(2, 3)\)</span> for a two-dimensional integral with three nodes per dimension (Panel A). Adaption occurs based on the mode (Panel B) and covariance of the integrand via either the Cholesky (Panel C) or spectral (Panel D) decomposition of the inverse curvature at the mode. Here, the integrand is <span class="math inline">\(f(z_1, z_2) = \text{sn}(0.5 z_1, \alpha = 2) \cdot \text{sn}(0.8 z_1 - 0.5 z_2, \alpha = -2)\)</span>, where <span class="math inline">\(\text{sn}(\cdot)\)</span> is the standard skewnormal probability density function with shape parameter <span class="math inline">\(\alpha \in \mathbb{R}\)</span>.
</p>
</div>
<p>Two alternatives for the matrix decomposition <span class="math inline">\(\hat{\boldsymbol{\mathbf{H}}}^{-1} = \hat{\mathbf{P}} \hat{\mathbf{P}}^\top\)</span> are the Cholesky and spectral decomposition <span class="citation">(<a href="#ref-jackel2005note">Jäckel 2005</a>)</span>.
For the Cholesky decomposition <span class="math inline">\(\hat{\mathbf{P}} = \hat{\mathbf{L}}\)</span>, where
<span class="math display">\[\begin{equation}
\hat{\mathbf{L}} =
\begin{pmatrix}
L_{11} &amp; 0 &amp; \cdots &amp; 0 \\
\hat{L}_{12} &amp; \hat{L}_{22} &amp; \ddots &amp; \vdots \\
\vdots &amp; \ddots&amp; \ddots&amp; 0 \\
\hat{L}_{1d} &amp; \ldots&amp; \hat{L}_{(d-1)d} &amp; \hat{L}_{dd}\\
\end{pmatrix}
\end{equation}\]</span>
is a lower triangular matrix.
For the spectral decomposition <span class="math inline">\(\hat{\mathbf{P}} = \hat{\mathbf{E}} \hat{\mathbf{\Lambda}}^{1/2}\)</span>, where <span class="math inline">\(\hat{\mathbf{E}} = (\hat{\mathbf{e}}_{1}, \ldots \hat{\mathbf{e}}_{d})\)</span> contains the eigenvectors of <span class="math inline">\(\hat{\mathbf{H}}^{-1}\)</span> and <span class="math inline">\(\hat{\mathbf{\Lambda}}\)</span> is a diagonal matrix containing its eigenvalues <span class="math inline">\((\hat \lambda_{1}, \ldots, \hat \lambda_{d})\)</span>.
Figure <a href="naomi-aghq.html#fig:aghq-demo">6.3</a> demonstrates GHQ and AGHQ for a two-dimensional example, using both decomposition approaches.
Using the Cholesky decomposition results in adapted quadrature nodes which collapse along one of the dimensions, as a result of the matrix <span class="math inline">\(\hat{\mathbf{L}}\)</span> being lower triangular.
On the other hand, using the spectral decomposition results in adapted quadrature nodes which lie along the orthogonal eigenvectors of <span class="math inline">\(\hat{\mathbf{H}}^{-1}\)</span>.</p>
<p>Using AGHQ, <span class="citation">Bilodeau, Stringer, and Tang (<a href="#ref-bilodeau2022stochastic">2022</a>)</span> provide the first stochastic convergence rate for adaptive quadrature applied to Bayesian inference.</p>
</div>
</div>
<div id="inla" class="section level3 hasAnchor" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Integrated nested Laplace approximation<a href="naomi-aghq.html#inla" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The integrated nested Laplace approximation (INLA) method <span class="citation">(<a href="#ref-rue2009approximate">Håvard Rue, Martino, and Chopin 2009</a>)</span> combines marginal Laplace approximations with quadrature to enable approximation of posterior marginal distributions.</p>
<p>Consider the marginal Laplace approximation (Section <a href="naomi-aghq.html#marginal-la">6.1.1.1</a>) for a three-stage hierarchical model given by
<span class="math display">\[\begin{equation}
\tilde p_{\texttt{LA}}(\boldsymbol{\mathbf{\theta}}, \mathbf{y}) = \frac{p(\mathbf{y}, \mathbf{x}, \boldsymbol{\mathbf{\theta}})}{\tilde p_\texttt{G}(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}, \mathbf{y})} \Big\rvert_{\mathbf{x} = \hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}})}.
\end{equation}\]</span>
To complete approximation of the posterior normalising constant, the marginal Laplace approximation can be integrated over the hyperparameters using a quadrature rule (Section <a href="naomi-aghq.html#quadrature">6.1.2</a>)
<span class="math display" id="eq:inlanormconst">\[\begin{equation}
\tilde p(\mathbf{y}) = \sum_{\mathbf{z} \in \mathcal{Q}} \tilde p_\texttt{LA}(\mathbf{z}, \mathbf{y}) \omega(\mathbf{z}). \tag{6.12}
\end{equation}\]</span>
Though any choice of quadrature rule is possible, following <span class="citation">Stringer, Brown, and Stafford (<a href="#ref-stringer2022fast">2022</a>)</span> here I consider use of AGHQ.
Let <span class="math inline">\(\mathbf{z} \in \mathcal{Q}(m, k)\)</span> be the <span class="math inline">\(m\)</span>-dimensional GHQ nodes constructed using the product rule with <span class="math inline">\(k\)</span> nodes per dimension, and <span class="math inline">\(\omega: \mathbb{R}^m \to \mathbb{R}\)</span> the corresponding weighting function.
These nodes are adapted by <span class="math inline">\(\boldsymbol{\mathbf{\theta}}(\mathbf{z}) = \hat{\mathbf{P}}_\texttt{LA} \mathbf{z} + \hat{\boldsymbol{\mathbf{\theta}}}_\texttt{LA}\)</span> where
<span class="math display">\[\begin{align}
\hat{\boldsymbol{\mathbf{\theta}}}_\texttt{LA} &amp;= \arg\max_{\boldsymbol{\mathbf{\theta}}} \log \tilde p_{\texttt{LA}}(\boldsymbol{\mathbf{\theta}}, \mathbf{y}), \\
\hat{\boldsymbol{\mathbf{H}}}_\texttt{LA} &amp;= - \frac{\partial^2}{\partial \boldsymbol{\mathbf{\theta}} \partial \boldsymbol{\mathbf{\theta}}^\top} \log \tilde p_{\texttt{LA}}(\boldsymbol{\mathbf{\theta}}, \mathbf{y}) \rvert_{\boldsymbol{\mathbf{\theta}} = \hat{\boldsymbol{\mathbf{\theta}}}_\texttt{LA}}, \\
\hat{\boldsymbol{\mathbf{H}}}_\texttt{LA}^{-1} &amp;= \hat{\mathbf{P}}_\texttt{LA} \hat{\mathbf{P}}_\texttt{LA}^\top.
\end{align}\]</span>
The nested AGHQ estimate of the posterior normalising constant is then
<span class="math display" id="eq:aghqnormconst">\[\begin{equation}
\tilde p_{\texttt{AQ}}(\mathbf{y}) = | \hat{\mathbf{P}}_\texttt{LA} | \sum_{\mathbf{z} \in \mathcal{Q}(m, k)} \tilde p_\texttt{LA}(\boldsymbol{\mathbf{\theta}}(\mathbf{z}), \mathbf{y}) \omega(\mathbf{z}). \tag{6.13}
\end{equation}\]</span>
This estimate can be used to normalise the marginal Laplace approximation as follows
<span class="math display">\[\begin{equation}
\tilde p_{\texttt{LA}}(\boldsymbol{\mathbf{\theta}} \, | \, \mathbf{y}) = \frac{\tilde p_{\texttt{LA}}(\boldsymbol{\mathbf{\theta}}, \mathbf{y})}{\tilde p_{\texttt{AQ}}(\mathbf{y})}.
\end{equation}\]</span></p>
<p>The posterior marginals <span class="math inline">\(\tilde p(\theta_j \, | \, \mathbf{y})\)</span> may be obtained by
<span class="math display">\[\begin{align}
\tilde p(\theta_j \, | \, \mathbf{y}) = \int \tilde p(\theta_j \, | \, \mathbf{y}) \text{d} \boldsymbol{\mathbf{\theta}}_{-j}.
\end{align}\]</span>
These integrals may be computed by reusing the AGHQ rule.
More recent methods are discussed in Section 3.2 of <span class="citation">Martins et al. (<a href="#ref-martins2013bayesian">2013</a>)</span>.</p>
<p>Multiple methods have been proposed for obtaining the <span class="math inline">\(\tilde p(\mathbf{x} \, | \, \mathbf{y})\)</span> or individual marginals <span class="math inline">\(\tilde p(x_i \, | \, \mathbf{y})\)</span>
Four methods are presented below, trading-off accuracy with computational expense.</p>
<div id="gaussian-marginals" class="section level4 hasAnchor" number="6.1.3.1">
<h4><span class="header-section-number">6.1.3.1</span> Gaussian marginals<a href="naomi-aghq.html#gaussian-marginals" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Most easily, inferences for the latent field can be obtained by approximation of <span class="math inline">\(p(\mathbf{x} \, | \, \mathbf{y})\)</span> using another application of the quadrature rule <span class="citation">(<a href="#ref-rue2007approximate">Håvard Rue and Martino 2007</a>)</span>
<span class="math display" id="eq:mixgaussian">\[\begin{align}
p(\mathbf{x} \, | \, \mathbf{y}) &amp;= \int p(\mathbf{x}, \boldsymbol{\mathbf{\theta}} \, | \, \mathbf{y}) \text{d} \boldsymbol{\mathbf{\theta}} = \int p(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}, \mathbf{y}) p(\boldsymbol{\mathbf{\theta}} \, | \, \mathbf{y}) \text{d} \boldsymbol{\mathbf{\theta}} \\
&amp;\approx |\hat{\mathbf{P}}_\texttt{LA}| \sum_{\mathbf{z} \in \mathcal{Q}(m, k)} \tilde p_\texttt{G}(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}(\mathbf{z}), \mathbf{y}) \tilde p_\texttt{LA}(\boldsymbol{\mathbf{\theta}}(\mathbf{z}) \, | \, \mathbf{y}) \omega(\mathbf{z}). \tag{6.14}
\end{align}\]</span>
The quadrature rule <span class="math inline">\(\mathbf{z} \in \mathcal{Q}(m, k)\)</span> is used both internally to normalise the marginal Laplace approximation, and externally to perform integration with respect to the hyperparameters.
Equation <a href="naomi-aghq.html#eq:mixgaussian">(6.14)</a> is a mixture of Gaussian distributions
<span class="math display" id="eq:mixgaussian-individual">\[\begin{equation}
p_\texttt{G}(\mathbf{x} \, | \, \boldsymbol{\mathbf{\theta}}(\mathbf{z}), \mathbf{y}), \tag{6.15}
\end{equation}\]</span>
each with multinomial probabilities
<span class="math display">\[\begin{equation}
\lambda(\mathbf{z}) = |\hat{\mathbf{P}}_\texttt{LA}| \tilde p_\texttt{LA}(\boldsymbol{\mathbf{\theta}}(\mathbf{z}) \, | \, \mathbf{y}) \omega(\mathbf{z}),
\end{equation}\]</span>
where <span class="math inline">\(\sum \lambda(\mathbf{z}) = 1\)</span> and <span class="math inline">\(\lambda(\mathbf{z}) &gt; 0\)</span>.
Samples may therefore be naturally obtained for the complete vector <span class="math inline">\(\mathbf{x}\)</span> jointly by first drawing a node <span class="math inline">\(\mathbf{z} \in \mathcal{Q}(m, k)\)</span> with multinomial probabilities <span class="math inline">\(\lambda(\mathbf{z})\)</span> then drawing a sample from the corresponding Gaussian distribution in Equation <a href="naomi-aghq.html#eq:mixgaussian-individual">(6.15)</a>.
Algorithms for fast and exact simulation from a Gaussian distribution have been developed, including by <span class="citation">Håvard Rue (<a href="#ref-rue2001fast">2001</a>)</span>.
The posterior marginals for any subset of the complete vector can simply be obtained by keeping the relevant entries of <span class="math inline">\(\mathbf{x}\)</span>.</p>
</div>
<div id="laplace-marginals" class="section level4 hasAnchor" number="6.1.3.2">
<h4><span class="header-section-number">6.1.3.2</span> Laplace marginals<a href="naomi-aghq.html#laplace-marginals" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>An alternative higher accuracy, but more computationally expensive, approach is to calculate a Laplace approximation to the marginal posterior
<span class="math display" id="eq:lamarginaljoint">\[\begin{equation}
\tilde p_\texttt{LA}(x_i, \boldsymbol{\mathbf{\theta}}, \mathbf{y}) = \frac{p(x_i, \mathbf{x}_{-i}, \boldsymbol{\mathbf{\theta}}, \mathbf{y})}{\tilde p_\texttt{G}(\mathbf{x}_{-i} \, | \, x_i, \boldsymbol{\mathbf{\theta}}, \mathbf{y})} \Big\rvert_{\mathbf{x}_{-i} = \hat{\mathbf{x}}_{-i}(x_i, \boldsymbol{\mathbf{\theta}})}. \tag{6.16}
\end{equation}\]</span>
Here, the variable <span class="math inline">\(x_i\)</span> is excluded from the Gaussian approximation such that
<span class="math display">\[\begin{equation}
p_\texttt{G}(\mathbf{x}_{-i} \, | \, x_i, \boldsymbol{\mathbf{\theta}}, \mathbf{y}) = \mathcal{N}(\mathbf{x}_{-i} \, | \, \hat{\mathbf{x}}_{-i}(x_i, \boldsymbol{\mathbf{\theta}}), \hat{\mathbf{H}}_{-i, -i}(x_i, \boldsymbol{\mathbf{\theta}})),
\end{equation}\]</span>
with <span class="math inline">\((N - 1)\)</span>-dimensional posterior mode
<span class="math display">\[\begin{equation}
\hat{\mathbf{x}}_{-i}(x_i, \boldsymbol{\mathbf{\theta}}) = \arg\max_{\mathbf{x}_{-i}} \log p(\mathbf{y}, x_i, \mathbf{x}_{-i}, \boldsymbol{\mathbf{\theta}}),
\end{equation}\]</span>
and <span class="math inline">\((N - 1) \times (N - 1)\)</span>-dimensional Hessian matrix evaluated at the posterior mode
<span class="math display">\[\begin{equation}
\hat{\mathbf{H}}_{-i, -i}(x_i, \boldsymbol{\mathbf{\theta}}) = - \frac{\partial^2}{\partial \mathbf{x}_{-i} \partial \mathbf{x}_{-i}^\top} \log p(\mathbf{y}, x_i, \mathbf{x}_{-i}, \boldsymbol{\mathbf{\theta}}) \rvert_{\mathbf{x}_{-i} = \hat{\mathbf{x}}_{-i}(x_i, \boldsymbol{\mathbf{\theta}})}.
\end{equation}\]</span>
The approximate posterior marginal <span class="math inline">\(\tilde p(x_i \, | \, \mathbf{y})\)</span> can be obtained by first normalsiing the marginal Laplace approximation in Equation <a href="naomi-aghq.html#eq:lamarginaljoint">(6.16)</a>
<span class="math display">\[\begin{equation}
\tilde p_\texttt{LA}(x_i, \boldsymbol{\mathbf{\theta}} \, | \, \mathbf{y}) = \frac{\tilde p_\texttt{LA}(x_i, \boldsymbol{\mathbf{\theta}}, \mathbf{y})}{\tilde p(\mathbf{y})}
\end{equation}\]</span>
In the denominator, the previously obtained estimate of the evidence in Equation <a href="naomi-aghq.html#eq:aghqnormconst">(6.13)</a> may be reused.
Alternatively, a new estimate may be computed.
Then, integration with respect to the hyperparameters may be performed, similarly to Equation <a href="naomi-aghq.html#eq:mixgaussian">(6.14)</a>
<span class="math display" id="eq:lamarginal">\[\begin{align}
p(x_i \, | \, \mathbf{y}) &amp;= \int p(x_i, \boldsymbol{\mathbf{\theta}} \, | \, \mathbf{y}) \text{d} \boldsymbol{\mathbf{\theta}} = \int p(x_i \, | \, \boldsymbol{\mathbf{\theta}}, \mathbf{y}) p(\boldsymbol{\mathbf{\theta}} \, | \, \mathbf{y}) \text{d} \boldsymbol{\mathbf{\theta}} \\
&amp;\approx |\hat{\mathbf{P}}_\texttt{LA}| \sum_{\mathbf{z} \in \mathcal{Q}(m, k)} \tilde p_\texttt{LA}(x_i \, | \, \boldsymbol{\mathbf{\theta}}(\mathbf{z}), \mathbf{y}) \tilde p_\texttt{LA}(\boldsymbol{\mathbf{\theta}}(\mathbf{z}) \, | \, \mathbf{y}) \omega(\mathbf{z}). \tag{6.17}
\end{align}\]</span></p>
<p>Equation <a href="naomi-aghq.html#eq:lamarginal">(6.17)</a> is a mixture of the normalised Laplace approximations <span class="math inline">\(\tilde p_\texttt{LA}(x_i, \boldsymbol{\mathbf{\theta}} \, | \, \mathbf{y})\)</span> over the hyperparameter quadrature nodes.
However, unlike the Gaussian case (Section <a href="naomi-aghq.html#gaussian-marginals">6.1.3.1</a>) it is not easy to directly sample each Laplace approximation.
As such, Equation <a href="naomi-aghq.html#eq:lamarginal">(6.17)</a> may be represented by its evaluation at a number of nodes, such as those from an AGHQ rule.</p>
</div>
<div id="simplified-laplace-marginals" class="section level4 hasAnchor" number="6.1.3.3">
<h4><span class="header-section-number">6.1.3.3</span> Simplified Laplace marginals<a href="naomi-aghq.html#simplified-laplace-marginals" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>When the latent field <span class="math inline">\(\mathbf{x}\)</span> is a Gauss-Markov random fields [GMRF; <span class="citation">Havard Rue and Held (<a href="#ref-rue2005gaussian">2005</a>)</span>] it is possible to efficiently approximate the Laplace marginals in Section <a href="naomi-aghq.html#laplace-marginals">6.1.3.2</a>.
The simplified approximation is achieved by a Taylor expansion on the numerator and denominator of Equation <a href="naomi-aghq.html#eq:lamarginaljoint">(6.16)</a> up to third order.
The approach is analogous to correcting the Gaussian approximation in Section <a href="naomi-aghq.html#gaussian-marginals">6.1.3.1</a> for location and skewness.
Details are left to Section 3.2.3 of <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span>.</p>
</div>
<div id="simplified-inla" class="section level4 hasAnchor" number="6.1.3.4">
<h4><span class="header-section-number">6.1.3.4</span> Simplified INLA<a href="naomi-aghq.html#simplified-inla" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="citation">Wood (<a href="#ref-wood2020simplified">2020</a>)</span> describe a method for approximating the Laplace marginals without depending on the Markov structure, while still achieving equivalent efficiency.
This work was motivated by the spline setting, which similar to the extended latent Gaussian models [ELGMs; <span class="citation">Stringer, Brown, and Stafford (<a href="#ref-stringer2022fast">2022</a>)</span>] setting, results in precision matrices which are not as sparse.
Details are left to <span class="citation">Wood (<a href="#ref-wood2020simplified">2020</a>)</span>.</p>
</div>
<div id="inclusion-of-the-structured-additive-predictor-in-the-latent-field" class="section level4 hasAnchor" number="6.1.3.5">
<h4><span class="header-section-number">6.1.3.5</span> Inclusion of the structured additive predictor in the latent field<a href="naomi-aghq.html#inclusion-of-the-structured-additive-predictor-in-the-latent-field" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This section is concluded by briefly discussing inclusion or exclusion of the structured additive predictor within the latent field.
The issue relates to the sparsity structure of
<span class="math display">\[\begin{align}
\hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}}) &amp;= \arg\max_{\mathbf{x}} h(\mathbf{x}, \boldsymbol{\mathbf{\theta}}), \\
\hat {\mathbf{H}}(\boldsymbol{\mathbf{\theta}}) &amp;= - \frac{\partial^2}{\partial \mathbf{x} \partial \mathbf{x}^\top} h(\mathbf{x}, \boldsymbol{\mathbf{\theta}}) \rvert_{\mathbf{x} = \hat{\mathbf{x}}(\boldsymbol{\mathbf{\theta}})}.
\end{align}\]</span>
The modified model used by <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span> is
<span class="math display">\[\begin{align}
\boldsymbol{\mathbf{\eta}}^\star &amp;= \boldsymbol{\mathbf{\eta}} + \boldsymbol{\mathbf{\epsilon}}, \\
\boldsymbol{\mathbf{\epsilon}} &amp;\sim \mathcal{N}(\mathbf{0}, \tau^{-1} \mathbf{I}_n), \\
\mathbf{x}^\star &amp;= (\boldsymbol{\mathbf{\eta}}^\star, \mathbf{x}) \sim \mathcal{N}(\cdots).
\end{align}\]</span>
<span class="citation">Stringer, Brown, and Stafford (<a href="#ref-stringer2022fast">2022</a>)</span> note that this doesn’t work as well for ELGMs.
Discussed in <span class="citation">Van Niekerk et al. (<a href="#ref-van2023new">2023</a>)</span>.</p>
</div>
</div>
<div id="software" class="section level3 hasAnchor" number="6.1.4">
<h3><span class="header-section-number">6.1.4</span> Software<a href="naomi-aghq.html#software" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="r-inla" class="section level4 hasAnchor" number="6.1.4.1">
<h4><span class="header-section-number">6.1.4.1</span> <code>R-INLA</code><a href="naomi-aghq.html#r-inla" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <code>R-INLA</code> software <span class="citation">(<a href="#ref-martins2013bayesian">Martins et al. 2013</a>)</span> implements the INLA method, as well as the stochastic partial differential equation (SPDE) approach of <span class="citation">Lindgren, Rue, and Lindström (<a href="#ref-lindgren2011explicit">2011</a>)</span>.
<code>R-INLA</code> is the R interface to the core <code>inla</code> program, which is written in C <span class="citation">(<a href="#ref-martino2009implementing">Martino and Rue 2009</a>)</span> and uses algorithms from the <code>GMRFLib</code> C library <span class="citation">(<a href="#ref-rue2001gmrflib">Håvard Rue and Follestad 2001</a>)</span>.
First and second derivatives are obtained in <code>R-INLA</code> numerically using central finite differences <span class="citation">(<a href="#ref-fattah2021smart">Fattah, Van Niekerk, and Rue 2021</a>)</span>.
For a review recent computational features of <code>R-INLA</code>, including parallelism via <code>OpenMP</code> <span class="citation">(<a href="#ref-diaz2018openmp">Diaz et al. 2018</a>)</span> and use of the PARDISO sparse linear equation solver <span class="citation">(<a href="#ref-bollhofer2020state">Bollhöfer et al. 2020</a>)</span>, see <span class="citation">Gaedke-Merzhäuser et al. (<a href="#ref-gaedke2023parallelized">2023</a>)</span>.
Further information about <code>R-INLA</code>, including recent developments, can be found at <a href="https://r-inla.org"><code>https://r-inla.org</code></a>.</p>
<p>A formula interface of the form <code>y ~ ...</code>, similar to that used in the <code>lm</code> function in the core <code>stats</code> R package, is used to specify the connection between the latent field <span class="math inline">\(\mathbf{x}\)</span> and the structured additive predictor <span class="math inline">\(\boldsymbol{\mathbf{\eta}}\)</span>.
For a model with one fixed effect <code>a</code> and one IID random effect <code>b</code>, the formula would be written as <code>y ~ a + f(b, model = "iid")</code>.
This interface is easy to engage with for new users, but can be limiting for more advanced users.</p>
<p>The approach used to compute the marginals <span class="math inline">\(\tilde p(x_i \, | \, \mathbf{y})\)</span> can chosen by setting <code>method</code> to <code>"gaussian"</code> (Section <a href="naomi-aghq.html#gaussian-marginals">6.1.3.1</a>), <code>"laplace"</code> (Section <a href="naomi-aghq.html#laplace-marginals">6.1.3.2</a>) or <code>simplified.laplace</code> (Section <a href="naomi-aghq.html#simplified-laplace-marginals">6.1.3.3</a>).
The quadrature grid used can be chosen by setting <code>int.strategy</code> to <code>"eb"</code> (empirical Bayes, one quadrature node), <code>"grid"</code> (a dense grid), or <code>"ccd"</code> [Box-Wilson central composite design; <span class="citation">Box and Wilson (<a href="#ref-box1992experimental">1992</a>)</span>].
Figure <a href="naomi-aghq.html#fig:inla-grid-demo">6.4</a> demonstrates the latter two integration strategies.
By default, the <code>"grid"</code> strategy is used for <span class="math inline">\(m \leq 2\)</span> and the <code>"ccd"</code> strategy is used for <span class="math inline">\(m &gt; 2\)</span>.</p>
<p>Various software packages have been built using <code>R-INLA</code>.
Perhaps the most substantial of which is the <code>inlabru</code> R package <span class="citation">(<a href="#ref-bachl2019inlabru">Bachl et al. 2019</a>)</span>, which provides a simplified syntax, and capabilities for fitting more general non-linear structured additive predictor expressions via linearisation and repeat use of <code>R-INLA</code>.</p>
<!-- Note: does the CCD need to have weights added? -->

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:inla-grid-demo"></span>
<img src="figures/naomi-aghq/inla-grid-demo.png" alt="Consider the function \(f(z_1, z_2) = \text{sn}(0.5 z_1, \alpha = 2) \cdot \text{sn}(0.8 z_1 - 0.5 z_2, \alpha = -2)\) as described in Figure 6.3. Panel A shows the grid method as used in R-INLA and detailed in Section 3.1 of Håvard Rue, Martino, and Chopin (2009). Briefly, equally-weighted quadrature points are generated by starting at the mode and taking steps of size \(\delta_z\) along each eigenvector of the inverse curvature at the mode, scaled by the eigenvalues, until the difference in log-scale function evaluations (compared to the mode) is below a threshold \(\delta_\pi\). Intermediate values are included if they have sufficient log-scale function evaluation. Here, I set \(\delta_z = 0.75\) and \(\delta_\pi = 2\). Panel B shows a CCD as used in R-INLA and detailed in Section 6.5 of Håvard Rue, Martino, and Chopin (2009). The CCD was generated using the rsm R package (Lenth 2009), and is comprised of: one centre point; four factorial points, used to help estimate linear effects; and four star points, used to help estimate the curvature." width="95%" />
<p class="caption">
Figure 6.4: Consider the function <span class="math inline">\(f(z_1, z_2) = \text{sn}(0.5 z_1, \alpha = 2) \cdot \text{sn}(0.8 z_1 - 0.5 z_2, \alpha = -2)\)</span> as described in Figure <a href="naomi-aghq.html#fig:aghq-demo">6.3</a>. Panel A shows the grid method as used in <code>R-INLA</code> and detailed in Section 3.1 of <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span>. Briefly, equally-weighted quadrature points are generated by starting at the mode and taking steps of size <span class="math inline">\(\delta_z\)</span> along each eigenvector of the inverse curvature at the mode, scaled by the eigenvalues, until the difference in log-scale function evaluations (compared to the mode) is below a threshold <span class="math inline">\(\delta_\pi\)</span>. Intermediate values are included if they have sufficient log-scale function evaluation. Here, I set <span class="math inline">\(\delta_z = 0.75\)</span> and <span class="math inline">\(\delta_\pi = 2\)</span>. Panel B shows a CCD as used in <code>R-INLA</code> and detailed in Section 6.5 of <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span>. The CCD was generated using the <code>rsm</code> R package <span class="citation">(<a href="#ref-lenth2009rsm">Lenth 2009</a>)</span>, and is comprised of: one centre point; four factorial points, used to help estimate linear effects; and four star points, used to help estimate the curvature.
</p>
</div>
</div>
<div id="tmb" class="section level4 hasAnchor" number="6.1.4.2">
<h4><span class="header-section-number">6.1.4.2</span> <code>TMB</code><a href="naomi-aghq.html#tmb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Template Model Builder [<code>TMB</code>; <span class="citation">Kristensen et al. (<a href="#ref-kristensen2016tmb">2016</a>)</span>] is an R package which implements the Laplace approximation.
In <code>TMB</code> derivatives are obtained using automatic differentiation, also known as algorithmic differentiation [AD; <span class="citation">Baydin et al. (<a href="#ref-baydin2017automatic">2017</a>)</span>].
The approach of AD is to decompose any function into a sequence of elementary operations with known derivatives.
These derivatives may then be composed by repeat use of the chain rule to obtain the function’s derivative.
<code>TMB</code> uses the C++ package <code>CppAD</code> <span class="citation">(<a href="#ref-cppaddocumentation">Bell 2023</a>)</span> for AD.
Details are provided in Section 3 of <span class="citation">Kristensen et al. (<a href="#ref-kristensen2016tmb">2016</a>)</span>.</p>
<p>Whereas <code>R-INLA</code> requires to sparsity structure to be known in advance, <code>TMB</code> uses an algorithm to automatically determine the sparsity structure [Section 4.2; <span class="citation">Kristensen et al. (<a href="#ref-kristensen2016tmb">2016</a>)</span>]
The R package <code>Matrix</code> and C++ package <code>Eigen</code> are then used for sparse and dense matrix calculations.</p>
<p>Models are specified in <code>TMB</code> using a C++ template file which evaluates <span class="math inline">\(\log p(\mathbf{y}, \mathbf{x}, \boldsymbol{\mathbf{\theta}})\)</span>.
Other software packages have been developed which also use <code>TMB</code> C++ templates.
The <code>tmbstan</code> R package <span class="citation">(<a href="#ref-monnahan2018no">Monnahan and Kristensen 2018</a>)</span> allows running the Hamiltonian Monte Carlo (HMC) algorithm via <code>Stan</code>.
The <code>aghq</code> R package <span class="citation">(<a href="#ref-stringer2021implementing">Stringer 2021b</a>)</span> allows use of AGHQ, and AGHQ over the marginal Laplace approximation, via the <code>mvQuad</code> R package <span class="citation">(<a href="#ref-weiser2016mvquad">Weiser 2016</a>)</span>.
The <code>glmmTMB</code> R package <span class="citation">(<a href="#ref-brooks2017glmmtmb">Brooks et al. 2017</a>)</span> allows specification of common GLMM models via a formula interface.
It is also possible to extract the <code>TMB</code> objective function used by <code>glmmTMB</code>, which may then be passed into <code>aghq</code> or <code>tmbstan</code>.</p>
<!-- Could cite @bolker2013strategies. -->
<!-- An important design feature of `TMB` is its modularity. -->
</div>
<div id="other-software" class="section level4 hasAnchor" number="6.1.4.3">
<h4><span class="header-section-number">6.1.4.3</span> Other software<a href="naomi-aghq.html#other-software" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <code>mgcv</code> [Mixed GAM computation vehicle; <span class="citation">Wood (<a href="#ref-wood2017generalized">2017</a>)</span>] R package estimates generalised additive models (GAMs) specified using a formula interface.
This package is briefly mentioned so as to note that the function <code>mgcv::ginla</code> implements the simplified INLA approach of <span class="citation">Wood (<a href="#ref-wood2020simplified">2020</a>)</span> as described in Section <a href="naomi-aghq.html#simplified-inla">6.1.3.4</a>.</p>
</div>
</div>
</div>
<div id="universal" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> A universal INLA implementation<a href="naomi-aghq.html#universal" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section is about implementation of the INLA method using the <code>TMB</code> package, with both Gaussian and Laplace marginals.
The implementation can be described as “universal” in that it is compatible with any model with a <code>TMB</code> C++ template, rather than being based on a more restrictive formula interface <span class="citation">(<a href="#ref-vstrumbelj2023past">Štrumbelj et al. 2023</a>)</span>.
<!-- A probabilistic programming language can be said to be universal when it is Turing complete. --></p>
<p><span class="citation">Martino and Riebler (<a href="#ref-martino2019integrated">2019</a>)</span> note that “implementing INLA from scratch is a complex task” and as a result “applications of INLA are limited to the (large class of) models implemented [in <code>R-INLA</code>]”.
A universal INLA implementation facilitates application of the method to models which are not compatible with <code>R-INLA</code>, including Naomi as one among many examples.
The potential benefits of a more flexible INLA implementation based on AD were noted by <span class="citation">Skaug (<a href="#ref-skaug2009approximate">2009</a>)</span> (a coauthor of <code>TMB</code>) in discussion of <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span>, who noted that such a system would be “fast, flexible, and easy-to-use”, as well as “automatic from a user’s perspective”.
As this suggestion was made close to 15 years ago, it is surprising that its potential remains unrealised.</p>
<p>I demonstrate the universal implementation with two examples:</p>
<ol style="list-style-type: decimal">
<li>Section <a href="naomi-aghq.html#epil">6.2.1</a> considers a generalised linear mixed model (GLMM) of an epilepsy drug.
This example was used in Section 5.2 of <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span>, and the model is compatible with <code>R-INLA</code>.
For some parameters there is a notable difference in approximation error depending on use of Gaussian (Section) or Laplace (Section) marginals.
This example is therefore used to demonstrate the correspondence between my Laplace marginal implementation, and that of <code>R-INLA</code> with <code>method</code> set to <code>"laplace"</code>.</li>
<li>Section <a href="naomi-aghq.html#unknown">6.2.2</a> considers a model which is not is not compatible with <code>R-INLA</code>.
This example is used as a demonstration of the benefit of a more generally applicable INLA implementation.</li>
</ol>
<div id="epil" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Epilepsy GLMM<a href="naomi-aghq.html#epil" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a GLMM for an epilepsy drug double-blind clinical trial <span class="citation">(<a href="#ref-leppik1985double">Leppik et al. 1985</a>)</span>.
The original model of <span class="citation">Thall and Vail (<a href="#ref-thall1990some">1990</a>)</span> was modified by <span class="citation">Breslow and Clayton (<a href="#ref-breslow1993approximate">1993</a>)</span> and widely disseminated as a part of the BUGS [Bayesian inference using Gibbs sampling; <span class="citation">D. Spiegelhalter et al. (<a href="#ref-spiegelhalter1996bugs">1996</a>)</span>] manual.
Patients <span class="math inline">\(i = 1, \ldots, 59\)</span> were each assigned either a new drug <span class="math inline">\(\texttt{Trt}_i = 1\)</span> or a placebo <span class="math inline">\(\texttt{Trt}_i = 0\)</span>.
Each patient made four visits the clinic <span class="math inline">\(j = 1, \ldots, 4\)</span>, and the observations <span class="math inline">\(y_{ij}\)</span> are the number of seizures of the <span class="math inline">\(i\)</span>th person in the two weeks preceding their <span class="math inline">\(j\)</span>th clinic visit.
The covariates used in the model were baseline seizure counts <span class="math inline">\(\texttt{Base}_i\)</span>, treatment <span class="math inline">\(\texttt{Trt}_i\)</span>, age <span class="math inline">\(\texttt{Age}_i\)</span>, and an indicator for the final clinic visit <span class="math inline">\({\texttt{V}_4}_j\)</span>.
Each of the covariates were centred.
The observations were modelled using a Poisson distribution
<span class="math display">\[\begin{equation}
y_{ij} \sim \text{Poisson}(e^{\eta_{ij}}),
\end{equation}\]</span>
with structured additive predictor
<span class="math display" id="eq:epil">\[\begin{align}
\eta_{ij}
&amp;= \beta_0 + \beta_\texttt{Base} \log(\texttt{Base}_i / 4) + \beta_\texttt{Trt} \texttt{Trt}_i +
   \beta_{\texttt{Trt} \times \texttt{Base}} (\texttt{Trt}_i \times \log(\texttt{Base}_i / 4)) \\
&amp;+ \beta_\texttt{Age} \log(\texttt{Age}_i) + \beta_{\texttt{V}_4} {\texttt{V}_4}_j +
   \epsilon_i + \nu_{ij}, \quad i \in [59], \quad j \in [4]. \tag{6.18}
\end{align}\]</span>
The prior distribution on each of the regression parameters, including the intercept <span class="math inline">\(\beta_0\)</span>, was <span class="math inline">\(\mathcal{N}(0, 100^2)\)</span>.
The patient <span class="math inline">\(\epsilon_i \sim \mathcal{N}(0, 1/\tau_\epsilon)\)</span> and patient-visit <span class="math inline">\(\nu_{ij} \sim \mathcal{N}(0, 1/\tau_\nu)\)</span> random effects were IID with gamma precision prior distributions <span class="math inline">\(\tau_\epsilon, \tau_\nu \sim \Gamma(0.001, 0.001)\)</span>.</p>

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:epil"></span>
<img src="figures/naomi-aghq/epil.png" alt="The number of seizures in the treatment group was fewer, on average, than the number of seizures in the control group. This is not sufficient to conclude that the treatment was effective. The GLMM accounts for differences between the treatment and control group, including in baseline seizures and age, and so can be used to help estimate a causal treatment effect." width="95%" />
<p class="caption">
Figure 6.5: The number of seizures in the treatment group was fewer, on average, than the number of seizures in the control group. This is not sufficient to conclude that the treatment was effective. The GLMM accounts for differences between the treatment and control group, including in baseline seizures and age, and so can be used to help estimate a causal treatment effect.
</p>
</div>
<p>I consider inference for the epilepsy GLMM using a range of approaches:</p>
<ol style="list-style-type: decimal">
<li>INLA with <code>R-INLA</code> (Section <a href="naomi-aghq.html#epil-inla">6.2.1.1</a>).</li>
<li>Gaussian marginals and EB with <code>TMB</code> (Section <a href="naomi-aghq.html#epil-gauss-eb-tmb">6.2.1.2</a>).</li>
<li>Gaussian marginals and AGHQ with <code>aghq</code> (Section <a href="naomi-aghq.html#epil-gauss-aghq-tmb">6.2.1.3</a>).</li>
<li>Laplace marginals and EB with <code>TMB</code> (Section <a href="naomi-aghq.html#epil-laplace-eb-tmb">6.2.1.4</a>).</li>
<li>Laplace marginals and AGHQ with <code>TMB</code> (Section <a href="naomi-aghq.html#epil-laplace-aghq-tmb">6.2.1.5</a>).</li>
<li>NUTS with <code>tmbstan</code> (Section <a href="naomi-aghq.html#epil-nuts">6.2.1.6</a>).</li>
</ol>
<p>These approaches are compared in Section <a href="naomi-aghq.html#epil-comparison">6.2.1.8</a>.
The foremost objective is to demonstrate correspondence between inferences obtained from <code>R-INLA</code> and those from <code>TMB</code>.
Illustrative code is used throughout this section, and will not be used in future sections.</p>
<div id="epil-inla" class="section level4 hasAnchor" number="6.2.1.1">
<h4><span class="header-section-number">6.2.1.1</span> INLA with <code>R-INLA</code><a href="naomi-aghq.html#epil-inla" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The epilepsy data are available from the <code>R-INLA</code> package.
The covariates may be obtained by:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="naomi-aghq.html#cb1-1" tabindex="-1"></a>centre <span class="ot">&lt;-</span> <span class="cf">function</span>(x) (x <span class="sc">-</span> <span class="fu">mean</span>(x))</span>
<span id="cb1-2"><a href="naomi-aghq.html#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="naomi-aghq.html#cb1-3" tabindex="-1"></a>Epil <span class="ot">&lt;-</span> Epil <span class="sc">%&gt;%</span></span>
<span id="cb1-4"><a href="naomi-aghq.html#cb1-4" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">CTrt    =</span> <span class="fu">centre</span>(Trt),</span>
<span id="cb1-5"><a href="naomi-aghq.html#cb1-5" tabindex="-1"></a>         <span class="at">ClBase4 =</span> <span class="fu">centre</span>(<span class="fu">log</span>(Base<span class="sc">/</span><span class="dv">4</span>)),</span>
<span id="cb1-6"><a href="naomi-aghq.html#cb1-6" tabindex="-1"></a>         <span class="at">CV4     =</span> <span class="fu">centre</span>(V4),</span>
<span id="cb1-7"><a href="naomi-aghq.html#cb1-7" tabindex="-1"></a>         <span class="at">ClAge   =</span> <span class="fu">centre</span>(<span class="fu">log</span>(Age)),</span>
<span id="cb1-8"><a href="naomi-aghq.html#cb1-8" tabindex="-1"></a>         <span class="at">CBT     =</span> <span class="fu">centre</span>(Trt <span class="sc">*</span> <span class="fu">log</span>(Base<span class="sc">/</span><span class="dv">4</span>)))</span></code></pre></div>
<p>The structured additive predictor (Equation <a href="naomi-aghq.html#eq:epil">(6.18)</a>) is then specified by:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="naomi-aghq.html#cb2-1" tabindex="-1"></a>formula <span class="ot">&lt;-</span> y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> CTrt <span class="sc">+</span> ClBase4 <span class="sc">+</span> CV4 <span class="sc">+</span> ClAge <span class="sc">+</span> CBT <span class="sc">+</span></span>
<span id="cb2-2"><a href="naomi-aghq.html#cb2-2" tabindex="-1"></a>  <span class="fu">f</span>(rand, <span class="at">model =</span> <span class="st">&quot;iid&quot;</span>, <span class="at">hyper =</span> tau_prior) <span class="sc">+</span>  </span>
<span id="cb2-3"><a href="naomi-aghq.html#cb2-3" tabindex="-1"></a>  <span class="fu">f</span>(Ind,  <span class="at">model =</span> <span class="st">&quot;iid&quot;</span>, <span class="at">hyper =</span> tau_prior)</span></code></pre></div>
<p>The object <code>tau_prior</code> specifies the <span class="math inline">\(\Gamma(0.001, 0.001)\)</span> precision prior:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="naomi-aghq.html#cb3-1" tabindex="-1"></a>tau_prior <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">prec =</span> <span class="fu">list</span>(</span>
<span id="cb3-2"><a href="naomi-aghq.html#cb3-2" tabindex="-1"></a>  <span class="at">prior =</span> <span class="st">&quot;loggamma&quot;</span>,</span>
<span id="cb3-3"><a href="naomi-aghq.html#cb3-3" tabindex="-1"></a>  <span class="at">param =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.001</span>),</span>
<span id="cb3-4"><a href="naomi-aghq.html#cb3-4" tabindex="-1"></a>  <span class="at">initial =</span> <span class="dv">1</span>,</span>
<span id="cb3-5"><a href="naomi-aghq.html#cb3-5" tabindex="-1"></a>  <span class="at">fixed =</span> <span class="cn">FALSE</span>)</span>
<span id="cb3-6"><a href="naomi-aghq.html#cb3-6" tabindex="-1"></a>)</span></code></pre></div>
<p>Inference may then be performed, specifying the latent field posterior marginals approach <code>strat</code> and quadrature approach <code>int_strat</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="naomi-aghq.html#cb4-1" tabindex="-1"></a>beta_prior <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">prec =</span> <span class="dv">1</span> <span class="sc">/</span> <span class="dv">100</span><span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb4-2"><a href="naomi-aghq.html#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="naomi-aghq.html#cb4-3" tabindex="-1"></a>epil_inla <span class="ot">&lt;-</span> <span class="cf">function</span>(strat, int_strat) {</span>
<span id="cb4-4"><a href="naomi-aghq.html#cb4-4" tabindex="-1"></a>  <span class="fu">inla</span>(</span>
<span id="cb4-5"><a href="naomi-aghq.html#cb4-5" tabindex="-1"></a>    formula,</span>
<span id="cb4-6"><a href="naomi-aghq.html#cb4-6" tabindex="-1"></a>    <span class="at">control.fixed =</span> beta_prior,</span>
<span id="cb4-7"><a href="naomi-aghq.html#cb4-7" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;poisson&quot;</span>,</span>
<span id="cb4-8"><a href="naomi-aghq.html#cb4-8" tabindex="-1"></a>    <span class="at">data =</span> Epil,</span>
<span id="cb4-9"><a href="naomi-aghq.html#cb4-9" tabindex="-1"></a>    <span class="at">control.inla =</span> <span class="fu">list</span>(<span class="at">strategy =</span> strat, <span class="at">int.strategy =</span> int_strat),</span>
<span id="cb4-10"><a href="naomi-aghq.html#cb4-10" tabindex="-1"></a>    <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb4-11"><a href="naomi-aghq.html#cb4-11" tabindex="-1"></a>  )</span>
<span id="cb4-12"><a href="naomi-aghq.html#cb4-12" tabindex="-1"></a>}</span></code></pre></div>
<p>The object <code>beta_prior</code> specifies the <span class="math inline">\(\mathcal{N}(0, 100^2)\)</span> regression coefficient prior.
The Poisson likelihood is specified via the <code>family</code> argument.
Inferences may be then obtained via the <code>fit</code> object:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="naomi-aghq.html#cb5-1" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">epil_inla</span>(<span class="at">strat =</span> <span class="st">&quot;gaussian&quot;</span>, <span class="at">int_strat =</span> <span class="st">&quot;grid&quot;</span>)</span></code></pre></div>
<p>As described in Section <a href="naomi-aghq.html#r-inla">6.1.4.1</a>, <code>strat</code> may be set to one of <code>"gaussian"</code>, <code>"laplace"</code>, or <code>"simplified.laplace"</code> and <code>int_strat</code> may be set to one of <code>"eb"</code>, <code>"grid"</code>, or <code>"ccd"</code>.</p>
</div>
<div id="epil-gauss-eb-tmb" class="section level4 hasAnchor" number="6.2.1.2">
<h4><span class="header-section-number">6.2.1.2</span> Gaussian marginals and EB with <code>TMB</code><a href="naomi-aghq.html#epil-gauss-eb-tmb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A C++ template for the log-posterior of the model is required to obtain inferences with <code>TMB</code>.
For simple models, writing this template is usually a more involved task then specifying the formula object required for <code>R-INLA</code>.
The <code>TMB</code> C++ template <code>epil.cpp</code> for the epilepsy GLMM is in Appendix <a href="fast-approximate-bayesian-inference.html#tmb-epil">C.1.1</a>.
This template specifies exactly the same model as <code>R-INLA</code> in Section <a href="naomi-aghq.html#epil-inla">6.2.1.1</a>.
The lines with a <code>DATA_</code> prefix specify the fixed data inputs to be passed to <code>TMB</code>.
Examples of data inputs include the data <span class="math inline">\(\mathbf{y}\)</span> and the covariate design matrix.
The lines with a <code>PARAMETER_</code> prefix specify the parameters <span class="math inline">\(\boldsymbol{\mathbf{\phi}} = (\mathbf{x}, \boldsymbol{\mathbf{\theta}})\)</span> to be estimated.
It is recommended to specify all parameters on the real scale to help performance of the optimisation procedure.
More familiar versions of parameters, such as the precision rather than log precision, may be created outside the <code>PARAMETER_</code> section.
Lines of the form <code>nlp -= ddist(...)</code> increment the negative log-posterior, where <code>dist</code> is the name of a distribution.</p>
<p>The <code>TMB</code> template may now first be compiled:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="naomi-aghq.html#cb6-1" tabindex="-1"></a><span class="fu">compile</span>(<span class="st">&quot;epil.cpp&quot;</span>)</span>
<span id="cb6-2"><a href="naomi-aghq.html#cb6-2" tabindex="-1"></a><span class="fu">dyn.load</span>(<span class="fu">dynlib</span>(<span class="st">&quot;epil&quot;</span>))</span></code></pre></div>
<p>The objective function <code>obj</code> may then be created, implementing <span class="math inline">\(\tilde p_{\texttt{LA}}(\boldsymbol{\mathbf{\theta}}, \mathbf{y})\)</span> and its first and second derivatives:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="naomi-aghq.html#cb7-1" tabindex="-1"></a>obj <span class="ot">&lt;-</span> TMB<span class="sc">::</span><span class="fu">MakeADFun</span>(</span>
<span id="cb7-2"><a href="naomi-aghq.html#cb7-2" tabindex="-1"></a>  <span class="at">data =</span> dat,</span>
<span id="cb7-3"><a href="naomi-aghq.html#cb7-3" tabindex="-1"></a>  <span class="at">parameters =</span> param,</span>
<span id="cb7-4"><a href="naomi-aghq.html#cb7-4" tabindex="-1"></a>  <span class="at">random =</span> <span class="fu">c</span>(<span class="st">&quot;beta&quot;</span>, <span class="st">&quot;epsilon&quot;</span>, <span class="st">&quot;nu&quot;</span>),</span>
<span id="cb7-5"><a href="naomi-aghq.html#cb7-5" tabindex="-1"></a>  <span class="at">DLL =</span> <span class="st">&quot;epil&quot;</span></span>
<span id="cb7-6"><a href="naomi-aghq.html#cb7-6" tabindex="-1"></a>)</span></code></pre></div>
<p>The object <code>dat</code> is a list of data inputs passed to <code>TMB</code>.
The object <code>param</code> is a list of parameter starting values passed to <code>TMB</code>.
The argument <code>random</code> determines which parameters are to be integrated out with a Gaussian approximation.
Here, the parameters <code>c("beta", "epsilon", "nu")</code>, or mathematically
<span class="math display">\[\begin{equation}
(\beta_0, \beta_\texttt{Base}, \beta_\texttt{Trt}, \beta_{\texttt{Trt} \times \texttt{Base}}, \beta_\texttt{Age}, \beta_{\texttt{V}_4}, \epsilon_1, \ldots, \epsilon_{59}, \nu_{1,1}, \ldots, \nu_{59,4}) = (\boldsymbol{\mathbf{\beta}}, \boldsymbol{\mathbf{\epsilon}}, \boldsymbol{\mathbf{\nu}}) = \mathbf{x}
\end{equation}\]</span>
were selected as the latent field.</p>
<p>The objective function <code>obj</code> may then be optimised using any gradient based optimiser, to obtain <span class="math inline">\(\hat{\boldsymbol{\mathbf{\theta}}}_\texttt{LA}\)</span>:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="naomi-aghq.html#cb8-1" tabindex="-1"></a>opt <span class="ot">&lt;-</span> <span class="fu">nlminb</span>(</span>
<span id="cb8-2"><a href="naomi-aghq.html#cb8-2" tabindex="-1"></a>  <span class="at">start =</span> obj<span class="sc">$</span>par,</span>
<span id="cb8-3"><a href="naomi-aghq.html#cb8-3" tabindex="-1"></a>  <span class="at">objective =</span> obj<span class="sc">$</span>fn,</span>
<span id="cb8-4"><a href="naomi-aghq.html#cb8-4" tabindex="-1"></a>  <span class="at">gradient =</span> obj<span class="sc">$</span>gr,</span>
<span id="cb8-5"><a href="naomi-aghq.html#cb8-5" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">list</span>(<span class="at">iter.max =</span> <span class="dv">1000</span>, <span class="at">trace =</span> <span class="dv">0</span>)</span>
<span id="cb8-6"><a href="naomi-aghq.html#cb8-6" tabindex="-1"></a>)</span></code></pre></div>
<p>The <code>sdreport</code> function is used to evaluate the Hessian at a particular value.
Setting <code>par.fixed</code> to the previously obtained <code>opt$par</code> returns <span class="math inline">\(\hat{\boldsymbol{\mathbf{H}}}_\texttt{LA}\)</span>:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="naomi-aghq.html#cb9-1" tabindex="-1"></a>sd_out <span class="ot">&lt;-</span> TMB<span class="sc">::</span><span class="fu">sdreport</span>(</span>
<span id="cb9-2"><a href="naomi-aghq.html#cb9-2" tabindex="-1"></a>  obj,</span>
<span id="cb9-3"><a href="naomi-aghq.html#cb9-3" tabindex="-1"></a>  <span class="at">par.fixed =</span> opt<span class="sc">$</span>par,</span>
<span id="cb9-4"><a href="naomi-aghq.html#cb9-4" tabindex="-1"></a>  <span class="at">getJointPrecision =</span> <span class="cn">TRUE</span></span>
<span id="cb9-5"><a href="naomi-aghq.html#cb9-5" tabindex="-1"></a>)</span></code></pre></div>
<p>It also is possible to succinctly fit the epilepsy GLMM in a frequentist setting (that is, using improper hyperparameter priors <span class="math inline">\(p(\boldsymbol{\mathbf{\theta}}) \propto 1\)</span>) using a formula interface in <code>glmmTMB</code></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="naomi-aghq.html#cb10-1" tabindex="-1"></a>formula <span class="ot">&lt;-</span> y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> CTrt <span class="sc">+</span> ClBase4 <span class="sc">+</span> CV4 <span class="sc">+</span> ClAge <span class="sc">+</span> CBT</span>
<span id="cb10-2"><a href="naomi-aghq.html#cb10-2" tabindex="-1"></a>                 <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> rand) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Ind)</span>
<span id="cb10-3"><a href="naomi-aghq.html#cb10-3" tabindex="-1"></a>                 </span>
<span id="cb10-4"><a href="naomi-aghq.html#cb10-4" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glmmTMB</span>(formula, <span class="at">data =</span> Epil, <span class="at">family =</span> <span class="fu">poisson</span>(<span class="at">link =</span> <span class="st">&quot;log&quot;</span>))</span></code></pre></div>
</div>
<div id="epil-gauss-aghq-tmb" class="section level4 hasAnchor" number="6.2.1.3">
<h4><span class="header-section-number">6.2.1.3</span> Gaussian marginals and AGHQ with <code>aghq</code><a href="naomi-aghq.html#epil-gauss-aghq-tmb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The objective function <code>obj</code> created in Section <a href="naomi-aghq.html#epil-gauss-eb-tmb">6.2.1.2</a> may be directly passed to <code>aghq</code> to perform inference using AGHQ:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="naomi-aghq.html#cb11-1" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fu">c</span>(param<span class="sc">$</span>l_tau_epsilon, param<span class="sc">$</span>l_tau_nu)</span>
<span id="cb11-2"><a href="naomi-aghq.html#cb11-2" tabindex="-1"></a>fit <span class="ot">&lt;-</span> aghq<span class="sc">::</span><span class="fu">marginal_laplace_tmb</span>(obj, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">startingvalue =</span> start)</span></code></pre></div>
<p>The argument <code>k</code> specifies the number of quadrature nodes to be used per dimension, here set to three.
A more complete <code>aghq</code> vignette is provided by <span class="citation">Stringer (<a href="#ref-stringer2021implementing">2021b</a>)</span>.</p>
</div>
<div id="epil-laplace-eb-tmb" class="section level4 hasAnchor" number="6.2.1.4">
<h4><span class="header-section-number">6.2.1.4</span> Laplace marginals and EB with <code>TMB</code><a href="naomi-aghq.html#epil-laplace-eb-tmb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Laplace latent field marginal <span class="math inline">\(\tilde p_\texttt{LA}(x_i, \boldsymbol{\mathbf{\theta}}, \mathbf{y})\)</span> may be obtained by setting <code>random</code> to <span class="math inline">\(\mathbf{x}_{-i}\)</span> in the <code>MakeADFun</code> function call.
This is not directly possible, as the <code>random</code> argument takes a vector of strings as input, and has no native method for indexing.
Instead, the following steps must be taken to modify the <code>TMB</code> C++ template:</p>
<ol style="list-style-type: decimal">
<li>Include <code>DATA_INTEGER(i)</code> to pass the index <span class="math inline">\(i\)</span> to <code>TMB</code>.</li>
<li>Concatenate the latent field to <code>PARAMETER_VECTOR(x_minus_i)</code> and <code>PARAMETER(x_i)</code>.</li>
<li>Include <code>DATA_IVECTOR(x_lengths)</code> and <code>DATA_IVECTOR(x_starts)</code> to pass the start point and lengths of each subvector of <span class="math inline">\(\mathbf{x}\)</span>.
The <span class="math inline">\(j\)</span>th subvector may then be obtained using <code>x.segment(x_starts(j), x_lengths(j))</code>.</li>
</ol>
<p>The modified <code>TMB</code> C++ template for the epilepsy GLMM is in Appendix <a href="fast-approximate-bayesian-inference.html#tmb-modified-epil">C.1.2</a>.</p>
<p>Now it is possible (after suitably alterations are made to <code>dat</code> and <code>param</code>) to obtain the desired objective function via:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="naomi-aghq.html#cb12-1" tabindex="-1"></a><span class="fu">compile</span>(<span class="st">&quot;epil_modified.cpp&quot;</span>)</span>
<span id="cb12-2"><a href="naomi-aghq.html#cb12-2" tabindex="-1"></a><span class="fu">dyn.load</span>(<span class="fu">dynlib</span>(<span class="st">&quot;epil_modified.cpp&quot;</span>))</span>
<span id="cb12-3"><a href="naomi-aghq.html#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="naomi-aghq.html#cb12-4" tabindex="-1"></a>obj_i <span class="ot">&lt;-</span> <span class="fu">MakeADFun</span>(</span>
<span id="cb12-5"><a href="naomi-aghq.html#cb12-5" tabindex="-1"></a>  <span class="at">data =</span> dat,</span>
<span id="cb12-6"><a href="naomi-aghq.html#cb12-6" tabindex="-1"></a>  <span class="at">parameters =</span> param,</span>
<span id="cb12-7"><a href="naomi-aghq.html#cb12-7" tabindex="-1"></a>  <span class="at">random =</span> <span class="st">&quot;x_minus_i&quot;</span>,</span>
<span id="cb12-8"><a href="naomi-aghq.html#cb12-8" tabindex="-1"></a>  <span class="at">DLL =</span> <span class="st">&quot;epil_modified&quot;</span>,</span>
<span id="cb12-9"><a href="naomi-aghq.html#cb12-9" tabindex="-1"></a>  <span class="at">silent =</span> <span class="cn">TRUE</span>,</span>
<span id="cb12-10"><a href="naomi-aghq.html#cb12-10" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="epil-laplace-aghq-tmb" class="section level4 hasAnchor" number="6.2.1.5">
<h4><span class="header-section-number">6.2.1.5</span> Laplace marginals and AGHQ with <code>TMB</code><a href="naomi-aghq.html#epil-laplace-aghq-tmb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="naomi-aghq.html#cb13-1" tabindex="-1"></a><span class="co"># code here</span></span></code></pre></div>
</div>
<div id="epil-nuts" class="section level4 hasAnchor" number="6.2.1.6">
<h4><span class="header-section-number">6.2.1.6</span> NUTS with <code>tmbstan</code><a href="naomi-aghq.html#epil-nuts" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Running NUTS with <code>tmbstan</code> using the objective function <code>obj</code> is easy to do:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="naomi-aghq.html#cb14-1" tabindex="-1"></a>fit <span class="ot">&lt;-</span> tmbstan<span class="sc">::</span><span class="fu">tmbstan</span>(<span class="at">obj =</span> obj, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">refresh =</span> <span class="dv">0</span>)</span></code></pre></div>
<p>Convergence diagnostics for NUTS with <code>tmbstan</code> are in Appendix <a href="fast-approximate-bayesian-inference.html#tmbstan-epil">C.1.4.1</a>.</p>
</div>
<div id="epil-nuts-rstan" class="section level4 hasAnchor" number="6.2.1.7">
<h4><span class="header-section-number">6.2.1.7</span> NUTS with <code>rstan</code><a href="naomi-aghq.html#epil-nuts-rstan" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For interest in the relative inefficiency of <code>tmbstan</code>, the epilepsy model was also implemented in <code>Stan</code>.
The <code>Stan</code> C++ template <code>epil.stan</code> for the epilepsy GLMM is in Appendix <a href="fast-approximate-bayesian-inference.html#stan-epil">C.1.3</a>.
This may be of interest to users familiar with <code>Stan</code> syntax, to help provide context for <code>TMB</code>.
The <code>Stan</code> template was validated as be equivalent to the <code>TMB</code> template up to a constant of proportionality.
Inferences from <code>Stan</code> may be obtained by</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="naomi-aghq.html#cb15-1" tabindex="-1"></a>fit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">stan</span>(<span class="at">file =</span> <span class="st">&quot;epil.stan&quot;</span>, <span class="at">data =</span> dat, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">refresh =</span> <span class="dv">0</span>)</span></code></pre></div>
<p>Convergence diagnostics for NUTS with <code>rstan</code> are in Appendix <a href="fast-approximate-bayesian-inference.html#rstan-epil">C.1.4.2</a>.</p>
</div>
<div id="epil-comparison" class="section level4 hasAnchor" number="6.2.1.8">
<h4><span class="header-section-number">6.2.1.8</span> Comparison<a href="naomi-aghq.html#epil-comparison" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Posterior means and standard deviations for the the six regression parameters <span class="math inline">\(\boldsymbol{\mathbf{\beta}}\)</span> were near identical using <code>R-INLA</code> and <code>TMB</code> (Table <a href="naomi-aghq.html#tab:epil-results">6.1</a>).</p>
<table>
<caption>
<span id="tab:epil-results">Table 6.1: </span>Posterior mean and standard deviation results for the six regression parameters in the epilepsy GLMM.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
R-INLA
</th>
<th style="text-align:right;">
TMB
</th>
<th style="text-align:right;">
AGHQ
</th>
<th style="text-align:right;">
NUTS
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
beta[0]
</td>
<td style="text-align:right;">
1.6272418
</td>
<td style="text-align:right;">
1.6266589
</td>
<td style="text-align:right;">
1.6252194
</td>
<td style="text-align:right;">
1.5736379
</td>
</tr>
<tr>
<td style="text-align:left;">
sd(beta[0])
</td>
<td style="text-align:right;">
0.0750768
</td>
<td style="text-align:right;">
0.0764481
</td>
<td style="text-align:right;">
0.0766634
</td>
<td style="text-align:right;">
0.0782053
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[1]
</td>
<td style="text-align:right;">
-0.9256949
</td>
<td style="text-align:right;">
-0.9262305
</td>
<td style="text-align:right;">
-0.9351916
</td>
<td style="text-align:right;">
-0.9526077
</td>
</tr>
<tr>
<td style="text-align:left;">
sd(beta[1])
</td>
<td style="text-align:right;">
0.4085444
</td>
<td style="text-align:right;">
0.4135053
</td>
<td style="text-align:right;">
0.4192253
</td>
<td style="text-align:right;">
0.4115089
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[2]
</td>
<td style="text-align:right;">
0.8582943
</td>
<td style="text-align:right;">
0.8581393
</td>
<td style="text-align:right;">
0.8643509
</td>
<td style="text-align:right;">
0.8869287
</td>
</tr>
<tr>
<td style="text-align:left;">
sd(beta[2])
</td>
<td style="text-align:right;">
0.1343051
</td>
<td style="text-align:right;">
0.1361203
</td>
<td style="text-align:right;">
0.1335267
</td>
<td style="text-align:right;">
0.1345200
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[3]
</td>
<td style="text-align:right;">
-0.1002819
</td>
<td style="text-align:right;">
-0.1005232
</td>
<td style="text-align:right;">
-0.1022552
</td>
<td style="text-align:right;">
-0.1040067
</td>
</tr>
<tr>
<td style="text-align:left;">
sd(beta[3])
</td>
<td style="text-align:right;">
0.0859909
</td>
<td style="text-align:right;">
0.0858690
</td>
<td style="text-align:right;">
0.0845704
</td>
<td style="text-align:right;">
0.0871546
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[4]
</td>
<td style="text-align:right;">
0.4722568
</td>
<td style="text-align:right;">
0.4704351
</td>
<td style="text-align:right;">
0.4852713
</td>
<td style="text-align:right;">
0.4935811
</td>
</tr>
<tr>
<td style="text-align:left;">
sd(beta[4])
</td>
<td style="text-align:right;">
0.3547226
</td>
<td style="text-align:right;">
0.3595652
</td>
<td style="text-align:right;">
0.3545031
</td>
<td style="text-align:right;">
0.3628812
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[5]
</td>
<td style="text-align:right;">
0.3400574
</td>
<td style="text-align:right;">
0.3399361
</td>
<td style="text-align:right;">
0.3413073
</td>
<td style="text-align:right;">
0.3507211
</td>
</tr>
<tr>
<td style="text-align:left;">
sd(beta[5])
</td>
<td style="text-align:right;">
0.2077633
</td>
<td style="text-align:right;">
0.2104471
</td>
<td style="text-align:right;">
0.2126778
</td>
<td style="text-align:right;">
0.2063390
</td>
</tr>
</tbody>
</table>

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:epil-time"></span>
<img src="figures/naomi-aghq/epil-time.png" alt="Time taken." width="95%" />
<p class="caption">
Figure 6.6: Time taken.
</p>
</div>
</div>
</div>
<div id="unknown" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> An example that <code>R-INLA</code> doesn’t work for<a href="naomi-aghq.html#unknown" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An example of a model that <code>R-INLA</code> can’t fit but INLA with <code>TMB</code> can.
Demonstrate Laplace marginals making a difference to accuracy as compared with Gaussian marginals.
The model structure was as follows.
Inference was performed using:</p>
<ol style="list-style-type: decimal">
<li>Gaussian marginals and EB with <code>TMB</code></li>
<li>Gaussian marginals and AGHQ with <code>aghq</code></li>
<li>Laplace marginals and EB with <code>TMB</code></li>
<li>Laplace marginals and AGHQ with <code>TMB</code></li>
<li>NUTS with <code>tmbstan</code></li>
</ol>
<p>The results were as follows.</p>
</div>
</div>
<div id="naomi" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> The Naomi model<a href="naomi-aghq.html#naomi" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The work in this chapter was conducted in search of a fast and accurate Bayesian inference method for the Naomi model <span class="citation">(<a href="#ref-eaton2021naomi">Eaton et al. 2021</a>)</span>.
This section begins in Section <a href="naomi-aghq.html#naomi-model">6.3.1</a> by providing a description of the simplified version of Naomi considered in this chapter.
The model is simplified in that it is defined only at the time of the most recent household survey with HIV testing is considered.
The nowcasting and temporal projection components of the complete model are omitted.
However, these time points play a limited role in inference as they correspond to a small proportion of the total data.
As such, findings about inference for the simplified model are very likely transferable to the complete model.
Some features of the simplified model are left to more exhaustive description in Appendix <a href="fast-approximate-bayesian-inference.html#naomi-math">C.2</a>.
After outlining the model, Section <a href="naomi-aghq.html#naomi-elgm">6.3.2</a> explains why it is not an extended latent Gaussian model [ELGM; <span class="citation">Stringer, Brown, and Stafford (<a href="#ref-stringer2022fast">2022</a>)</span>] rather than a latent Gaussian model [LGM; <span class="citation">Håvard Rue, Martino, and Chopin (<a href="#ref-rue2009approximate">2009</a>)</span>].</p>
<div id="naomi-model" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Model structure<a href="naomi-aghq.html#naomi-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Naomi synthesises data from three different sources to estimate HIV indicators at a district-level, by age and sex.
It may be described as having three components, corresponding to these three data sources.
The model components are:</p>
<ul>
<li>the household survey component (Section <a href="naomi-aghq.html#household">6.3.1.2</a>);</li>
<li>the antenatal care (ANC) clinic testing component (Section <a href="naomi-aghq.html#art">6.3.1.4</a>);</li>
<li>the antiretroviral therapy (ART) attendance component (Section <a href="naomi-aghq.html#art">6.3.1.4</a>).</li>
</ul>
<p>After specifying common notation used throughout the model, each of these components is described in turn.</p>
<div id="notation" class="section level4 hasAnchor" number="6.3.1.1">
<h4><span class="header-section-number">6.3.1.1</span> Notation<a href="naomi-aghq.html#notation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider a country in sub-Saharan Africa where a household survey with complex design has taken place.
Let <span class="math inline">\(x \in \mathcal{X}\)</span> index district, <span class="math inline">\(a \in \mathcal{A}\)</span> index five-year age group, and <span class="math inline">\(s \in \mathcal{S}\)</span> index sex.
For ease of notation, let <span class="math inline">\(i\)</span> index the finest district-age-sex division included in the model.
(A district-age-sex specific quantity <span class="math inline">\(z_{x,a,s}\)</span> may then be written as <span class="math inline">\(z_i\)</span>, and where required the district, age, and sex may be recovered by <span class="math inline">\(x(i) = x\)</span>, <span class="math inline">\(a(i) = a\)</span>, and <span class="math inline">\(s(i) = s\)</span>.)
Let:</p>
<ul>
<li><span class="math inline">\(N_i \in \mathbb{N}\)</span> be the known, fixed population size;</li>
<li><span class="math inline">\(\rho_i \in [0, 1]\)</span> be the HIV prevalence;</li>
<li><span class="math inline">\(\alpha_i \in [0, 1]\)</span> be the ART coverage;</li>
<li><span class="math inline">\(\kappa_i \in [0, 1]\)</span> be the proportion recently infected among HIV positive persons;</li>
<li><span class="math inline">\(\lambda_i &gt; 0\)</span> be the annual HIV incidence rate.</li>
</ul>
<p>Some observations are made at an aggregate level over a collection of strata <span class="math inline">\(i\)</span> rather than for a single <span class="math inline">\(i\)</span>.
Let <span class="math inline">\(I \subseteq \mathcal{X} \times \mathcal{A} \times \mathcal{S}\)</span> be a set of indices <span class="math inline">\(i\)</span> for which an aggregate observation is reported.
The set of all <span class="math inline">\(I\)</span> is denoted <span class="math inline">\(\mathcal{I}\)</span> such that <span class="math inline">\(I \in \mathcal{I}\)</span>.</p>
</div>
<div id="household" class="section level4 hasAnchor" number="6.3.1.2">
<h4><span class="header-section-number">6.3.1.2</span> Household survey component<a href="naomi-aghq.html#household" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Independent logistic regression models are specified for HIV prevalence and ART coverage in the general population.
Without giving the linear predictors in detail, these models are specified by
<span class="math display">\[\begin{equation}
\text{logit}(\rho_i) = \eta^\rho_i,
\end{equation}\]</span>
and
<span class="math display">\[\begin{equation}
\text{logit}(\alpha_i) = \eta^\alpha_i.
\end{equation}\]</span>
HIV incidence rate is modelled on the log scale as
<span class="math display">\[\begin{equation}
\log(\lambda_i) = \eta^\lambda_i.
\end{equation}\]</span>
The structured additive predictor <span class="math inline">\(\eta^\lambda_i\)</span> includes terms for adult HIV prevalence and adult ART coverage.
The proportion recently infected among HIV positive persons is linked to HIV incidence via
<span class="math display" id="eq:kappa">\[\begin{equation}
\kappa_i = 1- \exp \left( - \lambda_i \cdot \frac{1 - \rho_i}{\rho_i} \cdot (\Omega_T - \beta_T) - \beta_T \right), \tag{6.19}
\end{equation}\]</span>
where the mean duration of recent infection <span class="math inline">\(\Omega_T\)</span> and the proportion of long-term HIV infections misclassified as recent <span class="math inline">\(\beta_T\)</span> are strongly informed by prior distributions for the particular survey.</p>
<p>These processes are each primarily informed by household survey data.
Let <span class="math inline">\(j\)</span> denote a surveyed individual, in strata <span class="math inline">\(i(j)\)</span>.
Weighted aggregate survey observations are calculated as
<span class="math display" id="eq:survey-obs">\[\begin{equation}
\hat \theta_I = \frac{\sum_{i(j) \in I} w_j \cdot\theta_j}{\sum_{i(j) \in I} w_j}, \tag{6.20}
\end{equation}\]</span>
with individual responses <span class="math inline">\(\theta_j \in \{0, 1\}\)</span> and survey weights <span class="math inline">\(w_j\)</span> for each of <span class="math inline">\(\theta \in \{\rho, \alpha, \kappa\}\)</span>.
<!-- Are the survey weights the same for each observation type? -->
Survey weights are supplied by the survey provider.
Their aim to reduce bias by decreasing possible correlation between response and recording mechanism <span class="citation">(<a href="#ref-meng2018statistical">Meng 2018</a>)</span>.
The weighted aggregate number of outcomes are obtained by multiplying Equation <a href="naomi-aghq.html#eq:survey-obs">(6.20)</a> by the Kish effective sample size [ESS; <span class="citation">Kish (<a href="#ref-kish1965survey">1965</a>)</span>]
<span class="math display" id="eq:weighted-aggregate">\[\begin{equation}
y^{\theta}_{I} = m^{\theta}_{I} \hat \theta_{I}, \tag{6.21}
\end{equation}\]</span>
where
<span class="math display" id="eq:kish-ess">\[\begin{equation}
m^{\theta}_I = \frac{\left(\sum_{i(j) \in I} w_j\right)^2}{\sum_{i(j) \in I} w_j^2}. \tag{6.22}
\end{equation}\]</span>
As the Kish ESS is maximised by constant survey weights, in exchange for reducing bias, survey weighting increases variance.
Equations <a href="naomi-aghq.html#eq:survey-obs">(6.20)</a>, <a href="naomi-aghq.html#eq:weighted-aggregate">(6.21)</a> and <a href="naomi-aghq.html#eq:kish-ess">(6.22)</a> are imprecise in the notation used does not reflect the fact that <span class="math inline">\(j\)</span> only runs over individuals within the relevant denominator.
In particular, for ART coverage <span class="math inline">\(\alpha\)</span> and the proportion recently infected among HIV positive persons <span class="math inline">\(\kappa\)</span>, only those individuals who are HIV positive are included in the set.
The denominator for HIV prevalence <span class="math inline">\(\rho\)</span> includes all individuals.</p>
<p>The weighted aggregate number of outcomes are modelled using a binomial working likelihood <span class="citation">(<a href="#ref-chen2014use">Chen, Wakefield, and Lumely 2014</a>)</span> defined to operate on the reals
<span class="math display">\[\begin{equation}
y^{\theta}_{I} \sim \text{xBin}(m^{\theta}_{I}, \theta_{I}).
\end{equation}\]</span>
The terms <span class="math inline">\(\theta_{I}\)</span> are the following weighted aggregates
<span class="math display" id="eq:weighted-aggregates">\[\begin{equation}
\rho_{I} = \frac{\sum_{i \in I} N_i \rho_i}{\sum_{i \in I} N_i}, \quad
\alpha_{I} = \frac{\sum_{i \in I} N_i \rho_i \alpha_i}{\sum_{i \in I} N_i \rho_i}, \quad
\kappa_{I} = \frac{\sum_{i \in I} N_i \rho_i \kappa_i}{\sum_{i \in I} N_i \rho_i}, \tag{6.23}
\end{equation}\]</span>
where the denominators of <span class="math inline">\(\alpha_{I}\)</span> and <span class="math inline">\(\kappa_{I}\)</span> reflect their restriction to HIV positive persons.</p>
</div>
<div id="anc" class="section level4 hasAnchor" number="6.3.1.3">
<h4><span class="header-section-number">6.3.1.3</span> ANC testing component<a href="naomi-aghq.html#anc" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Women attending ANC clinics are routinely tested for HIV, to help prevent mother-to-child transmission.</p>
<p>HIV prevalence <span class="math inline">\(\rho^\text{ANC}_i \in [0, 1]\)</span> and ART coverage <span class="math inline">\(\alpha^\text{ANC}_i \in [0, 1]\)</span> among pregnant women are modelled as offset from the general population indicators.
(For <span class="math inline">\(s(i)\)</span> male, these quantities are not defined.)
Again not detailing the linear predictors, the model is of the form
<span class="math display">\[\begin{align}
\text{logit}(\rho^\text{ANC}_i) &amp;= \text{logit}(\rho_i) + \eta^{\rho^\text{ANC}}_i, \\
\text{logit}(\alpha^\text{ANC}_i) &amp;= \text{logit}(\alpha_i) + \eta^{\alpha^\text{ANC}}_i.
\end{align}\]</span>
The terms <span class="math inline">\(\eta^{\rho^\text{ANC}}_i\)</span> and <span class="math inline">\(\eta^{\alpha^\text{ANC}}_i\)</span> can be interpreted as the differences in HIV prevalence and ART coverage between pregnant women attending ANC, and the general population.
As such, both the household survey data informs ANC indicators, and the ANC indicator informs general population indicators.</p>
<p>These two processes are informed by likelihoods specified for aggregate ANC clinic data from the year of the most recent survey.
Let:</p>
<ul>
<li>the number of ANC clients with ascertained status be fixed as <span class="math inline">\(m^{\rho^\text{ANC}}_I\)</span>;</li>
<li>the number of those with positive status are <span class="math inline">\(y^{\rho^\text{ANC}}_I \leq m^{\rho^\text{ANC}}_I\)</span>;</li>
<li>the number of those already on ART prior to their first ANC visit are <span class="math inline">\(y^{\alpha^\text{ANC}}_I \leq y^{\rho^\text{ANC}}_I\)</span>.</li>
</ul>
<p>These data are modelled using nested binomial likelihoods
<span class="math display">\[\begin{align*}
y^{\rho^\text{ANC}}_I &amp;\sim \text{Bin}(m^{\rho^\text{ANC}}_I, \rho^\text{ANC}_{I}), \\
y^{\alpha^\text{ANC}}_I &amp;\sim \text{Bin}(y^{\rho^\text{ANC}}_I, \alpha^\text{ANC}_{I}).
\end{align*}\]</span>
It is not necessary to use an extended binomial working likelihood, as in Section <a href="bayes-st.html#survey">3.5</a>, because the ANC data are not survey weighted and therefore are integer valued.
Analogous to Equation <a href="naomi-aghq.html#eq:weighted-aggregates">(6.23)</a> in the household survey component, the weighted aggregates used here are
<span class="math display">\[\begin{equation*}
\rho^\text{ANC}_{I} = \frac{\sum_{i \in I} \Psi_i \rho_i^\text{ANC}}{\sum_{i \in I} \Psi_i}, \quad
\alpha^\text{ANC}_{I} = \frac{\sum_{i \in I} \Psi_i \rho_i^\text{ANC} \alpha^\text{ANC}_i}{\sum_{i \in I} \Psi_i \rho_i^\text{ANC}},
\end{equation*}\]</span>
where <span class="math inline">\(\Psi_i\)</span> are the number of pregnant women, which are assume to be fixed.</p>
</div>
<div id="art" class="section level4 hasAnchor" number="6.3.1.4">
<h4><span class="header-section-number">6.3.1.4</span> ART attendance component<a href="naomi-aghq.html#art" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Data on attendance of ART clinics are routinely collected.
These data provide helpful information about HIV prevalence and coverage of ART, but are challenging to use because people living with HIV sometimes choose to access ART services outside of the district that they reside in.
(Indeed, this section of the model remains a challenge, and is under active development <span class="citation">(<a href="#ref-esra2023improved">Esra 2023</a>)</span>.)</p>
<p>Multinomial logistic regression equations are used to model the probabilities of individuals accessing treatment outside their home district.
Briefly, let <span class="math inline">\(\gamma_{x, x&#39;}\)</span> be the probability that a person on ART residing in district <span class="math inline">\(x\)</span> receives ART in district <span class="math inline">\(x&#39;\)</span>.
These probabilities are set to <span class="math inline">\(\gamma_{x, x&#39;} = 0\)</span> unless <span class="math inline">\(x = x&#39;\)</span> or the two districts are neighbouring such that <span class="math inline">\(x \sim x&#39;\)</span>.
As such, it is assumed that no one travels beyond their district or its immediate neighbours to receive ART services.
(Of course, in reality this assumption is violated.)
The log-odds are modelled using a structured additive predictor which only depends on the home district <span class="math inline">\(x\)</span>
<span class="math display">\[\begin{equation}
\tilde \gamma_{x, x&#39;} = \text{logit}(\gamma_{x, x&#39;}) = \eta_{x}^{\tilde \gamma}.
\end{equation}\]</span>
As a result, it is assumed that travel to each neighbouring district, for all age-sex strata, is equally likely.</p>
<p>Let the number of people observed receiving ART in strata <span class="math inline">\(i\)</span> be <span class="math inline">\(y^{A}_i\)</span> with corresponding aggregate
<span class="math display" id="eq:art-aggregate">\[\begin{equation}
y^{A}_I = \sum_{i \in I} y^{A}_i. \tag{6.24}
\end{equation}\]</span>
Let the probability of a person in strata <span class="math inline">\(i\)</span> travelling from district <span class="math inline">\(x(i) = x\)</span> to <span class="math inline">\(x&#39;\)</span> to receive ART be
<span class="math display" id="eq:recieve-art">\[\begin{equation}
\pi_{i, x(i) = x, x&#39;} = \rho_{i} \alpha_{i} \gamma_{x(i) = x, x&#39;}. \tag{6.25}
\end{equation}\]</span>
These probabilities are the product of three probabilities, each for a person in strata <span class="math inline">\(i\)</span>:</p>
<ol style="list-style-type: decimal">
<li>the probability of a having HIV <span class="math inline">\(\rho_{i}\)</span>,</li>
<li>the probability of taking ART <span class="math inline">\(\alpha_{i}\)</span>,</li>
<li>the probability of travelling from district <span class="math inline">\(x(i) = x\)</span> to district <span class="math inline">\(x&#39;\)</span> to receive ART <span class="math inline">\(\gamma_{x(i) = x, x&#39;}\)</span>.</li>
</ol>
<p>Let the unobserved count of people in strata <span class="math inline">\(i\)</span> who travel to <span class="math inline">\(x&#39;\)</span> to receive ART be <span class="math inline">\(A_{i, x(i) = x, x&#39;}\)</span>, such that
<span class="math display">\[\begin{equation}
A_i = \sum_{x&#39; \sim x, x&#39; = x} A_{i, x(i) = x&#39;, x}.
\end{equation}\]</span>
Each unobserved count can be considered as arising from a binomial distribution, with sample size given by the population in strata <span class="math inline">\(i\)</span>, here with <span class="math inline">\(x(i) = x&#39;\)</span> such that
<span class="math display">\[\begin{equation}
A_{i, x(i) = x&#39;, x} \sim \text{Bin}(N_{i, x(i) = x&#39;}, \pi_{i, x(i) = x&#39;, x}).
\end{equation}\]</span></p>
<p>Each aggregate attendance observation (Equation <a href="naomi-aghq.html#eq:art-aggregate">(6.24)</a>) is modelled using a Gaussian approximation to a sum of binomials.
This sum is over both the strata <span class="math inline">\(i \in I\)</span> and the number of ART clients travelling from district <span class="math inline">\(x(i) = x&#39;\)</span> to <span class="math inline">\(x\)</span> to receive treatment.
The Gaussian approximation is
<span class="math display">\[\begin{equation}
y^{A}_I \sim \mathcal{N}(\mu^A_I, {\sigma^A_I}^2),
\end{equation}\]</span>
where the mean is
<span class="math display" id="eq:art-aggregate-mean">\[\begin{equation}
\mu^A_I = \sum_{i \in I} \sum_{x&#39; \sim x, x&#39; = x} N_{i, x(i) = x&#39;} \cdot \pi_{i, x(i) = x&#39;, x}, \tag{6.26}
\end{equation}\]</span>
and the variance is
<span class="math display" id="eq:art-aggregate-var">\[\begin{equation}
{\sigma^A_I}^2 = \sum_{i \in I} \sum_{x&#39; \sim x, x&#39; = x} N_{i, x(i) = x&#39;} \cdot \pi_{i, x(i) = x&#39;, x} \cdot (1 -  \pi_{i, x(i) = x&#39;, x}). \tag{6.27}
\end{equation}\]</span>
Equations <a href="naomi-aghq.html#eq:art-aggregate-mean">(6.26)</a> and <a href="naomi-aghq.html#eq:art-aggregate-var">(6.27)</a> are based on a Gaussian approximation to the binomial distribution <span class="math inline">\(\text{Bin}(n, p)\)</span> with mean <span class="math inline">\(np\)</span> and variance <span class="math inline">\(np(1 - p)\)</span>, together with the equations for a linear combination of Gaussian random variables.</p>
</div>
</div>
<div id="naomi-elgm" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Naomi as an ELGM<a href="naomi-aghq.html#naomi-elgm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In all, Naomi is a joint model on the observations
<span class="math display">\[\begin{equation}
\mathbf{y} = (y^{\theta}_I), \quad \theta \in \{\rho, \alpha, \kappa, \rho^\text{ANC}, \alpha^\text{ANC}, A\}, \quad I \in \mathcal{I}.
\end{equation}\]</span>
The observations are modelled using the structured additive predictor <span class="math inline">\(\boldsymbol{\mathbf{\eta}}\)</span>, which includes intercept effects, age random effects, and spatial random effects which may be concatenated into the latent field <span class="math inline">\(\mathbf{x}\)</span>.
The latent field is controlled by hyperparameters <span class="math inline">\(\boldsymbol{\mathbf{\theta}}\)</span> which include standard deviations, first-order autoregressive model correlation parameters, and reparameterised Besag-York-Mollie model [BYM2; <span class="citation">Simpson et al. (<a href="#ref-simpson2017penalising">2017</a>)</span>] proportion parameters.
These features are described in more detail in Appendix <a href="fast-approximate-bayesian-inference.html#naomi-math">C.2</a>.</p>
<p>Naomi has a large Gaussian latent field, governed by a smaller number of hyperparameters <span class="math inline">\(m &lt; N\)</span>.
However, it has complexities which place it outside the class of LGMs, as defined in Section <a href="bayes-st.html#lgm">3.3.5</a>.
Instead, it is an ELGM, as defined in Section <a href="bayes-st.html#elgm">3.3.6</a>.
In an ELGM, each mean response is allowed to depend non-linearly upon more than one structured additive predictor.
The departures of Naomi from the LGM framework are enumerated below.
When dependence on a specific number of structured additive predictors is given, it is in isolation, rather than in conjunction.</p>
<ol style="list-style-type: decimal">
<li><p>Throughout Naomi, processes are modelled at the finest district-age-sex division <span class="math inline">\(i\)</span>, but likelihoods are defined for observations aggregated over sets of indices <span class="math inline">\(i \in I\)</span>.
As such, these aggregate observations are related to <span class="math inline">\(|I|\)</span> structured additive predictors, rather than just one.</p></li>
<li><p>Multiple link functions are used in Naomi, such that there is no one inverse link function <span class="math inline">\(g\)</span> as specified in definition of an LGM.
This is a relatively minor point, and it is possible to specify models with several likelihoods in <code>R-INLA</code> by setting <code>family</code> to be vector valued [Section 6.4; <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian">2020</a>)</span>].</p></li>
<li><p>In Section <a href="naomi-aghq.html#household">6.3.1.2</a>, HIV incidence depends on district-level adult HIV prevalence and ART coverage (Equation <a href="fast-approximate-bayesian-inference.html#eq:inc">(C.2)</a>)).
Each <span class="math inline">\(\log(\lambda_i)\)</span> therefore depends on 28 structured additive predictors, where 28 arises by the product of 2 sexes (male and female), 7 age groups (<span class="math inline">\(\{\text{15-19}, \ldots, \text{45-49}\}\)</span>), and 2 indicators, HIV prevalence and ART coverage.
This reflects basic HIV epidemiology: incidence of sexually transmitted HIV is proportional to unsuppressed viral load among an individual’s potential sexual partners.
The district-level adult averages are used as a proxy.</p></li>
<li><p>In Section <a href="naomi-aghq.html#household">6.3.1.2</a>, the proportion recently infected <span class="math inline">\(\kappa_i\)</span> is given by a non-linear function (Equation <a href="naomi-aghq.html#eq:kappa">(6.19)</a>) of HIV incidence <span class="math inline">\(\lambda_i\)</span>, HIV prevalence <span class="math inline">\(\rho_i\)</span>, mean duration of recent infection <span class="math inline">\(\Omega_T\)</span> and proportion of long-term HIV infections misclassified as recent <span class="math inline">\(\beta_T\)</span>.
Though arguably a contorting of the ELGM framework, by considering <span class="math inline">\(\Omega_T\)</span> and <span class="math inline">\(\beta_T\)</span> as (Gaussian) linear predictors, then each <span class="math inline">\(\kappa_i\)</span> depends on four structured additive predictors.</p></li>
<li><p>In Section <a href="naomi-aghq.html#anc">6.3.1.3</a>, HIV prevalence and ART coverage among pregnant women are modelled as offset from their respective indicators in the general population.
Thus each mean response depends on two structured additive predictors.
The <code>copy</code> feature in <code>R-INLA</code> [Section 6.5; <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian">2020</a>)</span>] allows for this type of model structure.</p></li>
<li><p>In Section <a href="naomi-aghq.html#anc">6.3.1.3</a>, nested binomial likelihoods are used.</p></li>
<li><p>In Section <a href="naomi-aghq.html#art">6.3.1.4</a> a multinomial model with softmax link function is used.
The multinomial likelihood takes as input <span class="math inline">\(|\{x&#39;: x&#39; \sim x\}| + 1\)</span> structured additive predictors, one for each neighbouring district plus one for remaining in the home district.</p></li>
<li><p>In Section <a href="naomi-aghq.html#art">6.3.1.4</a> the probability of an individual receiving ART in a given district is the product of three probabilities.</p></li>
</ol>
<p>Though intended for use with LGMs, the advanced features of <code>R-INLA</code> [Chapter 6; <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian">2020</a>)</span>] allow for fitting of some ELGMs as described above.
In some sense then, the above exercise is mostly academic rather than practical.
The crux is that Naomi cannot be fit using <code>R-INLA</code> because it is not possible to specify such a complex model using a formula interface.
The limitations of modelling with formula interfaces are not unique to <code>R-INLA</code>.
Indeed, any such statistical software will see requests for users for additional features.
The practical impossibility of meeting all feature requests motivates a more universal INLA implementation (Section <a href="naomi-aghq.html#universal">6.2</a>) for advanced users.</p>
</div>
</div>
<div id="pca-aghq" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> AGHQ in moderate dimensions<a href="naomi-aghq.html#pca-aghq" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Inference for the Naomi model has previously been conducted using a marginal Laplace approximation, and optimisation over the hyperparameters, implemented using <code>TMB</code>.
This approach is illustrated for the epilepsy example in Section <a href="naomi-aghq.html#epil-gauss-eb-tmb">6.2.1.2</a>.
It would be more desirable to integrate with respect to the hyperparameters, taking an INLA-like approach as described in Section <a href="naomi-aghq.html#inla">6.1.3</a>.</p>
<p>Section <a href="naomi-aghq.html#universal">6.2</a> attends to this challenge, by developing INLA methods which compatible with the Naomi model log-posterior as implemented in <code>TMB</code>.
However, the Naomi model has <span class="math inline">\(m = 24\)</span> hyperparameters.
Although <span class="math inline">\(m = 24\)</span> cannot be described as high-dimensional, it is certainly more than the <span class="math inline">\(m &lt; 4\)</span> or so (low dimensional) parameters which are typical for use of INLA.
Hence, this situation is referred to here as being moderate-dimensional.
Naive use of AGHQ with the product rule requires evaluation of <span class="math inline">\(|\mathcal{Q}(m, k)| = k^m\)</span> quadrature points.
This would be intractable for <span class="math inline">\(m = 24\)</span> and any <span class="math inline">\(k &gt; 1\)</span>.
As a result, integrating out the hyperparameters for Naomi requires a quadrature rule which does not scale exponentially.</p>
<p>This section focuses on the development of an AGHQ rule for moderate dimension, for use within an inference procedure for the Naomi model.
Though the rule is to be applied within a nested Laplace approximation approach, it is not limited to this setting and could be applied as a general purpose quadrature rule.</p>
<div id="aghq-with-variable-levels" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> AGHQ with variable levels<a href="naomi-aghq.html#aghq-with-variable-levels" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Rather than having the same number of quadrature nodes for each dimension of <span class="math inline">\(\boldsymbol{\mathbf{\theta}}\)</span>, it is possible to use a variable number of nodes per dimension.
In line with the terminology used in the <code>mvQuad</code> package, I refer to the number of nodes per dimension as levels.
Let <span class="math inline">\(\mathbf{k} = (k_1, \ldots, k_m)\)</span> be a vector of levels, where each <span class="math inline">\(k_j \in \mathbb{Z}^+\)</span>.
A GHQ grid with (potentially) variable levels is then given by
<span class="math display">\[\begin{equation}
\mathcal{Q}(m, \mathbf{k}) = \mathcal{Q}(1, k_1) \times \cdots \times \mathcal{Q}(1, k_m).
\end{equation}\]</span>
The size of this grid is given by the product of the levels <span class="math inline">\(|\mathcal{Q}(m, \mathbf{k})| = \prod_{j = 1}^m k_j\)</span>.
The corresponding weighting function is given by
<span class="math display">\[\begin{equation}
\omega(\mathbf{z}) = \prod_{j = 1}^m \omega_k(z_j).
\end{equation}\]</span></p>
</div>
<div id="principal-components-analysis" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Principal components analysis<a href="naomi-aghq.html#principal-components-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A special case of variable levels approach is to set the first <span class="math inline">\(s \leq m\)</span> levels to be <span class="math inline">\(k\)</span> and the remaining <span class="math inline">\(m - s \geq 0\)</span> levels to be one.
Denote <span class="math inline">\(\mathcal{Q}(m, s, k)\)</span> to be <span class="math inline">\(\mathcal{Q}(m, \mathbf{k})\)</span> with levels <span class="math inline">\(k_j = k, j \leq s\)</span> and <span class="math inline">\(k_j = 1, j &gt; s\)</span> for some <span class="math inline">\(s \leq m\)</span>.
For example, for <span class="math inline">\(m = 2\)</span> and <span class="math inline">\(s = 1\)</span> then <span class="math inline">\(\mathbf{k} = (k, 1)\)</span>.</p>
<p>When the spectral decomposition is used to adapt the quadrature nodes, this choice of levels is analogous to a principal components analysis (PCA) approach.
Figure <a href="naomi-aghq.html#fig:pca-demo">6.7</a> illustrates PCA-AGHQ for a case when <span class="math inline">\(m = 2\)</span> and <span class="math inline">\(s = 1\)</span>.
Since AGHQ with <span class="math inline">\(k = 1\)</span> corresponds to the Laplace approximation, PCA-AGHQ can be interpreted as performing AGHQ on the first <span class="math inline">\(s\)</span> principal components of the inverse curvature, and a Laplace approximation on the remaining <span class="math inline">\(m - s\)</span> principal components.
As such, it may be argued that PCA-AGHQ provides a natural compromise between the EB and AGHQ integration strategies.</p>
<p>For concreteness, the normalising constant obtained by application of PCA-AGHQ to integration of the marginal Laplace approximation (Equation <a href="naomi-aghq.html#eq:inlanormconst">(6.12)</a>) is given by
<span class="math display">\[\begin{equation}
\tilde p_\texttt{PCA}(\mathbf{y}) = |\hat{\mathbf{E}}_{\texttt{LA}} \hat{\mathbf{\Lambda}}_{\texttt{LA}}^{1/2}|\sum_{\mathbf{z} \in \mathcal{Q}(m, s, k)} \tilde p_\texttt{LA}(\hat{\mathbf{E}}_{\texttt{LA}, s} \hat{\mathbf{\Lambda}}_{\texttt{LA}, s}^{1/2} \mathbf{z} + \hat{\boldsymbol{\mathbf{\theta}}}_\texttt{LA}, \mathbf{y}) \omega(\mathbf{z}),
\end{equation}\]</span>
where <span class="math inline">\(\hat{\mathbf{E}}_{\texttt{LA}, s}\)</span> is an <span class="math inline">\(m \times s\)</span> matrix containing the first <span class="math inline">\(s\)</span> eigenvectors, <span class="math inline">\(\hat{\mathbf{\Lambda}}_{\texttt{LA}, s}\)</span> is the <span class="math inline">\(s \times s\)</span> diagonal matrix containing the first <span class="math inline">\(s\)</span> eigenvalues, and
<span class="math display">\[\begin{equation}
\omega(\mathbf{z}) = \prod_{j = 1}^s \omega_s(z_j) \times \prod_{j = s + 1}^d \omega_1(z_j).
\end{equation}\]</span></p>

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:pca-demo"></span>
<img src="figures/naomi-aghq/pca-demo.png" alt="Consider the function \(f(z_1, z_2) = \text{sn}(0.5 z_1, \alpha = 2) \cdot \text{sn}(0.8 z_1 - 0.5 z_2, \alpha = -2)\) as described in Figure 6.3. Panel A shows the AGHQ nodes with a spectral matrix decomposition, as usual. Panel B shows the adapted PCA-AGHQ nodes \(\mathcal{Q}(2, 1, 3)\). These nodes correspond exactly to those in Panel A along the first eigenvector. The proportion of variation explained by this direction is around 95%, with the remaining 5% explained by the second eigenvector." width="95%" />
<p class="caption">
Figure 6.7: Consider the function <span class="math inline">\(f(z_1, z_2) = \text{sn}(0.5 z_1, \alpha = 2) \cdot \text{sn}(0.8 z_1 - 0.5 z_2, \alpha = -2)\)</span> as described in Figure <a href="naomi-aghq.html#fig:aghq-demo">6.3</a>. Panel A shows the AGHQ nodes with a spectral matrix decomposition, as usual. Panel B shows the adapted PCA-AGHQ nodes <span class="math inline">\(\mathcal{Q}(2, 1, 3)\)</span>. These nodes correspond exactly to those in Panel A along the first eigenvector. The proportion of variation explained by this direction is around 95%, with the remaining 5% explained by the second eigenvector.
</p>
</div>
</div>
</div>
<div id="malawi" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Malawi case-study<a href="naomi-aghq.html#malawi" class="anchor-section" aria-label="Anchor link to header"></a></h2>

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:naomi-output"></span>
<img src="resources/naomi-aghq/20230811-095752-5b8181d8/depends/figB.png" alt="District-level HIV prevalence, ART coverage, and new HIV cases and HIV incidence for adults 15-49 in Malawi. Inference conducted using a Gaussian approximation and EB via TMB." width="95%" />
<p class="caption">
Figure 6.8: District-level HIV prevalence, ART coverage, and new HIV cases and HIV incidence for adults 15-49 in Malawi. Inference conducted using a Gaussian approximation and EB via <code>TMB</code>.
</p>
</div>
<p>This section presents a case study of Bayesian inference methods applied to the Naomi model in Malawi.
Data from Malawi has previously been used to demonstrate the Naomi model, including as a part of the <code>naomi</code> R package vignette available from <a href="https://github.com/mrc-ide/naomi"><code>https://github.com/mrc-ide/naomi</code></a>.
Malawi was chosen in part because it has a small number of districts, <span class="math inline">\(n = 30\)</span>, limiting the computational demand of the model.</p>
<p>Three Bayesian inference approaches were considered:</p>
<ol style="list-style-type: decimal">
<li>Gaussian marginals and EB with <code>TMB</code>.
This is the method that has previously been used for Naomi.
As short-hand, this method is referred to as EB.</li>
<li>Gaussian marginals and PCA-AGHQ with <code>aghq</code> and <code>TMB</code>.
This is a novel method.
As short-hand, this method is referred to as PCA-AGHQ.</li>
<li>NUTS with <code>tmbstan</code>.
This represents a gold-standard.</li>
</ol>
<p>The <code>TMB</code> C++ user-template used to specify the log-posterior was the same for each approach, and described in Appendix <a href="fast-approximate-bayesian-inference.html#naomi-implementation">C.2.4</a>.
The dimension of the latent field was <span class="math inline">\(N = 467\)</span> and the dimension of the hyperparameters was <span class="math inline">\(m = 24\)</span>.
For EB and PCA-AGHQ, hyperparameter and latent field samples were simulated following deterministic inference.
For all methods, age-sex-district specific HIV prevalence, ART coverage and HIV incidence were simulated from the latent field and hyperparameter posterior samples.
Model outputs are illustrated in Figure <a href="naomi-aghq.html#fig:naomi-output">6.8</a>.</p>
<div id="nuts-convergence" class="section level3 hasAnchor" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> NUTS convergence<a href="naomi-aghq.html#nuts-convergence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The effective sample size ratios generated sampling with NUTS were low.
Four chains run in parallel for 100000 iterations were required to obtain acceptable NUTS diagnostics.
For ease-of-storage, these samples were thinned by a factor of 20 .
There were no divergent transitions, and the largest potential scale reduction factor <span class="citation">(<a href="#ref-gelman1992inference">Gelman and Rubin 1992</a>; <a href="#ref-vehtari2021rank">Vehtari et al. 2021</a>)</span> was <span class="math inline">\(\hat R = 1.02\)</span>.
These diagnostics were sufficient to treat results from NUTS as a gold-standard, though inaccuracies remain possible.</p>
</div>
<div id="use-of-pca-aghq" class="section level3 hasAnchor" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Use of PCA-AGHQ<a href="naomi-aghq.html#use-of-pca-aghq" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A Scree plot based on the spectral decomposition of <span class="math inline">\(\hat{\Hb}_\texttt{LA}(\hat{\btheta}_\texttt{LA})^{-1}\)</span> was used to select the number of principal components to keep.
Keeping <span class="math inline">\(s = 8\)</span> principal components was sufficient to explain some proportion of total variation.
The reduced rank approximation to the inverse curvature with this choice of <span class="math inline">\(s\)</span> was visually similar to the full rank matrix.</p>
</div>
<div id="model-assessment" class="section level3 hasAnchor" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> Model assessment<a href="naomi-aghq.html#model-assessment" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="inference-comparison" class="section level3 hasAnchor" number="6.5.4">
<h3><span class="header-section-number">6.5.4</span> Inference comparison<a href="naomi-aghq.html#inference-comparison" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="exceedance-probabilities" class="section level3 hasAnchor" number="6.5.5">
<h3><span class="header-section-number">6.5.5</span> Exceedance probabilities<a href="naomi-aghq.html#exceedance-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="meeting-the-second-90" class="section level4 hasAnchor" number="6.5.5.1">
<h4><span class="header-section-number">6.5.5.1</span> Meeting the second 90<a href="naomi-aghq.html#meeting-the-second-90" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Ambitious fast-track targets for scaling up ART treatment have been developed by UNAIDS, with the goal of “ending the AIDS epidemic by 2030”.</p>
</div>
<div id="finding-strata-with-high-incidence" class="section level4 hasAnchor" number="6.5.5.2">
<h4><span class="header-section-number">6.5.5.2</span> Finding strata with high incidence<a href="naomi-aghq.html#finding-strata-with-high-incidence" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Some HIV interventions are cost-effective only within high HIV incidence settings, typically defined as higher than 1% incidence per year.
The Naomi model can be used to assess the probability of a strata having high incidence by evaluating <span class="math inline">\(\mathbb{P}(\lambda_i &gt; 0.01)\)</span>.</p>
</div>
</div>
</div>
<div id="discussion-2" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Discussion<a href="naomi-aghq.html#discussion-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter made two main contributions.
First, the universal INLA implementation of Section <a href="naomi-aghq.html#universal">6.2</a>.
Second, the PCA-AGHQ rule (Sections <a href="naomi-aghq.html#pca-aghq">6.4</a>) with application to INLA for Naomi (Section <a href="naomi-aghq.html#malawi">6.5</a>).
This section discusses these contributions in turn, before outlining suggestions for future related work.</p>
<div id="a-universal-inla-implementation" class="section level3 hasAnchor" number="6.6.1">
<h3><span class="header-section-number">6.6.1</span> A universal INLA implementation<a href="naomi-aghq.html#a-universal-inla-implementation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="pca-aghq-with-application-to-inla-for-naomi" class="section level3 hasAnchor" number="6.6.2">
<h3><span class="header-section-number">6.6.2</span> PCA-AGHQ with application to INLA for Naomi<a href="naomi-aghq.html#pca-aghq-with-application-to-inla-for-naomi" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For the simplified Naomi model applied to data from Malawi, INLA with Gaussian marginals and the PCA-AGHQ quadrature rule was more accurate at inferring latent field posterior marginal distributions than with an EB quadrature rule.
However, model output posterior marginals did not see the same improvements.
The approximate posterior exceedance probabilities from both EB and PCA-AGHQ had systematic inaccuracies as compared with NUTS.
EB and PCA-AGHQ were substantially faster than NUTS, which took over two days to reach convergence.</p>
<p>The inaccuracies in model outputs from EB and PCA-AGHQ have the potential to meaningfully mislead policy.
As such, where possible gold-standard NUTS results should be computed.
Though NUTS is to slow too run during a workshop, it could be run afterwards.
That said, Malawi is one of the countries with the fewest number of districts.
As NUTS took days to run in Malawi, for larger countries, with hundreds of districts, it may not be possible to run NUTS to convergence.</p>
<p>PCA-AGHQ and NUTS could be added to the Naomi web interface (<a href="https://naomi.unaids.org"><code>https://naomi.unaids.org</code></a>) as an alternative to EB.
Analysts would be able to quickly iterate over model options using EB, before switching to a more accurate approach once they are happy with the results.</p>
<p>PCA-AGHQ can be adjusted to suit the computational budget available by choice of the number of dimensions kept in the PCA <span class="math inline">\(s\)</span> and the number of points per dimension <span class="math inline">\(k\)</span>.
The scree plot is a well established heuristic for choosing <span class="math inline">\(s\)</span>.
Heuristics for choosing <span class="math inline">\(k\)</span> are less well established.
Whether it is preferable for a given computational budget to increase <span class="math inline">\(s\)</span> or increase <span class="math inline">\(k\)</span> is an open question.
Further strategies, such as gradually lowering <span class="math inline">\(k\)</span> over the principal components, could also be considered.</p>
</div>
<div id="suggestions-for-future-work" class="section level3 hasAnchor" number="6.6.3">
<h3><span class="header-section-number">6.6.3</span> Suggestions for future work<a href="naomi-aghq.html#suggestions-for-future-work" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Finally, this section presents suggestions for future work based on this chapter.
Some suggestions relate more to individual contributions, others take a broader view, or relate to multiple contributions.</p>
<div id="further-comparisons" class="section level4 hasAnchor" number="6.6.3.1">
<h4><span class="header-section-number">6.6.3.1</span> Further comparisons<a href="naomi-aghq.html#further-comparisons" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Comparison to additional Bayesian inference methods could be included in Section <a href="naomi-aghq.html#malawi">6.5</a>.
Three further comparisons stand out as being particularly valuable:</p>
<ol style="list-style-type: decimal">
<li>There exist other quadrature rules for moderate dimension, such as the CCD.
It would be of interest to compare INLA with a PCA-AGHQ rule to INLA with other such quadrature rules.</li>
<li>NUTS is not especially well suited to sampling from Gaussian latent field models like Naomi.
Other MCMC algorithms, such as blocked Gibbs sampling <span class="citation">(<a href="#ref-geman1984stochastic">Geman and Geman 1984</a>)</span> or slice sampling <span class="citation">(<a href="#ref-neal2003slice">Neal 2003</a>)</span>, could be considered.
Both of these MCMC algorithms are implemented and can be customised, including the choice of block structure, within the <code>NIMBLE</code> probabilistic programming language <span class="citation">(<a href="#ref-de2017programming">Valpine et al. 2017</a>)</span>.</li>
<li>Rather than use quadrature to integrate the marginal Laplace approximation, an alternative approach, implemented in <code>tmbstan</code> by setting <code>laplace = TRUE</code>, is to run HMC <span class="citation">(<a href="#ref-monnahan2018no">Monnahan and Kristensen 2018</a>; <a href="#ref-margossian2020hamiltonian">Margossian et al. 2020</a>)</span>.
When run to convergence, inferential error of this method would solely be due to the Laplace approximation, helping to clarify the extent to which the inferential error of INLA is attributable to the quadrature grid.</li>
</ol>
<!-- Finn Lindgren is working on a method for non-linear predictors, called the [iterative INLA method](https://github.com/inlabru-org/inlabru/blob/55896f10d563c14e34cab577b29b733aac051f86/vignettes/method.Rmd). -->
<!-- More [slides](https://informatique-mia.inrae.fr/reseau-resste/sites/default/files/2020-09/slides-Lindgren_Avignon2018.pdf) here -->
</div>
<div id="investigation-of-quadrature-grid" class="section level4 hasAnchor" number="6.6.3.2">
<h4><span class="header-section-number">6.6.3.2</span> Investigation of quadrature grid<a href="naomi-aghq.html#investigation-of-quadrature-grid" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Gaussian times polynomial kernel fit to the 24 dimensional NUTS hyperparameter samples.
Assess whether PCA-AGHQ is suitable.
Or whether AGHQ is suitable.
Could be generalised.</p>
</div>
<div id="better-quadrature-grids" class="section level4 hasAnchor" number="6.6.3.3">
<h4><span class="header-section-number">6.6.3.3</span> Better quadrature grids<a href="naomi-aghq.html#better-quadrature-grids" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>PCA-AGHQ is a sensible approach to allocating more computational to dimensions which contribute more to the integral in question.
However, its application to Naomi surfaced instances where it overlooked potential benefits, or otherwise did not behave as one might wish:</p>
<ol style="list-style-type: decimal">
<li>The amount of variation explained in the Hessian matrix may not be of direct interest.
For the Naomi model, interest is in the effect of including each dimension on the relevant model outputs.
As such, using alternative measures of importance from sensitivity analysis, such as Shapley values <span class="citation">(<a href="#ref-shapley1953value">Shapley et al. 1953</a>)</span> or Sobol indicies, could be preferable.</li>
<li>Use of PCA is challenging when the dimensions have different scales.
For the Naomi model, logit-scale hyperparameters were systematically favoured over those on the log-scale.</li>
<li>When the quadrature rule is used within an INLA algorithm, it is more important to allocate quadrature nodes to those hyperparameter marginals which are non-Gaussian.
This is because the Laplace approximation is exact when the integrand is Gaussian, so a single quadrature node is sufficient.
The difficulty is, of course, knowing in advance which marginals will be non-Gaussian.
This could be done if there were a cheap way to obtain posterior means, which could then be compared to posterior modes obtained using optimisation.
Another approach would be to measure the fit of marginal samples from a cheap approximation, like EB.
The measures of fit would have to be for marginals, ruling out approaches like PSIS <span class="citation">(<a href="#ref-yao2018yes">Yao et al. 2018</a>)</span> which operate on joint distributions.</li>
</ol>
</div>
<div id="computational-improvements" class="section level4 hasAnchor" number="6.6.3.4">
<h4><span class="header-section-number">6.6.3.4</span> Computational improvements<a href="naomi-aghq.html#computational-improvements" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>Approximation: Implement the simplified Laplace marginals of <span class="citation">Wood (<a href="#ref-wood2020simplified">2020</a>)</span> (Section <a href="naomi-aghq.html#simplified-inla">6.1.3.4</a>).</li>
<li>Parallelisation: Integration over a moderate number of hyperparameters resulted in use of quadrature grids with a large number of nodes.
Computation at each node is independent, so algorithm run-time could potentially be significantly improved using parallel computing.
This point is discussed by <span class="citation">Kristensen et al. (<a href="#ref-kristensen2016tmb">2016</a>)</span> who highlight that <code>TMB</code> could applied to perform function evaluations in parallel, for example using the <code>parallel</code> R package.</li>
<li>Hardware: Further computational speed-ups might be obtained using graphics processing units (GPUs) specialised for the relevant matrix operations.</li>
</ol>
</div>
<div id="statistical-theory" class="section level4 hasAnchor" number="6.6.3.5">
<h4><span class="header-section-number">6.6.3.5</span> Statistical theory<a href="naomi-aghq.html#statistical-theory" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The class of functions which are integrated exactly by PCA-AGHQ remains to be shown.
Theorem 1 of <span class="citation">Stringer, Brown, and Stafford (<a href="#ref-stringer2022fast">2022</a>)</span> bounds the total variation error of AGHQ, establishing convergence in probability of coverage probabilities under the approximate posterior distribution to those under the true posterior distribution.
Similar theory could be established for PCA-AGHQ, or more generally AGHQ with varying levels.
The challenge of connecting this theory to nested use of any quadrature rule, like that in the INLA algorithm, remains an important open question.
<!-- Perhaps my clear formulation of the INLA algorithm with AGHQ rules helps --></p>
</div>
<div id="exploration-of-the-accuracy-of-inla-for-complex-models" class="section level4 hasAnchor" number="6.6.3.6">
<h4><span class="header-section-number">6.6.3.6</span> Exploration of the accuracy of INLA for complex models<a href="naomi-aghq.html#exploration-of-the-accuracy-of-inla-for-complex-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A universal INLA implementation could be used to assess the accuracy of INLA for a wider range of models.
Among the ELGM-type structures of particular interest are aggregated Gaussian process models <span class="citation">(<a href="#ref-nandi2023disaggregation">Nandi et al. 2023</a>)</span> and evidence synthesis models <span class="citation">(<a href="#ref-amoah2020geostatistical">Amoah, Diggle, and Giorgi 2020</a>)</span>.</p>
</div>
<div id="methods-dissemination" class="section level4 hasAnchor" number="6.6.3.7">
<h4><span class="header-section-number">6.6.3.7</span> Methods dissemination<a href="naomi-aghq.html#methods-dissemination" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The approach used to implement Laplace marginals with <code>TMB</code> was relatively ad-hoc, and involved modification of the <code>TMB</code> C++ template (Section <a href="naomi-aghq.html#epil-laplace-eb-tmb">6.2.1.4</a>).
For wider dissemination of this method, it is important that the user is not burdened with making these modifications themself.
One possibility would be to change the <code>random</code> argument in <code>TMB::MakeADFun</code> to allow for indexing.
Another (less desirable) option would be to algorithimically generate the modified <code>TMB</code> C++ template based on the original template.</p>

<div class="figure" style="text-align: centre"><span style="display:block;" id="fig:package-downloads"></span>
<img src="figures/naomi-aghq/package-downloads.png" alt="Monthly R package downloads from the Comprehensive R Archive Network (CRAN) for brms, glmmTMB, nimble, rstan and TMB, obtained using the Csárdi (2023) R package. Unfortunately, R-INLA is not available from CRAN, and so could not be included in this figure." width="95%" />
<p class="caption">
Figure 6.9: Monthly R package downloads from the Comprehensive R Archive Network (CRAN) for <code>brms</code>, <code>glmmTMB</code>, <code>nimble</code>, <code>rstan</code> and <code>TMB</code>, obtained using the <span class="citation">Csárdi (<a href="#ref-cranlogs">2023</a>)</span> R package. Unfortunately, <code>R-INLA</code> is not available from CRAN, and so could not be included in this figure.
</p>
</div>
<p>Though gaining in popularity, the user-base of <code>TMB</code> is relatively small, and package downloads are in large part driven by use of the more easy-to-use <code>glmmTMB</code> package (Figure <a href="naomi-aghq.html#fig:package-downloads">6.9</a>).
For users unfamiliar with C++, it can be challenging to use <code>TMB</code> directly.
One possibility is to look to disseminate methods via the users of <code>glmmTMB</code>.
Another approach would be to implement methods in other probabilistic programming languages, such as <code>Stan</code> or <code>NIMBLE</code>.
Implementation in <code>Stan</code> is made possible by the <code>bridgestan</code> package <span class="citation">(<a href="#ref-bridgestan">Ward 2023</a>)</span>, which provides access to the methods of a <code>Stan</code> model, and could be combined with the prototyping of an adjoint-differentiated Laplace approximation done in <code>Stan</code> by <span class="citation">Margossian et al. (<a href="#ref-margossian2020hamiltonian">2020</a>)</span>.
The ratio of downloads of <code>rstan</code> as compared with <code>brms</code> suggests a larger proportion of <code>Stan</code> users are interested in specifying their own model.
Implementation in <code>NIMBLE</code> is also possible as of version &gt;1.0.0 which includes functionality for automatic differentiation and Laplace approximation [Part V; <span class="citation">de Valpine et al. (<a href="#ref-nimblemanual">2023</a>)</span>] built using <code>CppAD</code> like <code>TMB</code>, as of .
Both the <code>NIMBLE</code> and <code>Stan</code> developers are actively looking into implementation algorithms combining the Laplace approximation and quadrature.</p>

</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-amoah2020geostatistical" class="csl-entry">
Amoah, Benjamin, Peter J Diggle, and Emanuele Giorgi. 2020. <span>“A Geostatistical Framework for Combining Spatially Referenced Disease Prevalence Data from Multiple Diagnostics.”</span> <em>Biometrics</em> 76 (1): 158–70.
</div>
<div id="ref-bachl2019inlabru" class="csl-entry">
Bachl, Fabian E, Finn Lindgren, David L Borchers, and Janine B Illian. 2019. <span>“Inlabru: An r Package for Bayesian Spatial Modelling from Ecological Survey Data.”</span> <em>Methods in Ecology and Evolution</em> 10 (6): 760–66.
</div>
<div id="ref-baydin2017automatic" class="csl-entry">
Baydin, Atılım Günes, Barak A Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind. 2017. <span>“<span class="nocase">Automatic differentiation in machine learning: a survey</span>.”</span> <em>The Journal of Machine Learning Research</em> 18 (1): 5595–5637.
</div>
<div id="ref-cppaddocumentation" class="csl-entry">
Bell, Bradley. 2023. <span>“CppAD: A Package for c++ Algorithmic Differentiation.”</span> <a href="http://www.coin-or.org/CppAD" class="uri">http://www.coin-or.org/CppAD</a>.
</div>
<div id="ref-bilodeau2022stochastic" class="csl-entry">
Bilodeau, Blair, Alex Stringer, and Yanbo Tang. 2022. <span>“Stochastic Convergence Rates and Applications of Adaptive Quadrature in Bayesian Inference.”</span> <em>Journal of the American Statistical Association</em>, 1–11.
</div>
<div id="ref-bollhofer2020state" class="csl-entry">
Bollhöfer, Matthias, Olaf Schenk, Radim Janalik, Steve Hamm, and Kiran Gullapalli. 2020. <span>“State-of-the-Art Sparse Direct Solvers.”</span> <em>Parallel Algorithms in Computational Science and Engineering</em>, 3–33.
</div>
<div id="ref-box1992experimental" class="csl-entry">
Box, George EP, and Kenneth B Wilson. 1992. <span>“On the Experimental Attainment of Optimum Conditions.”</span> In <em>Breakthroughs in Statistics: Methodology and Distribution</em>, 270–310. Springer.
</div>
<div id="ref-breslow1993approximate" class="csl-entry">
Breslow, Norman E, and David G Clayton. 1993. <span>“Approximate Inference in Generalized Linear Mixed Models.”</span> <em>Journal of the American Statistical Association</em> 88 (421): 9–25.
</div>
<div id="ref-brooks2017glmmtmb" class="csl-entry">
Brooks, Mollie E, Kasper Kristensen, Koen J Van Benthem, Arni Magnusson, Casper W Berg, Anders Nielsen, Hans J Skaug, Martin Machler, and Benjamin M Bolker. 2017. <span>“glmmTMB Balances Speed and Flexibility Among Packages for Zero-Inflated Generalized Linear Mixed Modeling.”</span> <em>The R Journal</em> 9 (2): 378–400.
</div>
<div id="ref-casella1985introduction" class="csl-entry">
Casella, George. 1985. <span>“An Introduction to Empirical Bayes Data Analysis.”</span> <em>The American Statistician</em> 39 (2): 83–87.
</div>
<div id="ref-chen2014use" class="csl-entry">
Chen, Cici, Jon Wakefield, and Thomas Lumely. 2014. <span>“The Use of Sampling Weights in Bayesian Hierarchical Models for Small Area Estimation.”</span> <em>Spatial and Spatio-Temporal Epidemiology</em> 11: 33–43.
</div>
<div id="ref-cranlogs" class="csl-entry">
Csárdi, Gábor. 2023. <em>Cranlogs: Download Logs from the ’RStudio’ ’CRAN’ Mirror</em>.
</div>
<div id="ref-davis1975methods" class="csl-entry">
Davis, Philip J, and Philip Rabinowitz. 1975. <em>Methods of Numerical Integration</em>. Academic Press.
</div>
<div id="ref-nimblemanual" class="csl-entry">
de Valpine, Perry, Christopher Paciorek, Daniel Turek, Nick Michaud, Cliff Anderson-Bergman, Fritz Obermeyer, Claudia Wehrhahn Cortes, Abel Rodrìguez, Duncan Temple Lang, and Sally Paganin. 2023. <em><span>NIMBLE</span> User Manual</em> (version 1.0.1). <a href="https://doi.org/10.5281/zenodo.1211190">https://doi.org/10.5281/zenodo.1211190</a>.
</div>
<div id="ref-diaz2018openmp" class="csl-entry">
Diaz, Jose Monsalve, Swaroop Pophale, Oscar Hernandez, David E Bernholdt, and Sunita Chandrasekaran. 2018. <span>“Openmp 4.5 Validation and Verification Suite for Device Offload.”</span> In <em>Evolving OpenMP for Evolving Architectures: 14th International Workshop on OpenMP, IWOMP 2018, Barcelona, Spain, September 26–28, 2018, Proceedings 14</em>, 82–95. Springer.
</div>
<div id="ref-eaton2021naomi" class="csl-entry">
Eaton, Jeffrey W, Laura Dwyer-Lindgren, Steve Gutreuter, Megan O’Driscoll, Oliver Stevens, Sumali Bajaj, Rob Ashton, et al. 2021. <span>“Naomi: A New Modelling Tool for Estimating HIV Epidemic Indicators at the District Level in Sub-Saharan Africa.”</span>
</div>
<div id="ref-esra2023improved" class="csl-entry">
Esra, Rachel. 2023. <span>“Improved Indicators for Subnational Unmet Antiretroviral Therapy Need in the Health System: Updates to the Naomi Model in 2023.”</span>
</div>
<div id="ref-fattah2021smart" class="csl-entry">
Fattah, Esmail Abdul, Janet Van Niekerk, and Håvard Rue. 2021. <span>“Smart Gradient–an Adaptive Technique for Improving Gradient Estimation.”</span> <em>arXiv Preprint arXiv:2106.07313</em>.
</div>
<div id="ref-gaedke2023parallelized" class="csl-entry">
Gaedke-Merzhäuser, Lisa, Janet van Niekerk, Olaf Schenk, and Håvard Rue. 2023. <span>“Parallelized Integrated Nested Laplace Approximations for Fast Bayesian Inference.”</span> <em>Statistics and Computing</em> 33 (1): 25.
</div>
<div id="ref-gelman1992inference" class="csl-entry">
Gelman, Andrew, and Donald B Rubin. 1992. <span>“Inference from Iterative Simulation Using Multiple Sequences.”</span> <em>Statistical Science</em>, 457–72.
</div>
<div id="ref-geman1984stochastic" class="csl-entry">
Geman, Stuart, and Donald Geman. 1984. <span>“Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, no. 6: 721–41.
</div>
<div id="ref-gomez2020bayesian" class="csl-entry">
Gómez-Rubio, Virgilio. 2020. <em>Bayesian Inference with INLA</em>. CRC Press.
</div>
<div id="ref-howes2023fast" class="csl-entry">
Howes, Adam, Alex Stringer, Seth R. Flaxman, and Jeffrey W. Eaton. 2023+. <span>“<span class="nocase">Fast approximate Bayesian inference of HIV indicators using PCA adaptive Gauss-Hermite quadrature</span>,”</span> 2023+.
</div>
<div id="ref-jackel2005note" class="csl-entry">
Jäckel, Peter. 2005. <span>“A Note on Multivariate Gauss-Hermite Quadrature.”</span> <em>London: ABN-Amro. Re</em>.
</div>
<div id="ref-kish1965survey" class="csl-entry">
Kish, Leslie. 1965. <em>Survey Sampling</em>. 04; HN29, K5.
</div>
<div id="ref-kristensen2016tmb" class="csl-entry">
Kristensen, Kasper, Anders Nielsen, Casper W Berg, Hans Skaug, Bradley M Bell, et al. 2016. <span>“TMB: Automatic Differentiation and Laplace Approximation.”</span> <em>Journal of Statistical Software</em> 70 (i05).
</div>
<div id="ref-laplace1774memoire" class="csl-entry">
Laplace, P. S. 1774. <span>“Memoire Sur La Probabilite de Causes Par Les Evenements.”</span> <em>Memoire de l’Academie Royale Des Sciences</em>.
</div>
<div id="ref-lenth2009rsm" class="csl-entry">
Lenth, Russell. 2009. <span>“Response-Surface Methods in <span>R</span>, Using <span class="nocase">rsm</span>.”</span> <em>Journal of Statistical Software</em> 32 (7): 1–17. <a href="https://doi.org/10.18637/jss.v032.i07">https://doi.org/10.18637/jss.v032.i07</a>.
</div>
<div id="ref-leppik1985double" class="csl-entry">
Leppik, IE, FE Dreifuss, T Bowman-Cloyd, N Santilli, M Jacobs, C Crosby, J Cloyd, et al. 1985. <span>“A Double-Blind Crossover Evaluation of Progabide in Partial Seizures.”</span> <em>Neurology</em> 35 (4): 285.
</div>
<div id="ref-lindgren2011explicit" class="csl-entry">
Lindgren, Finn, Håvard Rue, and Johan Lindström. 2011. <span>“An Explicit Link Between Gaussian Fields and Gaussian Markov Random Fields: The Stochastic Partial Differential Equation Approach.”</span> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 73 (4): 423–98.
</div>
<div id="ref-margossian2020hamiltonian" class="csl-entry">
Margossian, Charles, Aki Vehtari, Daniel Simpson, and Raj Agrawal. 2020. <span>“Hamiltonian Monte Carlo Using an Adjoint-Differentiated Laplace Approximation: Bayesian Inference for Latent Gaussian Models and Beyond.”</span> <em>Advances in Neural Information Processing Systems</em> 33: 9086–97.
</div>
<div id="ref-martino2019integrated" class="csl-entry">
Martino, Sara, and Andrea Riebler. 2019. <span>“Integrated Nested Laplace Approximations (INLA).”</span> <em>arXiv Preprint arXiv:1907.01248</em>.
</div>
<div id="ref-martino2009implementing" class="csl-entry">
Martino, Sara, and Håvard Rue. 2009. <span>“Implementing Approximate Bayesian Inference Using Integrated Nested Laplace Approximation: A Manual for the Inla Program.”</span> <em>Department of Mathematical Sciences, NTNU, Norway</em>.
</div>
<div id="ref-martins2013bayesian" class="csl-entry">
Martins, Thiago G, Daniel Simpson, Finn Lindgren, and Håvard Rue. 2013. <span>“<span class="nocase">Bayesian computing with INLA: new features</span>.”</span> <em>Computational Statistics &amp; Data Analysis</em> 67: 68–83.
</div>
<div id="ref-meng2018statistical" class="csl-entry">
Meng, Xiao-Li. 2018. <span>“Statistical Paradises and Paradoxes in Big Data (i) Law of Large Populations, Big Data Paradox, and the 2016 Us Presidential Election.”</span> <em>The Annals of Applied Statistics</em> 12 (2): 685–726.
</div>
<div id="ref-monnahan2018no" class="csl-entry">
Monnahan, Cole C, and Kasper Kristensen. 2018. <span>“No-u-Turn Sampling for Fast Bayesian Inference in ADMB and TMB: Introducing the Adnuts and Tmbstan r Packages.”</span> <em>PloS One</em> 13 (5): e0197954.
</div>
<div id="ref-nandi2023disaggregation" class="csl-entry">
Nandi, Anita K, Tim CD Lucas, Rohan Arambepola, Peter Gething, and Daniel J Weiss. 2023. <span>“Disaggregation: An r Package for Bayesian Spatial Disaggregation Modeling.”</span> <em>Journal of Statistical Software</em> 106: 1–19.
</div>
<div id="ref-naylor1982applications" class="csl-entry">
Naylor, John C, and Adrian FM Smith. 1982. <span>“Applications of a Method for the Efficient Computation of Posterior Distributions.”</span> <em>Journal of the Royal Statistical Society Series C: Applied Statistics</em> 31 (3): 214–25.
</div>
<div id="ref-neal2003slice" class="csl-entry">
Neal, Radford M. 2003. <span>“Slice Sampling.”</span> <em>The Annals of Statistics</em> 31 (3): 705–67.
</div>
<div id="ref-press2007numerical" class="csl-entry">
Press, William H, Teukolsky Saul A, William T Vetterling, and Brian P Flannery. 2007. <em>Numerical Recipes 3rd Edition: The Art of Scientific Computing</em>. Cambridge university press.
</div>
<div id="ref-rue2001fast" class="csl-entry">
Rue, Håvard. 2001. <span>“Fast Sampling of Gaussian Markov Random Fields.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 63 (2): 325–38.
</div>
<div id="ref-rue2001gmrflib" class="csl-entry">
Rue, Håvard, and Turid Follestad. 2001. <span>“GMRFLib: A c-Library for Fast and Exact Simulation of Gaussian Markov Random Fields.”</span> SIS-2002-236.
</div>
<div id="ref-rue2005gaussian" class="csl-entry">
Rue, Havard, and Leonhard Held. 2005. <em><span class="nocase">Gaussian Markov random fields: theory and applications</span></em>. CRC press.
</div>
<div id="ref-rue2007approximate" class="csl-entry">
Rue, Håvard, and Sara Martino. 2007. <span>“<span class="nocase">Approximate Bayesian inference for hierarchical Gaussian Markov random field models</span>.”</span> <em>Journal of Statistical Planning and Inference</em> 137 (10): 3177–92.
</div>
<div id="ref-rue2009approximate" class="csl-entry">
Rue, Håvard, Sara Martino, and Nicolas Chopin. 2009. <span>“<span class="nocase">Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 71 (2): 319–92.
</div>
<div id="ref-rue2017bayesian" class="csl-entry">
Rue, Håvard, Andrea Riebler, Sigrunn H Sørbye, Janine B Illian, Daniel P Simpson, and Finn K Lindgren. 2017. <span>“Bayesian Computing with INLA: A Review.”</span> <em>Annual Review of Statistics and Its Application</em> 4: 395–421.
</div>
<div id="ref-shapley1953value" class="csl-entry">
Shapley, Lloyd S et al. 1953. <span>“A Value for n-Person Games.”</span>
</div>
<div id="ref-simpson2017penalising" class="csl-entry">
Simpson, Daniel, Håvard Rue, Andrea Riebler, Thiago G Martins, Sigrunn H Sørbye, et al. 2017. <span>“<span class="nocase">Penalising model component complexity: A principled, practical approach to constructing priors</span>.”</span> <em>Statistical Science</em> 32 (1): 1–28.
</div>
<div id="ref-skaug2009approximate" class="csl-entry">
Skaug, Hans J. 2009. <span>“<span class="nocase">Discussion of "Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations"</span>.”</span> In <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 71:319–92. 2. Wiley Online Library.
</div>
<div id="ref-spiegelhalter1996bugs" class="csl-entry">
Spiegelhalter, David, Andrew Thomas, Nicky Best, and Wally Gilks. 1996. <span>“BUGS 0.5 Examples.”</span> <em>MRC Biostatistics Unit, Institute of Public Health, Cambridge, UK</em> 256.
</div>
<div id="ref-stringer2021implementing" class="csl-entry">
———. 2021b. <span>“Implementing Approximate Bayesian Inference Using Adaptive Quadrature: The Aghq Package.”</span> <em>arXiv Preprint arXiv:2101.04468</em>.
</div>
<div id="ref-stringer2022fast" class="csl-entry">
Stringer, Alex, Patrick Brown, and Jamie Stafford. 2022. <span>“Fast, Scalable Approximations to Posterior Distributions in Extended Latent Gaussian Models.”</span> <em>Journal of Computational and Graphical Statistics</em>, 1–15.
</div>
<div id="ref-vstrumbelj2023past" class="csl-entry">
Štrumbelj, Erik, Alexandre Bouchard-Côté, Jukka Corander, Andrew Gelman, Håvard Rue, Lawrence Murray, Henri Pesonen, Martyn Plummer, and Aki Vehtari. 2023. <span>“Past, Present, and Future of Software for Bayesian Inference.”</span>
</div>
<div id="ref-thall1990some" class="csl-entry">
Thall, Peter F, and Stephen C Vail. 1990. <span>“Some Covariance Models for Longitudinal Count Data with Overdispersion.”</span> <em>Biometrics</em>, 657–71.
</div>
<div id="ref-tierney1986accurate" class="csl-entry">
Tierney, Luke, and Joseph B Kadane. 1986. <span>“<span class="nocase">Accurate approximations for posterior moments and marginal densities</span>.”</span> <em>Journal of the American Statistical Association</em> 81 (393): 82–86.
</div>
<div id="ref-unaids2023global" class="csl-entry">
———. 2023b. <span>“The Path That Ends AIDS: UNAIDS Global AIDS Update 2023.”</span> <a href="https://www.unaids.org/en/resources/documents/2023/global-aids-update-2023" class="uri">https://www.unaids.org/en/resources/documents/2023/global-aids-update-2023</a>.
</div>
<div id="ref-de2017programming" class="csl-entry">
Valpine, Perry de, Daniel Turek, Christopher J Paciorek, Clifford Anderson-Bergman, Duncan Temple Lang, and Rastislav Bodik. 2017. <span>“Programming with Models: Writing Statistical Algorithms for General Model Structures with NIMBLE.”</span> <em>Journal of Computational and Graphical Statistics</em> 26 (2): 403–13.
</div>
<div id="ref-van2023new" class="csl-entry">
Van Niekerk, Janet, Elias Krainski, Denis Rustand, and Håvard Rue. 2023. <span>“A New Avenue for Bayesian Inference with INLA.”</span> <em>Computational Statistics &amp; Data Analysis</em> 181: 107692.
</div>
<div id="ref-vehtari2021rank" class="csl-entry">
Vehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and Paul-Christian Bürkner. 2021. <span>“<span class="nocase">Rank-normalization, folding, and localization: an improved R for assessing convergence of MCMC (with discussion)</span>.”</span> <em>Bayesian Analysis</em> 16 (2): 667–718.
</div>
<div id="ref-bridgestan" class="csl-entry">
Ward, Brian. 2023. <em>Bridgestan: BridgeStan, Accessing Stan Model Functions in r</em>.
</div>
<div id="ref-weiser2016mvquad" class="csl-entry">
Weiser, Constantin. 2016. <em><span class="nocase">mvQuad</span>: Methods for Multivariate Quadrature.</em> <a href="http://CRAN.R-project.org/package=mvQuad">http://CRAN.R-project.org/package=mvQuad</a>.
</div>
<div id="ref-wood2017generalized" class="csl-entry">
Wood, Simon N. 2017. <em>Generalized Additive Models: An Introduction with r</em>. CRC press.
</div>
<div id="ref-wood2020simplified" class="csl-entry">
———. 2020. <span>“<span class="nocase">Simplified integrated nested Laplace approximation</span>.”</span> <em>Biometrika</em> 107 (1): 223–30.
</div>
<div id="ref-yao2018yes" class="csl-entry">
Yao, Yuling, Aki Vehtari, Daniel Simpson, and Andrew Gelman. 2018. <span>“Yes, but Did It Work?: Evaluating Variational Inference.”</span> In <em>International Conference on Machine Learning</em>, 5581–90. PMLR.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multi-agyw.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ulyngs/oxforddown/tree/master/06-naomi-aghq.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
